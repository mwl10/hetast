{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62203aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##  better software principles w/ dataset class,\n",
    "    # what does a dataset have? normalizing functions, \n",
    "\n",
    "# how we're gonna do synthetic data\n",
    "    ## do the convolution thing once we have one band's carma fit to get others, then manually add lags\n",
    "    \n",
    "## could test the effects of length / num points on anomaly detection w/ syntehtic data, anomalous fits\n",
    "# for dataset balancing, its probably more about number of observed points\n",
    "# for training, its more about light cures being in the same time ranges \n",
    "\n",
    "\n",
    "## 12/27\n",
    "    ## mcmc sample errors on the fly during training, error bar code \n",
    "\n",
    "# weird decisions to make (for talkinig purposes)\n",
    "    # normlaize across training or individually? \n",
    "    # how to 'chop' by lenght or num points, min points?\n",
    "    # injecting domain-specific knowledge\n",
    "        # >1 mag err, keep obejcts between 13-20 mag, objects w/ certain intrinsitc var\n",
    "    # formatting, setting masks\n",
    "    \n",
    "    # hyper-parameter things\n",
    "    \n",
    "    # how to use error bars on input data? \n",
    "        \n",
    "        \n",
    "    # lr scheduling? \n",
    "    # visualize kl annealing? wait_until_kl_inc is a hyperparam! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a670f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from dataset import DataSet\n",
    "from eztao.carma import DRW_term, DHO_term\n",
    "from eztao.ts import gpSimRand\n",
    "import os\n",
    "import model\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "from eztao.carma import DRW_term, DHO_term\n",
    "from eztao.ts import gpSimRand, gpSimFull\n",
    "\n",
    "\n",
    "def get_synth_data(folder, seed = 0, batch_size=8, frac=0.5, kernel='drw', duration=730, n=180):\n",
    "    \"\"\"\n",
    "    \n",
    "    This function creates and loads a synthetic dataset relative to a given kernel (drw or dho), \n",
    "    distributing the kernel params relative to a real dataset, in base_folder \n",
    "    \n",
    "    parameters:\n",
    "        seed               (int)      --> random seed, this matters to keep the shuffles consistent\n",
    "        batch_size         (int)      --> for the network, usually a multiple of 2\n",
    "        kernel             (str)      --> 'drw' (dampled random walk), a carma(1) process; 'dho' (damped harmonic oscillator), a carma(2,1) process\n",
    "        \n",
    "    drw_kernel def --> 'tau' is decorelation timescale, 'amp' is the amplitude\n",
    "    dho_kernel def --> a1 = 2 * Xi * w0\n",
    "                       a2 = w0 ** 2\n",
    "                       b0 = sigma\n",
    "                       b1 = tau * b0\n",
    "                       wherein Xi is the damping ratio, w0 is the natural oscillation frequency, sigma is the amplitude\n",
    "                       of the short term perturbing white noise, tau is the characteristic timescale of the perturbation process\n",
    "    returns:\n",
    "        a dictionary of torch dataloaders with data formatted as necessary for network training \n",
    "        , as well as the dimension and union of all the time points\n",
    "    \"\"\"\n",
    "    # which bands do you want to simulate?!?\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    if not os.path.isdir(folder):\n",
    "        raise Exception(f\"{folder} is not a directory\")\n",
    "        \n",
    "    lcs = DataSet(name=folder, min_length=50, sep=',', start_col=1)\n",
    "    band_folders = os.listdir(folder)\n",
    "    for band_folder in band_folders:\n",
    "        band = band_folder.lower()\n",
    "        lcs.add_band(band, os.path.join(folder, band_folder))\n",
    "        \n",
    "    lcs.filter()         \n",
    "    lcs.prune_outliers()\n",
    "    lcs.set_carma_fits()\n",
    "    lcs.set_snr()\n",
    "    if kernel == 'drw':\n",
    "        synth_lcs = []\n",
    "        for i, params in enumerate(lcs.drw_fits):\n",
    "            if np.isnan(params[0]):\n",
    "                continue\n",
    "            DRW_kernel = DRW_term(*np.log(params))\n",
    "            # kernel, snr, duration (days), n \n",
    "            lc = np.array(gpSimRand(DRW_kernel,lcs.snr[i,0], duration, n)).transpose(1,0)[np.newaxis,np.newaxis]\n",
    "            synth_lcs.append(lc)\n",
    "        synth_lcs = np.concatenate(synth_lcs, axis=0)\n",
    "    ##################### dho #################################\n",
    "    else:\n",
    "        synth_lcs = []\n",
    "        for i, params in enumerate(lcs.dho_fits):\n",
    "            if np.isnan(params[0]):\n",
    "                print('nannnnnnn')\n",
    "                continue\n",
    "            DHO_kernel = DHO_term(*np.log(params))\n",
    "            # kernel, snr, duration (days), n \n",
    "            lc = np.array(gpSimRand(DHO_kernel,lcs.snr[i,0], duration, n)).transpose(1,0)[np.newaxis,np.newaxis]\n",
    "            synth_lcs.append(lc)\n",
    "        synth_lcs = np.concatenate(synth_lcs, axis=0)\n",
    "    \n",
    "    print(synth_lcs.shape)\n",
    "    union_tp = np.unique(synth_lcs[:,:,:,0].flatten()).astype('float32')\n",
    "    union_tp = np.arange(0, np.ptp(union_tp), step=0.5)\n",
    "    \n",
    "    np.random.shuffle(synth_lcs)\n",
    "    splindex = int(np.floor(.8*len(synth_lcs)))\n",
    "    training, valid, test = np.split(synth_lcs, [splindex, splindex + int(np.floor(.1*len(synth_lcs)))])# shuffle?\n",
    "    train_loader = torch.utils.data.DataLoader(training, batch_size=batch_size)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "    data_objects = {\n",
    "        \"train_loader\": train_loader,\n",
    "        \"test_loader\": test_loader,\n",
    "        \"valid_loader\": valid_loader,\n",
    "        'union_tp': union_tp,\n",
    "        \"input_dim\": 1,\n",
    "    }\n",
    "    return data_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3e2f39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1dc4117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8583dc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated 55 files out of 55 for band='g'\n",
      "0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/eztao/ts/carma_fit.py:423: RuntimeWarning: divide by zero encountered in log\n",
      "  (np.log(min_dt / 5), np.log(t[-1])),\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/eztao/ts/carma_fit.py:434: RuntimeWarning: divide by zero encountered in log\n",
      "  log_tau_range = [np.log(min_dt / 5), np.log(t[-1] / 10)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123456789101112131415161718192021222324252627282930313233343536373839[nan, nan]\n",
      "[nan, nan]\n",
      "[0.20783707 6.22633928]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[1.61934227e-01 4.55184695e+02]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "[nan, nan]\n",
      "(2, 1, 180, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loader': <torch.utils.data.dataloader.DataLoader at 0x153d9c910>,\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x2880644c0>,\n",
       " 'valid_loader': <torch.utils.data.dataloader.DataLoader at 0x288065360>,\n",
       " 'union_tp': array([0.000e+00, 5.000e-01, 1.000e+00, ..., 5.390e+02, 5.395e+02,\n",
       "        5.400e+02]),\n",
       " 'input_dim': 1}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_synth_data('test_data', kernel='drw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out previews\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70738e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hetvae",
   "language": "python",
   "name": "hetvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
