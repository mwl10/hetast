{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catalina_optuna.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMp2EQNIS+/WYUTwCe0v2w9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwl10/hetvae/blob/errors/src/catalina_optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CLSc_lZ7IhyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64bb656e-ea84-4d43-a1ac-4e3d632ec470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hetvae'...\n",
            "remote: Enumerating objects: 3899, done.\u001b[K\n",
            "remote: Counting objects: 100% (935/935), done.\u001b[K\n",
            "remote: Compressing objects: 100% (797/797), done.\u001b[K\n",
            "remote: Total 3899 (delta 153), reused 214 (delta 138), pack-reused 2964\u001b[K\n",
            "Receiving objects: 100% (3899/3899), 36.80 MiB | 26.32 MiB/s, done.\n",
            "Resolving deltas: 100% (1098/1098), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alembic==1.7.7\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs==21.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (21.4.0)\n",
            "Collecting autopage==0.5.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting backports.functools-lru-cache==1.6.4\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting cliff==3.10.1\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.4 MB/s \n",
            "\u001b[?25hCollecting cmaes==0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cmd2==2.3.3\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 70.6 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorlog==6.6.0\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: greenlet==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata==4.11.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources==5.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.7.1)\n",
            "Collecting Mako==1.2.0\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting numpy==1.21.0\n",
            "  Downloading numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 644 kB/s \n",
            "\u001b[?25hCollecting optuna==2.10.0\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 83.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging==21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (21.3)\n",
            "Collecting pbr==5.9.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 77.5 MB/s \n",
            "\u001b[?25hCollecting pip==22.1.1\n",
            "  Downloading pip-22.1.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prettytable==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (3.3.0)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (3.0.9)\n",
            "Collecting pyperclip==1.8.2\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.6 MB/s \n",
            "\u001b[?25hCollecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 86.9 MB/s \n",
            "\u001b[?25hCollecting setuptools==62.3.2\n",
            "  Downloading setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.8 MB/s \n",
            "\u001b[?25hCollecting SQLAlchemy==1.4.36\n",
            "  Downloading SQLAlchemy-1.4.36-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 14.1 MB/s \n",
            "\u001b[?25hCollecting stevedore==3.5.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (4.64.0)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (0.2.5)\n",
            "Requirement already satisfied: wheel==0.37.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (0.37.1)\n",
            "Requirement already satisfied: zipp==3.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 31)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2==2.3.3->-r requirements.txt (line 7)) (4.2.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=fc0a4b711d308fad038b781c06eb5b50ffad1e359778a367cb004024e6a59546\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, MarkupSafe, stevedore, SQLAlchemy, PyYAML, numpy, Mako, cmd2, autopage, scipy, colorlog, cmaes, cliff, alembic, setuptools, pip, optuna, colorama, backports.functools-lru-cache\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.37\n",
            "    Uninstalling SQLAlchemy-1.4.37:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.37\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.0 MarkupSafe-2.1.1 PyYAML-6.0 SQLAlchemy-1.4.36 alembic-1.7.7 autopage-0.5.0 backports.functools-lru-cache-1.6.4 cliff-3.10.1 cmaes-0.8.2 cmd2-2.3.3 colorama-0.4.4 colorlog-6.6.0 numpy-1.21.0 optuna-2.10.0 pbr-5.9.0 pip-22.1.1 pyperclip-1.8.2 scipy-1.7.3 setuptools-62.3.2 stevedore-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "os.chdir('/content')\n",
        "! git clone --branch errors https://github.com/mwl10/hetvae\n",
        "os.chdir('/content/hetvae')\n",
        "! pip install -r requirements.txt\n",
        "os.chdir('/content/hetvae/src')\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import models\n",
        "from argparse import Namespace\n",
        "import torch.optim as optim\n",
        "import utils\n",
        "import my_utils\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import importlib\n",
        "import vae_models\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from dataset import DataSet\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_args(trial):\n",
        "\n",
        "    args = Namespace(\n",
        "        batch_size = trial.suggest_categorical(\"batch_size\", [8,16,32]),\n",
        "        bound_variance = True,\n",
        "        const_var = False,\n",
        "        dataset='toy',\n",
        "        dropout = trial.suggest_float(\"dropout\", 0.0,0.5),\n",
        "        elbo_weight = trial.suggest_float(\"elbo_weight\", 0.0, 2.0),\n",
        "        embed_time = trial.suggest_categorical(\"embed_time\", [8,16,32,64,128]),\n",
        "        enc_num_heads=trial.suggest_categorical(\"enc_num_heads\", [1,2,4,8,16]),\n",
        "        intensity=True,\n",
        "        k_iwae=1,\n",
        "        kl_annealing=False,#trial.suggest_categorical(\"kl_annealing\",False),\n",
        "        kl_zero=False, \n",
        "        latent_dim=trial.suggest_categorical(\"latent_dim\", [8,16,32,64,128]),\n",
        "        lr=trial.suggest_float(\"lr\", 1e-7, 1e-1, log=True),\n",
        "        mixing=\"concat_and_mix\",#trial.suggest_categorical(\"mixing\", [\"concat\", \"concat_and_mix\"]),#\"separate\", \"interp_only\", \"na\"]),\n",
        "        mse_weight=trial.suggest_float(\"mse_weight\",1,6),\n",
        "        #n=trial.suggest_categorical(\"n\", [8,16,32,64,128]),\n",
        "        net='hetvae', \n",
        "        niters=1000, \n",
        "        norm=True, \n",
        "        normalize_input='znorm', \n",
        "        num_ref_points=trial.suggest_categorical(\"num_ref_points\", [8,16,32,64,128]),\n",
        "        rec_hidden=trial.suggest_categorical(\"rec_hidden\", [8,16,32,64,128]),\n",
        "        recon_loss=False, \n",
        "        sample_tp= trial.suggest_float(\"sample_tp\", 0.1,0.9), # will be ignored\n",
        "        save=True, \n",
        "        seed=0, \n",
        "        shuffle=True, \n",
        "        std=0.1, \n",
        "        var_per_dim=False, \n",
        "        width=trial.suggest_categorical(\"width\", [8,16,32,64,128,256])\n",
        "    )\n",
        "\n",
        "    return args"
      ],
      "metadata": {
        "id": "wjY9HgEIIo0S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "FILES = glob('/content/hetvae/data/CAT/*/*')\n",
        "#FILES = glob('/content/hetvae/data/CAT/*/*')[:50]\n",
        "\n",
        "\n",
        "DIM = 1"
      ],
      "metadata": {
        "id": "O_WWnh_TOXrt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import contextmanager\n",
        "import sys, os\n",
        "\n",
        "@contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:  \n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout"
      ],
      "metadata": {
        "id": "dyOMLFtpOeuW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    args = define_model_args(trial)\n",
        "\n",
        "    seed = args.seed\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # dataset hyperparams\n",
        "    num_samples=trial.suggest_int(\"num_samples\", 1,10)\n",
        "    # normalize choices for optuna\n",
        "    x_by_range = trial.suggest_categorical(\"x_by_range\", [True, False])\n",
        "    y_by_range = trial.suggest_categorical(\"y_by_range\", [True, False])\n",
        "    #normalize_y = trial.suggest_categorical(\"normalize_y\", [\"all\", \"individual\"])\n",
        "\n",
        "    with suppress_stdout():\n",
        "        Catalina = DataSet().add_files(FILES).files_to_numpy().handle_dups().prune_graham().resample_dataset(num_samples=num_samples) \\\n",
        "            .normalize(y_by_range=y_by_range, x_by_range=x_by_range).set_union_x().zero_fill().make_masks(frac=args.sample_tp)\n",
        "    \n",
        "    LightCurves = np.concatenate((Catalina.dataset, Catalina.subsampled_mask[:,:,np.newaxis], Catalina.recon_mask[:,:,np.newaxis]), axis=-1) # format the masks for the model \n",
        "\n",
        "    training, valid = np.split(LightCurves, [int(np.floor(0.8*len(LightCurves)))])# shuffle?\n",
        "    \n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(training, batch_size=args.batch_size)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=args.batch_size)\n",
        "    \n",
        "    \n",
        "    net = models.load_network(args, DIM, torch.Tensor(Catalina.union_x)) # , device=\"cuda\"\n",
        "    \n",
        "\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\",\"RMSprop\"])\n",
        "    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr=args.lr)\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        train(net, optimizer, epoch, train_loader, args, device=device)\n",
        "        nll_loss = my_utils.evaluate(net, valid_loader, device=device)\n",
        "        trial.report(nll_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return nll_loss"
      ],
      "metadata": {
        "id": "cKFtWI3nO1fY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NVnB2L2PtWo",
        "outputId": "d9885df5-caa3-40db-c2d8-4c5d2634c245"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 01:39:31,730]\u001b[0m A new study created in memory with name: no-name-6031f380-efeb-400e-8f68-7517a64178ad\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=10, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvzSPWzXPuqB",
        "outputId": "b97d816e-2648-4e80-d2c6-664d6ec3140f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 0.3729, avg nll: 0.5515, avg kl: 0.4081, mse: 0.047880, mae: 0.169447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, optimizer,epoch, train_loader, args, device=\"cuda\"):\n",
        "      \n",
        "      train_loss = 0.\n",
        "      train_n = 0.\n",
        "      avg_loglik, avg_kl, mse, mae = 0., 0., 0., 0.\n",
        "      for i, train_batch in enumerate(train_loader):\n",
        "          batch_len = train_batch.shape[0] \n",
        "          train_batch = train_batch.to(device)\n",
        "          x = train_batch[:,:,0]\n",
        "          y = train_batch[:,:,1:2]\n",
        "          \n",
        "          subsampled_mask = train_batch[:,:,3:4]\n",
        "          recon_mask = train_batch[:,:,4:]\n",
        "          sample_weight = train_batch[:,:,2:3]\n",
        "          seqlen = train_batch.size(1) \n",
        "          # subsampled flux values and their corresponding masks....\n",
        "          context_y = torch.cat((\n",
        "              y * subsampled_mask, subsampled_mask\n",
        "          ), -1) \n",
        "          recon_context_y = torch.cat((            # flux values with only recon_mask values showing\n",
        "                  y * recon_mask, recon_mask\n",
        "              ), -1)\n",
        "          \n",
        "    # #   def compute_unsupervised_loss(self, context_x, context_y, target_x, target_y, num_samples=1, beta=1):\n",
        "          loss_info = net.compute_unsupervised_loss(\n",
        "              x, # context_x, times\n",
        "              context_y,           \n",
        "              x, # target_x, same times, can project to arbitrary times \n",
        "              recon_context_y,\n",
        "              num_samples=args.k_iwae,\n",
        "              beta=1,\n",
        "              #sample_weight = sample_weight   # default is 1. (no errors provided)\n",
        "\n",
        "          )\n",
        "          optimizer.zero_grad()\n",
        "          loss_info.composite_loss.backward()\n",
        "          optimizer.step()\n",
        "          #scheduler.step()\n",
        "          train_loss += loss_info.composite_loss.item() * batch_len\n",
        "          avg_loglik += loss_info.loglik * batch_len\n",
        "          avg_kl += loss_info.kl * batch_len\n",
        "          mse += loss_info.mse * batch_len\n",
        "          mae += loss_info.mae * batch_len\n",
        "          train_n += batch_len\n",
        "      \n",
        "      \n",
        "      if epoch % 100 == 0:\n",
        "          print(\n",
        "              'Iter: {}, train loss: {:.4f}, avg nll: {:.4f}, avg kl: {:.4f}, '\n",
        "              'mse: {:.6f}, mae: {:.6f}'.format(\n",
        "                  epoch,\n",
        "                  train_loss / train_n,\n",
        "                  -avg_loglik / train_n,\n",
        "                  avg_kl / train_n,\n",
        "                  mse / train_n,\n",
        "                  mae / train_n\n",
        "              )\n",
        "          )\n",
        "      "
      ],
      "metadata": {
        "id": "9_jZW7NrPy-5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optuna.visualization.plot_param_importances(study)"
      ],
      "metadata": {
        "id": "8rI82ipQP4SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "oQb_oEElP40j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_slice(study, params=[\"optimizer\"])"
      ],
      "metadata": {
        "id": "RobOqJGDP7QP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}