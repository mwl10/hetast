{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catalina_optuna.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPzFQw6enQhiQiWJ7qQ+jwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwl10/hetvae/blob/errors/src/catalina_optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CLSc_lZ7IhyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c1d53bb-32a0-41f8-d2d0-40332bfda438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hetvae'...\n",
            "remote: Enumerating objects: 3957, done.\u001b[K\n",
            "remote: Counting objects: 100% (993/993), done.\u001b[K\n",
            "remote: Compressing objects: 100% (835/835), done.\u001b[K\n",
            "remote: Total 3957 (delta 194), reused 247 (delta 158), pack-reused 2964\u001b[K\n",
            "Receiving objects: 100% (3957/3957), 39.00 MiB | 3.65 MiB/s, done.\n",
            "Resolving deltas: 100% (1139/1139), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alembic==1.7.7\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs==21.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (21.4.0)\n",
            "Collecting autopage==0.5.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting backports.functools-lru-cache==1.6.4\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting cliff==3.10.1\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting cmaes==0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cmd2==2.3.3\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 75.3 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorlog==6.6.0\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: greenlet==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata==4.11.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources==5.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.7.1)\n",
            "Collecting Mako==1.2.0\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting numpy==1.21.0\n",
            "  Downloading numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 92.1 MB/s \n",
            "\u001b[?25hCollecting optuna==2.10.0\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 87.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging==21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (21.3)\n",
            "Collecting pbr==5.9.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 90.6 MB/s \n",
            "\u001b[?25hCollecting pip==22.1.1\n",
            "  Downloading pip-22.1.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prettytable==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (3.3.0)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (3.0.9)\n",
            "Collecting pyperclip==1.8.2\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.7 MB/s \n",
            "\u001b[?25hCollecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting setuptools==62.3.2\n",
            "  Downloading setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.9 MB/s \n",
            "\u001b[?25hCollecting SQLAlchemy==1.4.36\n",
            "  Downloading SQLAlchemy-1.4.36-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 75.6 MB/s \n",
            "\u001b[?25hCollecting stevedore==3.5.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (4.64.0)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (0.2.5)\n",
            "Requirement already satisfied: wheel==0.37.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (0.37.1)\n",
            "Requirement already satisfied: zipp==3.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 31)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2==2.3.3->-r requirements.txt (line 7)) (4.1.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=d772de891caae6f95768eee1648a4edbe98daa3e859d18bcd34706dfbf6d249c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, MarkupSafe, stevedore, SQLAlchemy, PyYAML, numpy, Mako, cmd2, autopage, scipy, colorlog, cmaes, cliff, alembic, setuptools, pip, optuna, colorama, backports.functools-lru-cache\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.37\n",
            "    Uninstalling SQLAlchemy-1.4.37:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.37\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.0 MarkupSafe-2.1.1 PyYAML-6.0 SQLAlchemy-1.4.36 alembic-1.7.7 autopage-0.5.0 backports.functools-lru-cache-1.6.4 cliff-3.10.1 cmaes-0.8.2 cmd2-2.3.3 colorama-0.4.4 colorlog-6.6.0 numpy-1.21.0 optuna-2.10.0 pbr-5.9.0 pip-22.1.1 pyperclip-1.8.2 scipy-1.7.3 setuptools-62.3.2 stevedore-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "os.chdir('/content')\n",
        "! git clone --branch errors https://github.com/mwl10/hetvae\n",
        "os.chdir('/content/hetvae')\n",
        "! pip install -r requirements.txt\n",
        "os.chdir('/content/hetvae/src')\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import models\n",
        "from argparse import Namespace\n",
        "import torch.optim as optim\n",
        "import utils\n",
        "import my_utils\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import importlib\n",
        "import vae_models\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from dataset import DataSet\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_args(trial):\n",
        "\n",
        "    args = Namespace(\n",
        "        batch_size = 8, #trial.suggest_categorical(\"batch_size\", [8,16,32]),\n",
        "        bound_variance = True,\n",
        "        const_var = False,\n",
        "        dataset='toy',\n",
        "        dropout = trial.suggest_float(\"dropout\", 0.0,0.5),\n",
        "        elbo_weight = trial.suggest_float(\"elbo_weight\", 0.0, 2.0),\n",
        "        embed_time = trial.suggest_categorical(\"embed_time\", [8,16,32,64]),\n",
        "        enc_num_heads=4,#trial.suggest_categorical(\"enc_num_heads\", [1,2,4,8]),\n",
        "        intensity=True,\n",
        "        k_iwae=1,\n",
        "        kl_annealing=False,#trial.suggest_categorical(\"kl_annealing\",False),\n",
        "        kl_zero=False, \n",
        "        latent_dim=128,#trial.suggest_categorical(\"latent_dim\", [8,16,32,64,128]),\n",
        "        lr=trial.suggest_float(\"lr\", 1e-7, 1e-1, log=True),\n",
        "        mixing=\"concat_and_mix\",#trial.suggest_categorical(\"mixing\", [\"concat\", \"concat_and_mix\"]),#\"separate\", \"interp_only\", \"na\"]),\n",
        "        mse_weight=trial.suggest_float(\"mse_weight\",1,6),\n",
        "        #n=trial.suggest_categorical(\"n\", [8,16,32,64,128]),\n",
        "        net='hetvae', \n",
        "        niters=1000, \n",
        "        norm=True, \n",
        "        normalize_input='znorm', \n",
        "        num_ref_points=trial.suggest_categorical(\"num_ref_points\", [64]),\n",
        "        rec_hidden=trial.suggest_categorical(\"rec_hidden\", [16,32,64]),\n",
        "        recon_loss=False, \n",
        "        sample_tp= 0.5, #trial.suggest_float(\"sample_tp\", 0.1,0.9), # will be ignored\n",
        "        save=True, \n",
        "        seed=0, \n",
        "        shuffle=True, \n",
        "        std=0.1, \n",
        "        var_per_dim=False, \n",
        "        width=trial.suggest_categorical(\"width\", [32,64,128])\n",
        "    )\n",
        "\n",
        "    return args"
      ],
      "metadata": {
        "id": "wjY9HgEIIo0S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "FILES = glob('/content/hetvae/data/CAT/*/*')\n",
        "#FILES = glob('/content/hetvae/data/CAT/*/*')[:50]\n",
        "\n",
        "\n",
        "DIM = 1"
      ],
      "metadata": {
        "id": "O_WWnh_TOXrt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import contextmanager\n",
        "import sys, os\n",
        "\n",
        "@contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:  \n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout"
      ],
      "metadata": {
        "id": "dyOMLFtpOeuW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agn_df = pd.read_csv('/content/hetvae/data/AGN_1H2106-099/1H2106-099_latest_lcs_pyroa.csv')\n",
        "# handle formatting for new AGN\n",
        "lcs = []\n",
        "for lc_df in agn_df.groupby('Filter'):\n",
        "    lc = lc_df[1][['MJD', 'Flux', 'Error']].to_numpy()\n",
        "    lcs.append(lc)\n",
        "# lcs[0] = lcs[0][lcs[0][:,0].argsort()]\n",
        "# lcs[0] = np.concatenate((lcs[0][:10], lcs[0][410:]))\n",
        "lcs = [lcs[0]]\n"
      ],
      "metadata": {
        "id": "BDzmoJsqUP7B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    args = define_model_args(trial)\n",
        "\n",
        "    seed = args.seed\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # dataset hyperparams\n",
        "    num_samples=trial.suggest_int(\"num_samples\", 1,6)\n",
        "    # normalize choices for optuna\n",
        "    x_by_range = trial.suggest_categorical(\"x_by_range\", [True, False])\n",
        "    y_by_range = False#trial.suggest_categorical(\"y_by_range\", [True, False])\n",
        "    #normalize_y = trial.suggest_categorical(\"normalize_y\", [\"all\", \"individual\"])\n",
        "\n",
        "    with suppress_stdout():\n",
        "        # AGN = DataSet().add_files(FILES).files_to_numpy().handle_dups().prune_graham().resample_dataset(num_samples=num_samples) \\\n",
        "        #     .normalize(y_by_range=y_by_range, x_by_range=x_by_range).set_union_x().zero_fill().make_masks(frac=args.sample_tp)\n",
        "        AGN = DataSet()\n",
        "        AGN.dataset = lcs\n",
        "        AGN = AGN.handle_dups().prune_outliers().resample_dataset(num_samples=num_samples) \\\n",
        "             .normalize(y_by_range=y_by_range, x_by_range=x_by_range).set_union_x().zero_fill().make_masks(frac=args.sample_tp)\n",
        "\n",
        "\n",
        "\n",
        "    LightCurves = AGN.dataset\n",
        "\n",
        "    training, valid = np.split(LightCurves, [int(np.floor(0.8*len(LightCurves)))])# shuffle?\n",
        "    \n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(training, batch_size=args.batch_size)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=args.batch_size)\n",
        "    \n",
        "    \n",
        "    net = models.load_network(args, DIM, torch.Tensor(AGN.union_x)) # , device=\"cuda\"\n",
        "    \n",
        "\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\"])\n",
        "    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr=args.lr)\n",
        "    frac = trial.suggest_float(\"sample_tp\", 0.1,0.9)\n",
        "    for epoch in range(EPOCHS):\n",
        "        nll_loss, mse = my_utils.train(net, optimizer, epoch, train_loader, args, device=device, frac=frac)\n",
        "        #nll_loss = my_utils.evaluate(net, valid_loader, device=device)\n",
        "        trial.report(nll_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return nll_loss"
      ],
      "metadata": {
        "id": "cKFtWI3nO1fY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NVnB2L2PtWo",
        "outputId": "54655517-c978-4645-e41e-92a4a828b3a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 17:13:06,140]\u001b[0m A new study created in memory with name: no-name-3328574b-bb12-4d3a-ae6a-a420bd38545e\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=10, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "EvzSPWzXPuqB",
        "outputId": "80558c82-ed20-4dbb-e738-f69cd73268fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 4.8142, avg nll: 1.6219, avg kl: 1.6879, mse: 1.042513, mae: 0.855909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 17:13:27,650]\u001b[0m Trial 0 finished with value: 1.4127589464187622 and parameters: {'dropout': 0.3599044428458503, 'elbo_weight': 1.9123338076707597, 'embed_time': 64, 'lr': 0.00023158498431509624, 'mse_weight': 1.333118335595446, 'num_ref_points': 128, 'rec_hidden': 64, 'width': 64, 'num_samples': 4, 'x_by_range': False, 'optimizer': 'Adam', 'sample_tp': 0.8876687004243902}. Best is trial 0 with value: 1.4127589464187622.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 2.7874, avg nll: 1.5374, avg kl: 0.6205, mse: 1.013716, mae: 0.846237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 17:13:50,377]\u001b[0m Trial 1 finished with value: 1.4736545085906982 and parameters: {'dropout': 0.42880324848285345, 'elbo_weight': 0.32179563504461317, 'embed_time': 8, 'lr': 0.000575385430744067, 'mse_weight': 2.2419644037783217, 'num_ref_points': 64, 'rec_hidden': 16, 'width': 128, 'num_samples': 5, 'x_by_range': True, 'optimizer': 'Adadelta', 'sample_tp': 0.1391064782851509}. Best is trial 0 with value: 1.4127589464187622.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 3.5249, avg nll: 1.5516, avg kl: 0.7760, mse: 0.998715, mae: 0.838576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-17 17:16:30,538]\u001b[0m Trial 2 finished with value: 1.5498145818710327 and parameters: {'dropout': 0.07953097325055608, 'elbo_weight': 0.6518073566103277, 'embed_time': 64, 'lr': 3.4757442786340244e-06, 'mse_weight': 2.4661865419478164, 'num_ref_points': 64, 'rec_hidden': 16, 'width': 128, 'num_samples': 6, 'x_by_range': False, 'optimizer': 'Adadelta', 'sample_tp': 0.5645767100115142}. Best is trial 0 with value: 1.4127589464187622.\u001b[0m\n",
            "\u001b[33m[W 2022-06-17 17:16:31,278]\u001b[0m Trial 3 failed because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.42 GiB (GPU 0; 15.78 GiB total capacity; 9.69 GiB already allocated; 2.28 GiB free; 12.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-6-879646592e0d>\", line 43, in objective\n",
            "    nll_loss, mse = my_utils.train(net, optimizer, epoch, train_loader, args, device=device, frac=frac)\n",
            "  File \"/content/hetvae/src/my_utils.py\", line 56, in train\n",
            "    loss_info.composite_loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 2.42 GiB (GPU 0; 15.78 GiB total capacity; 9.69 GiB already allocated; 2.28 GiB free; 12.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-696c78aafaeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-879646592e0d>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample_tp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;31m#nll_loss = my_utils.evaluate(net, valid_loader, device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/my_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, epoch, train_loader, args, device, frac, errors)\u001b[0m\n\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mloss_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposite_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.42 GiB (GPU 0; 15.78 GiB total capacity; 9.69 GiB already allocated; 2.28 GiB free; 12.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [I 2022-06-17 16:55:13,210] Trial 3 finished with value: 0.09719855338335037 and parameters: {'dropout': 0.02418752335062102, 'elbo_weight': 1.1061943368326204, 'embed_time': 16, 'lr': 4.212141191372822e-05, 'mse_weight': 5.108416562407145, 'rec_hidden': 128, 'num_samples': 6, 'x_by_range': True, 'optimizer': 'Adam', 'sample_tp': 0.1979453313080004}. Best is trial 3 with value: 0.09719855338335037.\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)"
      ],
      "metadata": {
        "id": "8rI82ipQP4SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "oQb_oEElP40j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_slice(study, params=[\"optimizer\"])"
      ],
      "metadata": {
        "id": "RobOqJGDP7QP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}