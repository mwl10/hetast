{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catalina_optuna.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPKzLGsMYJAeIKSHA0HtCcr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwl10/hetvae/blob/errors/src/catalina_optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CLSc_lZ7IhyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ec91b38-3f90-4181-898b-66395ada1eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hetvae'...\n",
            "remote: Enumerating objects: 4039, done.\u001b[K\n",
            "remote: Counting objects: 100% (1075/1075), done.\u001b[K\n",
            "remote: Compressing objects: 100% (889/889), done.\u001b[K\n",
            "remote: Total 4039 (delta 247), reused 293 (delta 186), pack-reused 2964\u001b[K\n",
            "Receiving objects: 100% (4039/4039), 46.21 MiB | 31.07 MiB/s, done.\n",
            "Resolving deltas: 100% (1192/1192), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alembic==1.7.7\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs==21.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (21.4.0)\n",
            "Collecting autopage==0.5.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting backports.functools-lru-cache==1.6.4\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting cliff==3.10.1\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting cmaes==0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cmd2==2.3.3\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorlog==6.6.0\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: greenlet==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata==4.11.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources==5.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.7.1)\n",
            "Collecting Mako==1.2.0\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting numpy==1.21.0\n",
            "  Downloading numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 81.8 MB/s \n",
            "\u001b[?25hCollecting optuna==2.10.0\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 98.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging==21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (21.3)\n",
            "Collecting pbr==5.9.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 96.1 MB/s \n",
            "\u001b[?25hCollecting pip==22.1.1\n",
            "  Downloading pip-22.1.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prettytable==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (3.3.0)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (3.0.9)\n",
            "Collecting pyperclip==1.8.2\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.8 MB/s \n",
            "\u001b[?25hCollecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting setuptools==62.3.2\n",
            "  Downloading setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 77.3 MB/s \n",
            "\u001b[?25hCollecting SQLAlchemy==1.4.36\n",
            "  Downloading SQLAlchemy-1.4.36-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 65.0 MB/s \n",
            "\u001b[?25hCollecting stevedore==3.5.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (4.64.0)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (0.2.5)\n",
            "Requirement already satisfied: wheel==0.37.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (0.37.1)\n",
            "Requirement already satisfied: zipp==3.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 31)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2==2.3.3->-r requirements.txt (line 7)) (4.1.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=e4f4966988ce8207bb93b7b64eae723058a9b5cfc2eda30c9cc1f00ebe8b72b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, MarkupSafe, stevedore, SQLAlchemy, PyYAML, numpy, Mako, cmd2, autopage, scipy, colorlog, cmaes, cliff, alembic, setuptools, pip, optuna, colorama, backports.functools-lru-cache\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.37\n",
            "    Uninstalling SQLAlchemy-1.4.37:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.37\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.0 MarkupSafe-2.1.1 PyYAML-6.0 SQLAlchemy-1.4.36 alembic-1.7.7 autopage-0.5.0 backports.functools-lru-cache-1.6.4 cliff-3.10.1 cmaes-0.8.2 cmd2-2.3.3 colorama-0.4.4 colorlog-6.6.0 numpy-1.21.0 optuna-2.10.0 pbr-5.9.0 pip-22.1.1 pyperclip-1.8.2 scipy-1.7.3 setuptools-62.3.2 stevedore-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "os.chdir('/content')\n",
        "! git clone --branch errors https://github.com/mwl10/hetvae\n",
        "os.chdir('/content/hetvae')\n",
        "! pip install -r requirements.txt\n",
        "os.chdir('/content/hetvae/src')\n",
        "import numpy as np\n",
        "import torch\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.optim as optim\n",
        "import models\n",
        "from argparse import Namespace\n",
        "import torch.optim as optim\n",
        "import utils\n",
        "import my_utils\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import importlib\n",
        "import vae_models\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from dataset import DataSet\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_args(trial):\n",
        "\n",
        "    args = Namespace(\n",
        "        batch_size = 8, #trial.suggest_categorical(\"batch_size\", [8,16,32]),\n",
        "        bound_variance = True,\n",
        "        const_var = False,\n",
        "        dataset='toy',\n",
        "        dropout = 0.3,#trial.suggest_float(\"dropout\", 0.0,0.5),\n",
        "        elbo_weight = trial.suggest_float(\"elbo_weight\", 0.0, 2.0),\n",
        "        embed_time = trial.suggest_categorical(\"embed_time\", [16,32,64]),\n",
        "        enc_num_heads=trial.suggest_categorical(\"enc_num_heads\", [4,8,16]),\n",
        "        intensity=True,\n",
        "        k_iwae=1,\n",
        "        kl_annealing=False,#trial.suggest_categorical(\"kl_annealing\",False),\n",
        "        kl_zero=False, \n",
        "        latent_dim=trial.suggest_categorical(\"latent_dim\", [64,128]),\n",
        "        lr=trial.suggest_float(\"lr\", 1e-7, 1e-1, log=True),\n",
        "        mixing=\"concat_and_mix\",#trial.suggest_categorical(\"mixing\", [\"concat\", \"concat_and_mix\"]),#\"separate\", \"interp_only\", \"na\"]),\n",
        "        mse_weight=trial.suggest_float(\"mse_weight\",1,20),\n",
        "        #n=trial.suggest_categorical(\"n\", [8,16,32,64,128]),\n",
        "        net='hetvae', \n",
        "        niters=1000, \n",
        "        norm=True, \n",
        "        normalize_input='znorm', \n",
        "        num_ref_points=128#trial.suggest_categorical(\"num_ref_points\", [64, 128,256]),\n",
        "        rec_hidden=trial.suggest_categorical(\"rec_hidden\", [32,64, 128]),\n",
        "        recon_loss=False, \n",
        "        sample_tp= trial.suggest_float(\"sample_tp\", 0.1,0.9), # will be ignored\n",
        "        save=False, \n",
        "        seed=0, \n",
        "        shuffle=True, \n",
        "        std=0.1, \n",
        "        var_per_dim=False, \n",
        "        width=trial.suggest_categorical(\"width\", [128,256])\n",
        "    )\n",
        "\n",
        "    return args"
      ],
      "metadata": {
        "id": "wjY9HgEIIo0S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 500\n",
        "#FILES = glob('/content/hetvae/data/CAT/*/*')\n",
        "#FILES = glob('/content/hetvae/data/CAT/*/*')[:50]\n",
        "\n",
        "FILES = glob('/content/hetvae/data/CAT/*/*')[:2]\n",
        "DIM = 1"
      ],
      "metadata": {
        "id": "O_WWnh_TOXrt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import contextmanager\n",
        "import sys, os\n",
        "\n",
        "@contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:  \n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout"
      ],
      "metadata": {
        "id": "g88SFziboC59"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    args = define_model_args(trial)\n",
        "\n",
        "    seed = args.seed\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # dataset hyperparams\n",
        "    num_samples=trial.suggest_int(\"num_samples\", 1,6)\n",
        "    # normalize choices for optuna\n",
        "    #x_by_range = trial.suggest_categorical(\"x_by_range\", [True, False])\n",
        "    #y_by_range = False #trial.suggest_categorical(\"y_by_range\", [True, False])\n",
        "    #normalize_y = trial.suggest_categorical(\"normalize_y\", [\"all\", \"individual\"])\n",
        "\n",
        "    with suppress_stdout():\n",
        "        # AGN = DataSet().add_files(FILES).files_to_numpy().handle_dups().prune_graham().resample_dataset(num_samples=num_samples) \\\n",
        "        #     .normalize(y_by_range=y_by_range, x_by_range=x_by_range).set_union_x().zero_fill().make_masks(frac=args.sample_tp)\n",
        "        # AGN = DataSet()\n",
        "        # AGN.dataset = lcs\n",
        "        # AGN = AGN.handle_dups().prune_outliers().resample_dataset(num_samples=num_samples) \\\n",
        "        #      .normalize(y_by_range=y_by_range, x_by_range=x_by_range).set_union_x().zero_fill().make_masks(frac=args.sample_tp)\n",
        "        Catalina = DataSet() \\\n",
        "                .add_files(FILES) \\\n",
        "                .files_to_numpy() \\\n",
        "                .handle_dups() \\\n",
        "                .prune_graham(plot=False, index=10, std_threshold=1) \\\n",
        "                .resample_dataset(num_samples=3) \\\n",
        "                .normalize(normalize_x = 'no', x_by_range=False) \\\n",
        "                .reorder() \\\n",
        "                .set_union_x() \\\n",
        "                .zero_fill() \\\n",
        "                .error_to_sample_weight()\n",
        "\n",
        "\n",
        "    LightCurves = Catalina.dataset\n",
        "\n",
        "    training, valid = np.split(LightCurves, [int(np.floor(1*len(LightCurves)))])# shuffle?\n",
        "    \n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(training, batch_size=args.batch_size)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=args.batch_size)\n",
        "    \n",
        "    \n",
        "    net = models.load_network(args, DIM, torch.Tensor(Catalina.union_x)) # , device=\"cuda\"\n",
        "    \n",
        "\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\"])\n",
        "    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr=args.lr)\n",
        "    frac = 0.4#trial.suggest_float(\"sample_tp\", 0.1,0.9)\n",
        "    step_size = trial.suggest_categorical(\"step_size\", [200,300,400,500])\n",
        "    gamma = trial.suggest_float(\"gamma\",0,1)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=gamma, step_size=step_size)\n",
        "    beta = trial.suggest_float(\"beta\", 0,1)\n",
        "    for epoch in range(EPOCHS):\n",
        "        nll_loss, mse = my_utils.train(net, optimizer, epoch, train_loader, args, device=device, frac=frac, beta=beta)\n",
        "        #nll_loss = my_utils.evaluate(net, valid_loader, device=device)\n",
        "        trial.report(nll_loss, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return nll_loss"
      ],
      "metadata": {
        "id": "cKFtWI3nO1fY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NVnB2L2PtWo",
        "outputId": "bc9b5326-03aa-4895-e9b7-3b25ef3ddb38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-23 08:15:37,826]\u001b[0m A new study created in memory with name: no-name-778f6f5f-a22c-4908-8f5a-a280e57df431\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EvzSPWzXPuqB",
        "outputId": "eef1a66e-1dbf-444d-bbc1-a132f38d90f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 25.3136, avg nll: 1.5712, avg kl: 7.2040, mse: 0.968706, mae: 0.788234\n",
            "Iter: 100, train loss: 13.5077, avg nll: 1.4596, avg kl: 0.0049, mse: 0.998239, mae: 0.820888\n",
            "Iter: 200, train loss: 13.6465, avg nll: 1.4212, avg kl: 0.0062, mse: 1.017059, mae: 0.824017\n",
            "Iter: 300, train loss: 12.5543, avg nll: 1.3625, avg kl: 0.0067, mse: 0.926468, mae: 0.786991\n",
            "Iter: 400, train loss: 13.4512, avg nll: 1.4287, avg kl: 0.0061, mse: 0.997931, mae: 0.810043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-23 08:16:37,417]\u001b[0m Trial 0 finished with value: 1.4359208345413208 and parameters: {'elbo_weight': 1.788725435572976, 'embed_time': 16, 'enc_num_heads': 8, 'latent_dim': 32, 'lr': 0.0018109242465550776, 'mse_weight': 10.908011412354638, 'num_ref_points': 256, 'rec_hidden': 128, 'sample_tp': 0.46331654711579984, 'width': 256, 'num_samples': 3, 'optimizer': 'Adam', 'step_size': 200, 'gamma': 0.8782403593597651, 'beta': 0.9263155894762508}. Best is trial 0 with value: 1.4359208345413208.\u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 4.0759, avg nll: 1.5769, avg kl: 0.8412, mse: 0.969767, mae: 0.796417\n",
            "Iter: 100, train loss: 3.5741, avg nll: 1.4598, avg kl: 0.0040, mse: 0.998377, mae: 0.821017\n",
            "Iter: 200, train loss: 3.5482, avg nll: 1.4149, avg kl: 0.0074, mse: 1.017097, mae: 0.823402\n",
            "Iter: 300, train loss: 3.3307, avg nll: 1.3615, avg kl: 0.0026, mse: 0.929827, mae: 0.788144\n",
            "Iter: 400, train loss: 3.5384, avg nll: 1.4299, avg kl: 0.0009, mse: 1.001287, mae: 0.810887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-23 08:16:52,233]\u001b[0m Trial 1 finished with value: 1.4322580099105835 and parameters: {'elbo_weight': 1.3060908332374406, 'embed_time': 32, 'enc_num_heads': 8, 'latent_dim': 32, 'lr': 0.0005523697027954683, 'mse_weight': 1.6682566076390137, 'num_ref_points': 64, 'rec_hidden': 128, 'sample_tp': 0.6362539135959181, 'width': 128, 'num_samples': 4, 'optimizer': 'Adam', 'step_size': 500, 'gamma': 0.6443410820064809, 'beta': 0.36277203717784456}. Best is trial 1 with value: 1.4322580099105835.\u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 3.6765, avg nll: 1.5970, avg kl: 3.2343, mse: 0.984947, mae: 0.789148\n",
            "Iter: 100, train loss: 3.0475, avg nll: 1.4593, avg kl: 0.0027, mse: 0.998184, mae: 0.820865\n",
            "Iter: 200, train loss: 3.0571, avg nll: 1.4169, avg kl: 0.0068, mse: 1.017073, mae: 0.823633\n",
            "Iter: 300, train loss: 2.8402, avg nll: 1.3622, avg kl: 0.0043, mse: 0.929401, mae: 0.788196\n",
            "Iter: 400, train loss: 3.0401, avg nll: 1.4316, avg kl: 0.0152, mse: 1.002972, mae: 0.809478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-23 08:17:07,216]\u001b[0m Trial 2 finished with value: 1.4366261959075928 and parameters: {'elbo_weight': 0.6963098079958869, 'embed_time': 32, 'enc_num_heads': 4, 'latent_dim': 32, 'lr': 0.0028614737131495093, 'mse_weight': 2.0345906934447084, 'num_ref_points': 128, 'rec_hidden': 16, 'sample_tp': 0.7413764170904419, 'width': 128, 'num_samples': 1, 'optimizer': 'Adam', 'step_size': 200, 'gamma': 0.32500861437405604, 'beta': 0.24886629341412403}. Best is trial 1 with value: 1.4322580099105835.\u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 16.6096, avg nll: 1.5770, avg kl: 3.3310, mse: 0.966031, mae: 0.789522\n",
            "Iter: 100, train loss: 16.6622, avg nll: 1.5270, avg kl: 1.0577, mse: 1.005043, mae: 0.819292\n",
            "Iter: 200, train loss: 16.7865, avg nll: 1.4404, avg kl: 0.4994, mse: 1.031181, mae: 0.829925\n",
            "Iter: 300, train loss: 15.1870, avg nll: 1.3651, avg kl: 0.0823, mse: 0.930577, mae: 0.788898\n",
            "Iter: 400, train loss: 16.2886, avg nll: 1.4332, avg kl: 0.0563, mse: 1.002043, mae: 0.812081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-23 08:17:32,656]\u001b[0m Trial 3 finished with value: 1.4310946464538574 and parameters: {'elbo_weight': 1.6069998945058062, 'embed_time': 64, 'enc_num_heads': 8, 'latent_dim': 32, 'lr': 2.3348821261761858e-05, 'mse_weight': 13.946685691008316, 'num_ref_points': 128, 'rec_hidden': 16, 'sample_tp': 0.471814239288029, 'width': 256, 'num_samples': 1, 'optimizer': 'Adam', 'step_size': 500, 'gamma': 0.47047385944060394, 'beta': 0.11253024919988519}. Best is trial 3 with value: 1.4310946464538574.\u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 13.7985, avg nll: 1.6491, avg kl: 2.5468, mse: 0.965401, mae: 0.792662\n",
            "Iter: 100, train loss: 14.3332, avg nll: 1.7456, avg kl: 2.5310, mse: 1.009154, mae: 0.820296\n",
            "Iter: 200, train loss: 14.7205, avg nll: 1.6988, avg kl: 2.7276, mse: 1.038419, mae: 0.835465\n",
            "Iter: 300, train loss: 13.3196, avg nll: 1.5443, avg kl: 2.4548, mse: 0.939795, mae: 0.791627\n",
            "Iter: 400, train loss: 14.1568, avg nll: 1.6755, avg kl: 2.3717, mse: 1.017304, mae: 0.819559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-06-23 08:18:10,093]\u001b[0m Trial 4 finished with value: 1.668915033340454 and parameters: {'elbo_weight': 1.4736498450895028, 'embed_time': 64, 'enc_num_heads': 16, 'latent_dim': 64, 'lr': 1.4552052832461638e-07, 'mse_weight': 9.30854052419444, 'num_ref_points': 64, 'rec_hidden': 32, 'sample_tp': 0.24541181082896957, 'width': 256, 'num_samples': 5, 'optimizer': 'Adam', 'step_size': 300, 'gamma': 0.9274219271816682, 'beta': 0.6346182792730116}. Best is trial 3 with value: 1.4310946464538574.\u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:10,312]\u001b[0m Trial 5 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 13.1007, avg nll: 1.5519, avg kl: 1.4383, mse: 0.965909, mae: 0.794288\n",
            "Iter: 0, train loss: 4.9029, avg nll: 1.5567, avg kl: 1.6622, mse: 0.965407, mae: 0.789836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:10,750]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:11,166]\u001b[0m Trial 7 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 24.5577, avg nll: 1.6726, avg kl: 7.3183, mse: 0.964401, mae: 0.792093\n",
            "Iter: 0, train loss: 51.3694, avg nll: 1.5488, avg kl: 25.8743, mse: 0.964470, mae: 0.790898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:11,467]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:11,563]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:11,676]\u001b[0m Trial 10 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 17.9679, avg nll: 1.6994, avg kl: 2.5405, mse: 0.964793, mae: 0.789857\n",
            "Iter: 0, train loss: 13.8713, avg nll: 1.6085, avg kl: 5.2166, mse: 0.965822, mae: 0.789152\n",
            "Iter: 0, train loss: 8.1529, avg nll: 1.5340, avg kl: 1.8911, mse: 0.966394, mae: 0.789435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:11,815]\u001b[0m Trial 11 pruned. \u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:11,955]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[32m[I 2022-06-23 08:18:12,020]\u001b[0m Trial 13 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0, train loss: 17.3267, avg nll: 1.5340, avg kl: 1.8911, mse: 0.966394, mae: 0.789435\n",
            "Iter: 0, train loss: 13.9066, avg nll: 1.6582, avg kl: 0.9782, mse: 0.969561, mae: 0.796351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/hetvae/src/dataset.py:328: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  self.dataset[:,:,2] = 1. / self.dataset[:,:,2]\n",
            "\u001b[33m[W 2022-06-23 08:18:12,320]\u001b[0m Trial 14 failed because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 2.59 GiB (GPU 0; 15.90 GiB total capacity; 10.39 GiB already allocated; 1.99 GiB free; 12.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-6-cdd22d0f5542>\", line 48, in objective\n",
            "    nll_loss, mse = my_utils.train(net, optimizer, epoch, train_loader, args, device=device, frac=frac, beta=beta)\n",
            "  File \"/content/hetvae/src/my_utils.py\", line 56, in train\n",
            "    loss_info.composite_loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 2.59 GiB (GPU 0; 15.90 GiB total capacity; 10.39 GiB already allocated; 1.99 GiB free; 12.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ffcd8edc94d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-cdd22d0f5542>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m#nll_loss = my_utils.evaluate(net, valid_loader, device=device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/my_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, epoch, train_loader, args, device, frac, errors, beta)\u001b[0m\n\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mloss_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposite_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.59 GiB (GPU 0; 15.90 GiB total capacity; 10.39 GiB already allocated; 1.99 GiB free; 12.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4mdmVVavw8Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [I 2022-06-17 16:55:13,210] Trial 3 finished with value: 0.09719855338335037 and parameters: {'dropout': 0.02418752335062102, 'elbo_weight': 1.1061943368326204, 'embed_time': 16, 'lr': 4.212141191372822e-05, 'mse_weight': 5.108416562407145, 'rec_hidden': 128, 'num_samples': 6, 'x_by_range': True, 'optimizer': 'Adam', 'sample_tp': 0.1979453313080004}. Best is trial 3 with value: 0.09719855338335037.\n",
        "\n",
        "optuna.visualization.plot_param_importances(study)"
      ],
      "metadata": {
        "id": "8rI82ipQP4SK",
        "outputId": "5d814074-bf01-47a6-8b32-2b0e27137695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b2cad949-6bc1-4136-9cd1-533ff518dbe7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2cad949-6bc1-4136-9cd1-533ff518dbe7\")) {                    Plotly.newPlot(                        \"b2cad949-6bc1-4136-9cd1-533ff518dbe7\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"num_ref_points (CategoricalDistribution): 0.0<extra></extra>\",\"sample_tp (UniformDistribution): 0.001526784675077683<extra></extra>\",\"num_samples (IntUniformDistribution): 0.002948854055088827<extra></extra>\",\"lr (LogUniformDistribution): 0.007986726823241422<extra></extra>\",\"dropout (UniformDistribution): 0.010633777296692471<extra></extra>\",\"elbo_weight (UniformDistribution): 0.011233213788269674<extra></extra>\",\"gamma (UniformDistribution): 0.014748280615862175<extra></extra>\",\"optimizer (CategoricalDistribution): 0.022444712365717146<extra></extra>\",\"mse_weight (UniformDistribution): 0.07941623557037905<extra></extra>\",\"rec_hidden (CategoricalDistribution): 0.0843725892553453<extra></extra>\",\"latent_dim (CategoricalDistribution): 0.11959365773458827<extra></extra>\",\"embed_time (CategoricalDistribution): 0.12251755007682326<extra></extra>\",\"width (CategoricalDistribution): 0.1415095705820383<extra></extra>\",\"step_size (CategoricalDistribution): 0.38106804716087633<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.0\",\"0.001526784675077683\",\"0.002948854055088827\",\"0.007986726823241422\",\"0.010633777296692471\",\"0.011233213788269674\",\"0.014748280615862175\",\"0.022444712365717146\",\"0.07941623557037905\",\"0.0843725892553453\",\"0.11959365773458827\",\"0.12251755007682326\",\"0.1415095705820383\",\"0.38106804716087633\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.0,0.001526784675077683,0.002948854055088827,0.007986726823241422,0.010633777296692471,0.011233213788269674,0.014748280615862175,0.022444712365717146,0.07941623557037905,0.0843725892553453,0.11959365773458827,0.12251755007682326,0.1415095705820383,0.38106804716087633],\"y\":[\"num_ref_points\",\"sample_tp\",\"num_samples\",\"lr\",\"dropout\",\"elbo_weight\",\"gamma\",\"optimizer\",\"mse_weight\",\"rec_hidden\",\"latent_dim\",\"embed_time\",\"width\",\"step_size\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b2cad949-6bc1-4136-9cd1-533ff518dbe7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "oQb_oEElP40j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_slice(study, params=[\"optimizer\"])"
      ],
      "metadata": {
        "id": "RobOqJGDP7QP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}