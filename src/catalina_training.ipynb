{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catalina_training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEPzZxf07USO7DHeSLMScO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwl10/hetvae/blob/errors/src/catalina_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IbY6UeYNFMEJ",
        "outputId": "7ce93f2c-3d1d-4cbf-c1cf-f6615fd29ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hetvae'...\n",
            "remote: Enumerating objects: 3777, done.\u001b[K\n",
            "remote: Counting objects: 100% (813/813), done.\u001b[K\n",
            "remote: Compressing objects: 100% (783/783), done.\u001b[K\n",
            "remote: Total 3777 (delta 67), reused 69 (delta 30), pack-reused 2964\u001b[K\n",
            "Receiving objects: 100% (3777/3777), 30.36 MiB | 23.62 MiB/s, done.\n",
            "Resolving deltas: 100% (1012/1012), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alembic==1.7.7\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs==21.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (21.4.0)\n",
            "Collecting autopage==0.5.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting backports.functools-lru-cache==1.6.4\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting cliff==3.10.1\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting cmaes==0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cmd2==2.3.3\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorlog==6.6.0\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: greenlet==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata==4.11.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.11.4)\n",
            "Requirement already satisfied: importlib-resources==5.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (5.7.1)\n",
            "Collecting Mako==1.2.0\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe==2.1.1\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting numpy==1.21.0\n",
            "  Downloading numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 558 kB/s \n",
            "\u001b[?25hCollecting optuna==2.10.0\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging==21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (21.3)\n",
            "Collecting pbr==5.9.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 72.1 MB/s \n",
            "\u001b[?25hCollecting pip==22.1.1\n",
            "  Downloading pip-22.1.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prettytable==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (3.3.0)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (3.0.9)\n",
            "Collecting pyperclip==1.8.2\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.9 MB/s \n",
            "\u001b[?25hCollecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 189 kB/s \n",
            "\u001b[?25hCollecting setuptools==62.3.2\n",
            "  Downloading setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.4 MB/s \n",
            "\u001b[?25hCollecting SQLAlchemy==1.4.36\n",
            "  Downloading SQLAlchemy-1.4.36-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 38.7 MB/s \n",
            "\u001b[?25hCollecting stevedore==3.5.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (4.64.0)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (0.2.5)\n",
            "Requirement already satisfied: wheel==0.37.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (0.37.1)\n",
            "Requirement already satisfied: zipp==3.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 31)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2==2.3.3->-r requirements.txt (line 7)) (4.2.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=c6795b08295e53158d52282e5362578d3d2de26d3418c77fc8bf902a0bfe6d8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, MarkupSafe, stevedore, SQLAlchemy, PyYAML, numpy, Mako, cmd2, autopage, scipy, colorlog, cmaes, cliff, alembic, setuptools, pip, optuna, colorama, backports.functools-lru-cache\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.37\n",
            "    Uninstalling SQLAlchemy-1.4.37:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.37\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.0 MarkupSafe-2.1.1 PyYAML-6.0 SQLAlchemy-1.4.36 alembic-1.7.7 autopage-0.5.0 backports.functools-lru-cache-1.6.4 cliff-3.10.1 cmaes-0.8.2 cmd2-2.3.3 colorama-0.4.4 colorlog-6.6.0 numpy-1.21.0 optuna-2.10.0 pbr-5.9.0 pip-22.1.1 pyperclip-1.8.2 scipy-1.7.3 setuptools-62.3.2 stevedore-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import shutil#\n",
        "os.chdir('/content')\n",
        "! git clone --branch errors https://github.com/mwl10/hetvae\n",
        "os.chdir('/content/hetvae')\n",
        "! pip install -r requirements.txt\n",
        "os.chdir('/content/hetvae/src')\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import models\n",
        "from argparse import Namespace\n",
        "import torch.optim as optim\n",
        "import utils\n",
        "import my_utils\n",
        "import pandas as pd\n",
        "import importlib\n",
        "import vae_models\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from dataset import DataSet\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------------------------------------------------\n",
        "# PREPROCESSING, from Catalina data\n",
        "#--------------------------------------------------------------------------------------------------------\n",
        "lc_files = glob('/content/hetvae/data/CAT/*/*')\n",
        "print(lc_files)\n",
        "Catalina = DataSet() \\\n",
        "            .add_files(lc_files) \\\n",
        "            .files_to_numpy(maximum=200) \\\n",
        "            .handle_dups() \\\n",
        "            .prune_graham(plot=True, index=100) \\\n",
        "            # .normalize(normalize_x='individual', normalize_y='individual') \\\n",
        "            # .reorder() \\\n",
        "            # .set_union_x() \\\n",
        "            # .zero_fill() \\\n",
        "            # .error_to_sample_weight() \\\n",
        "            # .make_masks(frac=0.5)\n",
        "\n",
        "# print(\n",
        "#     Catalina.files, '\\n',\n",
        "#     Catalina.union_x.shape,\n",
        "#     Catalina.dataset.shape,\n",
        "#     Catalina.subsampled_mask.shape,\n",
        "#     Catalina.recon_mask.shape\n",
        "#   )\n",
        "# fig,ax = plt.subplots(5,1, figsize=(20,20))\n",
        "# for i in range(5):\n",
        "#     ax[i].scatter(Catalina.dataset[i,:-130,0], Catalina.dataset[i,:-130,1])"
      ],
      "metadata": {
        "id": "8gbnOmB7FsvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num heads?\n",
        "args = Namespace(batch_size=8, bound_variance=False, const_var=False,dropout=0.3, \n",
        "                 elbo_weight=1, embed_time=32, enc_num_heads=4, intensity=True, k_iwae=1, kl_annealing=False, \n",
        "                 kl_zero=False, latent_dim=64, lr=0.001, mixing='concat_and_mix', mse_weight=1., net='hetvae', \n",
        "                 niters=1000, norm=True, normalize_input='znorm', num_ref_points=64, rec_hidden=64, recon_loss=False, \n",
        "                 sample_tp=0.33, save=True, seed=0, shuffle=True, std=0.9, var_per_dim=False, width=64)\n",
        "\n",
        "DIM = 1\n",
        "# definitly want a decaying error rate...\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=0.1)\n",
        "seed = args.seed\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "qvzEPdmJHO3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LightCurves = np.concatenate((Catalina.dataset, Catalina.subsampled_mask[:,:,np.newaxis], Catalina.recon_mask[:,:,np.newaxis]), axis=-1) # format the masks for the model \n"
      ],
      "metadata": {
        "id": "xSJoDHsxHT-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training, valid = np.split(LightCurves, [int(np.floor(0.8*len(LightCurves)))])# shuffle?\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(training, batch_size=args.batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=args.batch_size)\n",
        "\n",
        "net = models.load_network(args, DIM, torch.Tensor(Catalina.union_x)) \n",
        "params = list(net.parameters())\n",
        "# try different union x? "
      ],
      "metadata": {
        "id": "XxoUJ7CWHWEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruction, qz_mean, qz_std = viz_per_example(AGN_1H2106.dataset[0], AGN_1H2106.target_x[0], net, device=device, k_iwae=50)\n",
        "\n",
        "# visualisation for one light curve w/ increasing number of points\n",
        "def viz_per_example(example, target_x, net, device=\"cuda\", k_iwae=10, frac=0.5): \n",
        "    example = example[np.newaxis, :,:]\n",
        "    target_x = target_x[np.newaxis, :, np.newaxis]\n",
        "    np.random.seed(0)\n",
        "    with torch.no_grad(): \n",
        "        if torch.is_tensor(example):\n",
        "            example = example.cpu().numpy()\n",
        "        # make new masks relative to fraction of points we got to predict w/ \n",
        "        smask, rmask = my_utils.make_masks(example, frac=frac)\n",
        "        example = np.concatenate((example, smask[:,:,np.newaxis], rmask[:,:,np.newaxis], target_x), axis=-1) # format the masks \n",
        "        \n",
        "        example = torch.tensor(example)\n",
        "        example = example.to(device)\n",
        "        \n",
        "        subsampled_mask = example[:,:,3:4]\n",
        "        context_y = torch.cat((example[:,:, 1:2] * subsampled_mask, subsampled_mask), -1)\n",
        "        px, qz = net.get_reconstruction(example[:,:, 0], context_y, example[:,:,5], num_samples=k_iwae)\n",
        "\n",
        "        qz_mean = (qz.mean.cpu().numpy())\n",
        "        qz_std = (torch.exp(0.5 * qz.logvar).cpu().numpy())\n",
        "        px_mean = px.mean.cpu().numpy()\n",
        "        px_std = torch.exp(0.5 * px.logvar).cpu().numpy()\n",
        "        example = example.cpu().numpy()\n",
        "\n",
        "        px_mean = np.mean(px_mean, axis=0)[0,:200,0]\n",
        "        px_std = np.mean(px_std, axis=0)[0,:200,0]\n",
        "        target_x = target_x[0,:200,0]\n",
        "        w=2.0\n",
        "        plt.figure(figsize=(30, 10))\n",
        "        #plt.fill_between(target_x, px_mean - 2*px_std, px_mean+2*px_std, color='gray')\n",
        "\n",
        "        plt.plot(target_x, px_mean, c='b', lw=w, label='Reconstructions', zorder=20)\n",
        "        plt.scatter(example[0,:,0], example[0,:,1])\n",
        "        plt.errorbar(target_x, px_mean ,yerr=px_std,  ecolor='#65c9f7', c='b', lw=w, label='Reconstructions')\n",
        "\n",
        "        plt.show()\n",
        "        reconstruction = np.concatenate((target_x[:,np.newaxis], px_mean[:,np.newaxis], px_std[:,np.newaxis]), axis=1)\n",
        "        print(f'qz shape: {qz_mean.shape}')\n",
        "        print(f'reconstructed example: {reconstruction.shape}')\n",
        "        return reconstruction, qz_mean,qz_std"
      ],
      "metadata": {
        "id": "Lj5xlmLAHu92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_mean, x_std = AGN_1H2106.x_mean_std[0]\n",
        "y_mean, y_std = AGN_1H2106.y_mean_std[0]\n",
        "\n",
        "\n",
        "x = (reconstruction[:,0] * x_std) + x_mean\n",
        "y = (reconstruction[:,1] * y_std) + y_mean\n",
        "yerr = reconstruction[:,2] * y_std\n",
        "plt.errorbar(x,y,yerr=yerr)\n",
        "\n",
        "denorm_AGN = AGN_1H2106.error_to_sample_weight().denormalize()\n",
        "x = denorm_AGN[0,:,0]\n",
        "y = denorm_AGN[0,:,1]\n",
        "\n",
        "yerr = denorm_AGN[0,:,2]\n",
        "\n",
        "\n",
        "\n",
        "plt.errorbar(x,y,yerr=yerr, fmt='o')"
      ],
      "metadata": {
        "id": "wZHw4xM9H1pV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}