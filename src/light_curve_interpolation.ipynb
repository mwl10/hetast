{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "synthetic_data_interpolation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSKtH8WGhoBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fb3501-db6a-4c72-c37a-8f76df85c501"
      },
      "source": [
        "import os\n",
        "! git clone https://github.com/mwl10/hetvae\n",
        "os.chdir('/content/hetvae')\n",
        "! pip install -r requirements.txt\n",
        "os.chdir('/content/hetvae/src')\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import models\n",
        "import utils\n",
        "import my_utils\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hetvae'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 130 (delta 67), reused 77 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (130/130), 18.14 MiB | 11.28 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.3.5)\n",
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 7.5 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (1.1.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lc_files = glob('/content/hetvae/data/EDELSON/*')"
      ],
      "metadata": {
        "id": "cMCK4vrx3M_0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tmBNGJGxyrch"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcs = my_utils.file_to_np(*lc_files)\n",
        "\n",
        "# set starting time value to zero \n",
        "#lcs = [lc[:,0] - lc[0,0] for lc in lcs]\n",
        "# normalizing function now! \n",
        "for lc in lcs:\n",
        "  lc[:,0] = lc[:,0] - lc[0,0]\n",
        "print('-'*50)\n",
        "lcs = my_utils.handle_dups(lcs)\n",
        "union_tp = my_utils.union_timepoints(lcs)\n",
        "print(len(union_tp))\n",
        "lcs = my_utils.include_union_tp(lcs, union_tp)\n",
        "lcs.shape # fire!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O8IyKUO-fpq",
        "outputId": "701c77ad-ada2-403e-9ccd-a598e57c424b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dims of /content/hetvae/data/EDELSON/NGC5548_SX.dat:\t(267, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_W1.dat:\t(150, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_M2.dat:\t(148, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_SX.dat:\t(190, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_W2.dat:\t(259, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_HX.dat:\t(190, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_W1.dat:\t(260, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_HX.dat:\t(267, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_M2.dat:\t(248, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_W2.dat:\t(147, 3)\n",
            "--------------------------------------------------\n",
            "1644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1644, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "std_time = np.std(union_tp)\n",
        "std_flux = np.std(lcs[:,:,1].flatten())\n",
        "mean_flux = np.mean(lcs[:,:,1].flatten())\n",
        "union_tp = union_tp / std_time\n",
        "lcs[:,:,0] = lcs[:,:,0] / std_time"
      ],
      "metadata": {
        "id": "tks0rbVIz-1A"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcs = lcs.astype(np.float32)\n",
        "union_tp = union_tp.astype(np.float32)\n",
        "union_tp = torch.tensor(union_tp)\n",
        "train_loader = torch.utils.data.DataLoader(lcs, batch_size=2)\n",
        "\n",
        "dim = 1"
      ],
      "metadata": {
        "id": "2YGZeqo2g4e9"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AMjSKXYobJx"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Setting up arguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Namespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)"
      ],
      "metadata": {
        "id": "lrDc-45iHcJm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUdH2aGzifXQ"
      },
      "source": [
        "args = Namespace(batch_size=2, bound_variance=True, const_var=False, dataset='toy', dropout=0.0, \n",
        "                 elbo_weight=1.0, embed_time=128, enc_num_heads=1, intensity=True, k_iwae=1, kl_annealing=False, \n",
        "                 kl_zero=False, latent_dim=64, lr=0.000001, mixing='concat', mse_weight=0.0, n=2000, net='hetvae', \n",
        "                 niters=2000, norm=True, normalize_input='znorm', num_ref_points=16, rec_hidden=16, recon_loss=False, \n",
        "                 sample_tp=0.5, save=True, seed=0, shuffle=True, std=0.1, var_per_dim=False, width=512)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duBTaWMokd1T"
      },
      "source": [
        "seed = args.seed\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b4ufWPlkpmN",
        "outputId": "85684e30-7d30-490e-832e-d67644b08bee"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu4NfxiUojxk"
      },
      "source": [
        "## **Generating Synthetic Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# why is it subtracting 1 for the recon mask?\n",
        "# dataset class that loads agn by folder you give it? agn object, agn.addLC('').addLC('')\n",
        "# what is happening with the normalizations...\n",
        "# kl negative? negative losses in general???\n",
        "# make this capable of running on GPU\n",
        "# fixing visualization\n",
        "# adding error bars in the loss function?\n",
        "# is my union_tp right? \n",
        "# different sequence sizes, some drastically shorter... how to make this not matter? does it? \n",
        "\n",
        "\n",
        "# do we subsample the light curve like they do...?\n",
        "# i guess we do because you're just randomly selecting points each go round...\n",
        "\n",
        "\n",
        "# make the masks beforehand...\n",
        "def make_masks(lcs):\n",
        "\n",
        "  subsampled_mask = np.zeros_like(lcs[:,:,1])\n",
        "  recon_mask = np.zeros_like(lcs[:,:,1])\n",
        "  for i,lc in enumerate(lcs):\n",
        "    indexes = lc[:,1].nonzero()[0]\n",
        "    length = int(np.round(len(indexes) * .25))\n",
        "    obs_points = np.sort(np.random.choice(indexes, size=length, replace=False))\n",
        "    subsampled_mask[i, obs_points] = 1\n",
        "    recon_mask[i] = np.logical_not(subsampled_mask[i])\n",
        "\n",
        "  return subsampled_mask, recon_mask\n",
        "\n",
        "smask, rmask = make_masks(lcs)\n"
      ],
      "metadata": {
        "id": "twW6b7C2q8D6"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udt437lzovHw"
      },
      "source": [
        "## **Loading HeTVAE model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(subsampled_mask[0].sum(), recon_mask[0].sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szQGXV9FY49t",
        "outputId": "1a049ab7-5209-479e-ee3c-6237f8fc1533"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67.0 1577.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZAIfoHtlfVE"
      },
      "source": [
        "net = models.load_network(args, dim, union_tp) # dim = 1\n",
        "params = list(net.parameters())\n",
        "optimizer = optim.Adam(params, lr=args.lr)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a58EIBLfnj3v"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JE78L00Flifr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X9MDaO5zlD9H",
        "outputId": "028ed718-e46e-4d59-8c81-663b1d62907b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1644, 1])\n",
            "torch.Size([2, 1644, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "px"
      ],
      "metadata": {
        "id": "lgKGJ8wwm1Ty",
        "outputId": "a17c6593-f51e-4426-84f4-8c33252fddfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<vae_models.Gaussian at 0x7f9ecb008890>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for itr in range(1, args.niters + 1):\n",
        "      train_loss = 0\n",
        "      train_n = 0\n",
        "      avg_loglik, avg_kl, mse, mae = 0, 0, 0, 0\n",
        "      batch_size = 2\n",
        "      for i, train_batch in enumerate(train_loader):\n",
        "          batch_len = train_batch.shape[0] \n",
        "          train_batch = train_batch.to(device)\n",
        "          subsampled_mask = torch.tensor(smask[batch_size*i:batch_size*i + 2, :,np.newaxis]).to(device) # should look like our flux values?\n",
        "          recon_mask = torch.tensor(rmask[batch_size*i:batch_size*i + 2, :,np.newaxis]).to(device)\n",
        "          seqlen = train_batch.size(1) \n",
        "          print(subsampled_mask.shape)\n",
        "          print(train_batch[:,:,1:2].shape)\n",
        "          context_y = torch.cat((\n",
        "              train_batch[:, :, 1:2] * subsampled_mask, subsampled_mask\n",
        "          ), -1) \n",
        "    # #   def compute_unsupervised_loss(\n",
        "    # #     self, context_x, context_y, target_x, target_y, num_samples=1, beta=1.\n",
        "    # # ):\n",
        "\n",
        "          loss_info = net.compute_unsupervised_loss(\n",
        "              train_batch[:, :, 0], # context_x, times\n",
        "              context_y,             # context_y\n",
        "              train_batch[:, :, 0], # target_x, same times? \n",
        "              torch.cat((            # target_y\n",
        "                  train_batch[:, :, 1:2] * recon_mask, recon_mask\n",
        "              ), -1),\n",
        "              num_samples=args.k_iwae, # 1? \n",
        "              beta=1,       # ? \n",
        "          )\n",
        "          optimizer.zero_grad()\n",
        "          loss_info.composite_loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss_info.composite_loss.item() * batch_len\n",
        "          avg_loglik += loss_info.loglik * batch_len\n",
        "          avg_kl += loss_info.kl * batch_len\n",
        "          mse += loss_info.mse * batch_len\n",
        "          mae += loss_info.mae * batch_len\n",
        "          train_n += batch_len\n",
        "\n",
        "      if itr % 100 == 0:\n",
        "          print(\n",
        "              'Iter: {}, train loss: {:.4f}, avg nll: {:.4f}, avg kl: {:.4f}, '\n",
        "              'mse: {:.6f}, mae: {:.6f}'.format(\n",
        "                  itr,\n",
        "                  train_loss / train_n,\n",
        "                  -avg_loglik / train_n,\n",
        "                  avg_kl / train_n,\n",
        "                  mse / train_n,\n",
        "                  mae / train_n\n",
        "              )\n",
        "          )\n",
        "    #       for loader, num_samples in [(val_loader, 5), (test_loader, 100)]:\n",
        "    #           utils.evaluate_hetvae(\n",
        "    #               net,\n",
        "    #               dim,\n",
        "    #               loader,\n",
        "    #               0.5,\n",
        "    #               shuffle=False,\n",
        "    #               k_iwae=num_samples,\n",
        "    #               model_name=args.net,\n",
        "    #           )"
      ],
      "metadata": {
        "id": "wdgcWN0blrM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls ../"
      ],
      "metadata": {
        "id": "JeX4uvpJnbK6",
        "outputId": "0c138512-e269-4ca3-bfa8-e01086491957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  LICENSE  README.md  requirements.txt  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EIM5FAaPnto",
        "outputId": "a2c11007-20a4-4d23-9b1d-a01d222bebdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=ec17d09aedc31b1a39323c5906d553e5b2b06d5a4f9c165bf95b7da46b0882cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.5 GB  | Proc size: 1.5 GB\n",
            "GPU RAM Free: 177MB | Used: 11264MB | Util  98% | Total 11441MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkXkWKY-nQez"
      },
      "source": [
        "## **Vizualization with increasing number of observations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfrTzOZes5BN"
      },
      "source": [
        "def viz(test_loader, k_iwae=1, n_max=20):\n",
        "    pred_mean, pred_std = [], []\n",
        "    masks = []\n",
        "    targets = []\n",
        "    tp =[]\n",
        "    np.random.seed(0)\n",
        "    with torch.no_grad():\n",
        "        for low in [20]:\n",
        "            for batch in test_loader:\n",
        "                batch_len = batch.shape[0]\n",
        "                batch = batch.to(device)\n",
        "                subsampled_mask = torch.zeros_like(batch[:, :, dim:2 * dim]).to(device)\n",
        "                seqlen = batch.size(1)\n",
        "                for i in range(batch_len):\n",
        "                    length = np.random.randint(low=low, high=low + 1)\n",
        "                    obs_points = np.sort(np.random.choice(np.arange(seqlen), size=length, replace=False))\n",
        "                    subsampled_mask[i, obs_points, :] = 1\n",
        "                recon_mask = batch[:, :, dim:2 * dim] - subsampled_mask\n",
        "                context_y = torch.cat((batch[:, :, :dim] * subsampled_mask, subsampled_mask), -1)\n",
        "                px, _ = net.get_reconstruction(batch[:, :, -1], context_y, batch[:, :, -1], num_samples=k_iwae)\n",
        "                pred_mean.append(px.mean.cpu().numpy())\n",
        "                pred_std.append(torch.exp(0.5 * px.logvar).cpu().numpy())\n",
        "                targets.append((batch[:, :, :dim]).cpu().numpy())\n",
        "                masks.append(subsampled_mask.cpu().numpy())\n",
        "                tp.append(batch[:, :, -1].cpu().numpy())\n",
        "                if len(tp) % (n_max // 5) == 0:\n",
        "                    break\n",
        "    \n",
        "    pred_mean = np.concatenate(pred_mean, axis=1)\n",
        "    pred_std = np.concatenate(pred_std, axis=1)\n",
        "    targets = np.concatenate(targets, axis=0)\n",
        "    masks = np.concatenate(masks, axis=0)\n",
        "    tp = np.concatenate(tp, axis=0)\n",
        "    inputs = np.ma.masked_where(masks < 1., targets)\n",
        "    print(pred_mean.shape, pred_std.shape, targets.shape, masks.shape, tp.shape)\n",
        "    preds = np.random.randn(k_iwae // 2, k_iwae, pred_mean.shape[1], pred_mean.shape[2], pred_mean.shape[3]) * pred_std + pred_mean\n",
        "    preds = preds.reshape(-1, pred_mean.shape[1], pred_mean.shape[2], pred_mean.shape[3])\n",
        "    median = preds.mean(0) #np.quantile(preds, 0.5, axis=0)\n",
        "    quantile2 = np.quantile(preds, 0.841, axis=0)\n",
        "    quantile1 = np.quantile(preds, 0.159, axis=0)\n",
        "\n",
        "    w = 2.0\n",
        "    for index in range(n_max):\n",
        "        plt.figure(figsize=(12, 1.5))\n",
        "        for j in range(3):\n",
        "            plt.subplot(1, 3, j + 1)\n",
        "            plt.fill_between(tp[n_max * j + index], quantile1[n_max * j + index, :, 0], quantile2[n_max * j + index, :, 0], alpha=0.6, facecolor='#65c9f7', interpolate=True)\n",
        "            plt.plot(tp[n_max * j + index], median[n_max * j + index, :, 0], c='b', lw=w, label='Reconstructions')\n",
        "            #plt.plot(tp[n_max * j + index], gt[index], c='r', lw=w, label='Ground Truth')\n",
        "            plt.scatter(tp[n_max * j + index], inputs[n_max * j + index, :, 0], c='k', lw=w, label='Observed Data')\n",
        "            plt.xlim([0, 1])\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            if j == 1 and index == 0:\n",
        "                plt.legend(loc='upper center', ncol=3, bbox_to_anchor=(0.6,1.5))\n",
        "            \n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "N3keG-7Urr69",
        "outputId": "0c48a533-bd14-4361-c404-93d0ebd969ec"
      },
      "source": [
        "viz(train_loader, k_iwae=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-8691c71035b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_iwae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-165bda9664c4>\u001b[0m in \u001b[0;36mviz\u001b[0;34m(test_loader, k_iwae, n_max)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mrecon_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msubsampled_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mcontext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msubsampled_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampled_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_iwae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mpred_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mpred_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/vae_models.py\u001b[0m in \u001b[0;36mget_reconstruction\u001b[0;34m(self, context_x, context_y, target_x, num_samples)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/vae_models.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z, target_x)\u001b[0m\n\u001b[1;32m    119\u001b[0m         target_x = target_x[None, :, :].repeat(\n\u001b[1;32m    120\u001b[0m             num_sample, 1, 1).view(-1, target_x.shape[1])\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mpred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m    118\u001b[0m             x.size(0), -1, self.h, self.embed_time_k).transpose(1, 2)\n\u001b[1;32m    119\u001b[0m             for l, x in zip(self.linears, (query, key))]\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/layers.py\u001b[0m in \u001b[0;36mattention\u001b[0;34m(self, query, key, value, mask, dropout)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.51 GiB (GPU 0; 11.17 GiB total capacity; 10.68 GiB already allocated; 176.81 MiB free; 10.70 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgXlWxyhruho"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}