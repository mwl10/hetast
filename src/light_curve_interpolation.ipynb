{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "synthetic_data_interpolation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSKtH8WGhoBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848b119b-1f56-43af-8aad-2a11e087f71d"
      },
      "source": [
        "import os\n",
        "! git clone https://github.com/mwl10/hetvae\n",
        "os.chdir('/content/hetvae')\n",
        "! pip install -r requirements.txt\n",
        "os.chdir('/content/hetvae/src')\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import models\n",
        "import utils\n",
        "import my_utils\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hetvae'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 126 (delta 64), reused 77 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (126/126), 18.14 MiB | 42.12 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.3.5)\n",
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 5.5 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 2)) (3.1.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lc_files = glob('/content/hetvae/data/EDELSON/*')"
      ],
      "metadata": {
        "id": "cMCK4vrx3M_0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmBNGJGxyrch",
        "outputId": "2ff05b67-ce01-4b5b-a634-a873d3208e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dims of /content/hetvae/data/KOSHIDA/NGC4593_V.dat:\t(34, 3)\n",
            "dims of /content/hetvae/data/KOSHIDA/NGC5548_V.dat:\t(301, 3)\n",
            "dims of /content/hetvae/data/KOSHIDA/NGC5548_K.dat:\t(310, 3)\n",
            "dims of /content/hetvae/data/KOSHIDA/NGC4593_K.dat:\t(36, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_W2.dat:\t(259, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_HX.dat:\t(190, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_W2.dat:\t(147, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_W1.dat:\t(150, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_M2.dat:\t(148, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_HX.dat:\t(267, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_SX.dat:\t(267, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_M2.dat:\t(248, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_W1.dat:\t(260, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_SX.dat:\t(190, 3)\n",
            "dims of /content/hetvae/data/DEROSA/NGC5548_Cont.dat:\t(177, 3)\n",
            "dims of /content/hetvae/data/DEROSA/NGC5548_Emis.dat:\t(105, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Process light curves"
      ],
      "metadata": {
        "id": "-mZ4DPVIfQA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcs = my_utils.file_to_np(*lc_files)\n",
        "\n",
        "# set starting time value to zero \n",
        "#lcs = [lc[:,0] - lc[0,0] for lc in lcs]\n",
        "# normalizing function now! \n",
        "for lc in lcs:\n",
        "  lc[:,0] = lc[:,0] - lc[0,0]\n",
        "print('-'*50)\n",
        "lcs = my_utils.handle_dups(lcs)\n",
        "union_tp = my_utils.union_timepoints(lcs)\n",
        "print(len(union_tp))\n",
        "lcs = my_utils.include_union_tp(lcs, union_tp)\n",
        "lcs.shape # fire!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O8IyKUO-fpq",
        "outputId": "451c3bf3-4ad2-4459-ff12-e3d608229eb6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dims of /content/hetvae/data/EDELSON/NGC5548_SX.dat:\t(267, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_W1.dat:\t(150, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_M2.dat:\t(148, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_SX.dat:\t(190, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_W2.dat:\t(259, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_HX.dat:\t(190, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_W1.dat:\t(260, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_HX.dat:\t(267, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC5548_M2.dat:\t(248, 3)\n",
            "dims of /content/hetvae/data/EDELSON/NGC4593_W2.dat:\t(147, 3)\n",
            "--------------------------------------------------\n",
            "1644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1644, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(lcs[:,:,1].flatten())\n",
        "max(union_tp)\n",
        "\n",
        "std_time = np.std(union_tp)\n",
        "std_flux = np.std(lcs[:,:,1].flatten())\n",
        "mean_flux = np.mean(lcs[:,:,1].flatten())\n",
        "union_tp = union_tp / std_time\n",
        "lcs[:,:,0] = lcs[:,:,0] / std_time"
      ],
      "metadata": {
        "id": "tks0rbVIz-1A"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lcs = lcs.astype(np.float32)\n",
        "union_tp = union_tp.astype(np.float32)\n",
        "union_tp = torch.tensor(union_tp)\n",
        "train_loader = torch.utils.data.DataLoader(lcs, batch_size=2)\n",
        "dim = 1"
      ],
      "metadata": {
        "id": "2YGZeqo2g4e9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AMjSKXYobJx"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Setting up arguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Namespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)"
      ],
      "metadata": {
        "id": "lrDc-45iHcJm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUdH2aGzifXQ"
      },
      "source": [
        "args = Namespace(batch_size=2, bound_variance=True, const_var=False, dataset='toy', dropout=0.0, \n",
        "                 elbo_weight=1.0, embed_time=128, enc_num_heads=1, intensity=True, k_iwae=1, kl_annealing=False, \n",
        "                 kl_zero=False, latent_dim=64, lr=0.000001, mixing='concat', mse_weight=0.0, n=2000, net='hetvae', \n",
        "                 niters=2000, norm=True, normalize_input='znorm', num_ref_points=16, rec_hidden=16, recon_loss=False, \n",
        "                 sample_tp=0.5, save=True, seed=0, shuffle=True, std=0.1, var_per_dim=False, width=512)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duBTaWMokd1T"
      },
      "source": [
        "seed = args.seed\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b4ufWPlkpmN",
        "outputId": "63f2825e-9b60-43f7-a85e-cf304056c686"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu4NfxiUojxk"
      },
      "source": [
        "## **Generating Synthetic Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# why is it subtracting 1 for the recon mask?\n",
        "# dataset class that loads agn by folder you give it? agn object, agn.addLC('').addLC('')\n",
        "# what is happening with the normalizations...\n",
        "# kl negative? negative losses in general???\n",
        "# make this capable of running on GPU\n",
        "# fixing visualization\n",
        "# adding error bars in the loss function?\n",
        "# is my union_tp right? \n",
        "# different sequence sizes, some drastically shorter... how to make this not matter? does it? \n"
      ],
      "metadata": {
        "id": "twW6b7C2q8D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udt437lzovHw"
      },
      "source": [
        "## **Loading HeTVAE model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZAIfoHtlfVE"
      },
      "source": [
        "net = models.load_network(args, dim, union_tp) # dim = 1\n",
        "params = list(net.parameters())\n",
        "optimizer = optim.Adam(params, lr=args.lr)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a58EIBLfnj3v"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE78L00Flifr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e020e588-2b27-4008-b12c-e94824744bc6"
      },
      "source": [
        "for itr in range(1, args.niters + 1):\n",
        "      train_loss = 0\n",
        "      train_n = 0\n",
        "      avg_loglik, avg_kl, mse, mae = 0, 0, 0, 0\n",
        "      for train_batch in train_loader:\n",
        "          batch_len = train_batch.shape[0] \n",
        "          train_batch = train_batch.to(device)\n",
        "          subsampled_mask = torch.zeros_like(\n",
        "              train_batch[:, :, dim:2 * dim]).to(device) # mask is 128,51,1\n",
        "          seqlen = train_batch.size(1) # 51\n",
        "          \n",
        "          for i in range(batch_len):\n",
        "              # length = np.random.randint(low=3, high=10) # 3-9 \n",
        "              # obs_points = np.sort(  # random choice from 0-50 of random length 3-9, \n",
        "              #     np.random.choice(np.arange(seqlen), size=length, replace=False)\n",
        "              # )\n",
        "              # subsampled_mask[i, obs_points, :] = 1 # set those particular points to 1, others are still zero \n",
        "              tb_copy = train_batch[i,:,dim:2*dim].cpu()\n",
        "              subsampled_mask[i] = (np.logical_xor(np.zeros((seqlen, dim)), tb_copy) * 1)\n",
        "              # need a ones matrix where there are points \n",
        "          recon_mask = train_batch[:, :, dim:2 * dim] - subsampled_mask # whats the point of subtracting the values by 1? \n",
        "          # train_batch[:,:,1] flux values - \n",
        "          # keep only 3-9 points for each time series for each batch dunno why you need the mask too \n",
        "          context_y = torch.cat((\n",
        "              train_batch[:, :, :dim] * subsampled_mask, subsampled_mask\n",
        "          ), -1) \n",
        "\n",
        "          loss_info = net.compute_unsupervised_loss(\n",
        "              train_batch[:, :, -1],\n",
        "              context_y,\n",
        "              train_batch[:, :, -1],\n",
        "              torch.cat((\n",
        "                  train_batch[:, :, :dim] * recon_mask, recon_mask\n",
        "              ), -1),\n",
        "              num_samples=args.k_iwae,\n",
        "              beta=1,\n",
        "          )\n",
        "          optimizer.zero_grad()\n",
        "          loss_info.composite_loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss_info.composite_loss.item() * batch_len\n",
        "          avg_loglik += loss_info.loglik * batch_len\n",
        "          avg_kl += loss_info.kl * batch_len\n",
        "          mse += loss_info.mse * batch_len\n",
        "          mae += loss_info.mae * batch_len\n",
        "          train_n += batch_len\n",
        "\n",
        "      if itr % 100 == 0:\n",
        "          print(\n",
        "              'Iter: {}, train loss: {:.4f}, avg nll: {:.4f}, avg kl: {:.4f}, '\n",
        "              'mse: {:.6f}, mae: {:.6f}'.format(\n",
        "                  itr,\n",
        "                  train_loss / train_n,\n",
        "                  -avg_loglik / train_n,\n",
        "                  avg_kl / train_n,\n",
        "                  mse / train_n,\n",
        "                  mae / train_n\n",
        "              )\n",
        "          )\n",
        "          # for loader, num_samples in [(val_loader, 5), (test_loader, 100)]:\n",
        "          #     utils.evaluate_hetvae(\n",
        "          #         net,\n",
        "          #         dim,\n",
        "          #         loader,\n",
        "          #         0.5,\n",
        "          #         shuffle=False,\n",
        "          #         k_iwae=num_samples,\n",
        "          #         model_name=args.net,\n",
        "          #     )"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 100, train loss: 8.0246, avg nll: 7.8903, avg kl: 0.1343, mse: 17.896566, mae: 3.216139\n",
            "Iter: 200, train loss: 7.3870, avg nll: 7.2765, avg kl: 0.1106, mse: 17.790545, mae: 3.213968\n",
            "Iter: 300, train loss: 6.2606, avg nll: 6.1591, avg kl: 0.1015, mse: 17.459951, mae: 3.183439\n",
            "Iter: 400, train loss: 5.6937, avg nll: 5.5930, avg kl: 0.1007, mse: 17.270250, mae: 3.171838\n",
            "Iter: 500, train loss: 5.2559, avg nll: 5.1501, avg kl: 0.1058, mse: 17.067139, mae: 3.153033\n",
            "Iter: 600, train loss: 4.7164, avg nll: 4.6071, avg kl: 0.1093, mse: 16.770933, mae: 3.124796\n",
            "Iter: 700, train loss: 4.3236, avg nll: 4.2172, avg kl: 0.1064, mse: 16.442976, mae: 3.117291\n",
            "Iter: 800, train loss: 3.8942, avg nll: 3.7938, avg kl: 0.1004, mse: 16.349365, mae: 3.117128\n",
            "Iter: 900, train loss: 3.6250, avg nll: 3.5314, avg kl: 0.0936, mse: 16.062115, mae: 3.086208\n",
            "Iter: 1000, train loss: 3.3415, avg nll: 3.2552, avg kl: 0.0862, mse: 15.865320, mae: 3.074376\n",
            "Iter: 1100, train loss: 3.0708, avg nll: 2.9930, avg kl: 0.0778, mse: 15.560120, mae: 3.070187\n",
            "Iter: 1200, train loss: 2.8402, avg nll: 2.7722, avg kl: 0.0680, mse: 15.238527, mae: 3.044956\n",
            "Iter: 1300, train loss: 2.6274, avg nll: 2.5705, avg kl: 0.0568, mse: 14.990984, mae: 3.028649\n",
            "Iter: 1400, train loss: 2.4570, avg nll: 2.4130, avg kl: 0.0439, mse: 14.656512, mae: 2.980371\n",
            "Iter: 1500, train loss: 2.4049, avg nll: 2.3753, avg kl: 0.0296, mse: 14.578967, mae: 2.982681\n",
            "Iter: 1600, train loss: 2.2561, avg nll: 2.2425, avg kl: 0.0136, mse: 14.163112, mae: 2.935055\n",
            "Iter: 1700, train loss: 2.1924, avg nll: 2.1965, avg kl: -0.0041, mse: 14.101012, mae: 2.944843\n",
            "Iter: 1800, train loss: 2.0432, avg nll: 2.0659, avg kl: -0.0227, mse: 13.628369, mae: 2.890581\n",
            "Iter: 1900, train loss: 1.9949, avg nll: 2.0369, avg kl: -0.0421, mse: 13.543460, mae: 2.866221\n",
            "Iter: 2000, train loss: 1.9470, avg nll: 2.0087, avg kl: -0.0617, mse: 13.424315, mae: 2.869621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EIM5FAaPnto",
        "outputId": "a2c11007-20a4-4d23-9b1d-a01d222bebdb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=ec17d09aedc31b1a39323c5906d553e5b2b06d5a4f9c165bf95b7da46b0882cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.5 GB  | Proc size: 1.5 GB\n",
            "GPU RAM Free: 177MB | Used: 11264MB | Util  98% | Total 11441MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkXkWKY-nQez"
      },
      "source": [
        "## **Vizualization with increasing number of observations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfrTzOZes5BN"
      },
      "source": [
        "def viz(test_loader, k_iwae=1, n_max=20):\n",
        "    pred_mean, pred_std = [], []\n",
        "    masks = []\n",
        "    targets = []\n",
        "    tp =[]\n",
        "    np.random.seed(0)\n",
        "    with torch.no_grad():\n",
        "        for low in [3, 10, 20]:\n",
        "            for batch in test_loader:\n",
        "                batch_len = batch.shape[0]\n",
        "                batch = batch.to(device)\n",
        "                subsampled_mask = torch.zeros_like(batch[:, :, dim:2 * dim]).to(device)\n",
        "                seqlen = batch.size(1)\n",
        "                for i in range(batch_len):\n",
        "                    length = np.random.randint(low=low, high=low + 1)\n",
        "                    obs_points = np.sort(np.random.choice(np.arange(seqlen), size=length, replace=False))\n",
        "                    subsampled_mask[i, obs_points, :] = 1\n",
        "                recon_mask = batch[:, :, dim:2 * dim] - subsampled_mask\n",
        "                context_y = torch.cat((batch[:, :, :dim] * subsampled_mask, subsampled_mask), -1)\n",
        "                px, _ = net.get_reconstruction(batch[:, :, -1], context_y, batch[:, :, -1], num_samples=k_iwae)\n",
        "                pred_mean.append(px.mean.cpu().numpy())\n",
        "                pred_std.append(torch.exp(0.5 * px.logvar).cpu().numpy())\n",
        "                targets.append((batch[:, :, :dim]).cpu().numpy())\n",
        "                masks.append(subsampled_mask.cpu().numpy())\n",
        "                tp.append(batch[:, :, -1].cpu().numpy())\n",
        "                if len(tp) % (n_max // 5) == 0:\n",
        "                    break\n",
        "    \n",
        "    pred_mean = np.concatenate(pred_mean, axis=1)\n",
        "    pred_std = np.concatenate(pred_std, axis=1)\n",
        "    targets = np.concatenate(targets, axis=0)\n",
        "    masks = np.concatenate(masks, axis=0)\n",
        "    tp = np.concatenate(tp, axis=0)\n",
        "    inputs = np.ma.masked_where(masks < 1., targets)\n",
        "    print(pred_mean.shape, pred_std.shape, targets.shape, masks.shape, tp.shape)\n",
        "    preds = np.random.randn(k_iwae // 2, k_iwae, pred_mean.shape[1], pred_mean.shape[2], pred_mean.shape[3]) * pred_std + pred_mean\n",
        "    preds = preds.reshape(-1, pred_mean.shape[1], pred_mean.shape[2], pred_mean.shape[3])\n",
        "    median = preds.mean(0) #np.quantile(preds, 0.5, axis=0)\n",
        "    quantile2 = np.quantile(preds, 0.841, axis=0)\n",
        "    quantile1 = np.quantile(preds, 0.159, axis=0)\n",
        "\n",
        "    w = 2.0\n",
        "    for index in range(n_max):\n",
        "        plt.figure(figsize=(12, 1.5))\n",
        "        for j in range(3):\n",
        "            plt.subplot(1, 3, j + 1)\n",
        "            plt.fill_between(tp[n_max * j + index], quantile1[n_max * j + index, :, 0], quantile2[n_max * j + index, :, 0], alpha=0.6, facecolor='#65c9f7', interpolate=True)\n",
        "            plt.plot(tp[n_max * j + index], median[n_max * j + index, :, 0], c='b', lw=w, label='Reconstructions')\n",
        "            #plt.plot(tp[n_max * j + index], gt[index], c='r', lw=w, label='Ground Truth')\n",
        "            plt.scatter(tp[n_max * j + index], inputs[n_max * j + index, :, 0], c='k', lw=w, label='Observed Data')\n",
        "            plt.xlim([0, 1])\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            if j == 1 and index == 0:\n",
        "                plt.legend(loc='upper center', ncol=3, bbox_to_anchor=(0.6,1.5))\n",
        "            \n",
        "        plt.show()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "N3keG-7Urr69",
        "outputId": "0c48a533-bd14-4361-c404-93d0ebd969ec"
      },
      "source": [
        "viz(train_loader, k_iwae=100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-8691c71035b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_iwae\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-165bda9664c4>\u001b[0m in \u001b[0;36mviz\u001b[0;34m(test_loader, k_iwae, n_max)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mrecon_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msubsampled_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mcontext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msubsampled_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampled_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_iwae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mpred_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mpred_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/vae_models.py\u001b[0m in \u001b[0;36mget_reconstruction\u001b[0;34m(self, context_x, context_y, target_x, num_samples)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/vae_models.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z, target_x)\u001b[0m\n\u001b[1;32m    119\u001b[0m         target_x = target_x[None, :, :].repeat(\n\u001b[1;32m    120\u001b[0m             num_sample, 1, 1).view(-1, target_x.shape[1])\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mpred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m    118\u001b[0m             x.size(0), -1, self.h, self.embed_time_k).transpose(1, 2)\n\u001b[1;32m    119\u001b[0m             for l, x in zip(self.linears, (query, key))]\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hetvae/src/layers.py\u001b[0m in \u001b[0;36mattention\u001b[0;34m(self, query, key, value, mask, dropout)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.51 GiB (GPU 0; 11.17 GiB total capacity; 10.68 GiB already allocated; 176.81 MiB free; 10.70 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgXlWxyhruho"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}