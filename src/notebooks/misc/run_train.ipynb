{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d77dedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "0dab4e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = ../../datasets/ZTF_rm_segments/Mrk817/ZTF_epoch2_1.7664847373962402.h5\n",
    "checkpoint=../checkpoints/exp_30/ZTF_gri0.8933992385864258.h5 \\\n",
    "    '../checkpoints/keep_rm/Mrk142/ZTF_Mrk142-1.336236834526062.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39622623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../checkpoints/g/ZTF_g0.9460071325302124.h5',\n",
       "  '../checkpoints/g/ZTF_g1.1252859830856323.h5',\n",
       "  '../checkpoints/g/ZTF_g1.1747798919677734.h5',\n",
       "  '../checkpoints/g/ZTF_g1.154257893562317.h5',\n",
       "  '../checkpoints/g/ZTF_g0.9446610808372498.h5',\n",
       "  '../checkpoints/g/ZTF_g1.1041532754898071.h5'],\n",
       " ['../checkpoints/r/ZTF_r0.9804754257202148.h5',\n",
       "  '../checkpoints/r/ZTF_r0.9801130294799805.h5'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob('../checkpoints/g/*'), glob.glob('../checkpoints/r/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e578cd19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py:233: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_name='config', config_path='conf')\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Namespace(data_folder='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_MCG+08-11-011_g', checkpoint=None, seed=2, device='mps', shuffle=False, start_col=1, test_split=0.2, sep='comma', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=1, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=100000, patience=100000, batch_size=2, k_iwae=1, lr=0.0001, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, reset=True, factor=0.9, lr_patience=500, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=False, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=False, min_length=0, print_at=10, save_at=200, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=12, is_bounded=False) 9018\n",
      "found 1 for band='g'\n",
      "max time:  1122.0078\n",
      "created union_tp attribute of length 3500\n",
      "dataset created, lcs.dataset.shape=(13, 1, 170, 3)\n",
      "train size: 10, valid size: 2, test size: 3\n",
      "model_size=218562\n",
      "1,/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/layers.py:83: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
      "2,3,4,5,6,7,8,9,10,\tIter: 10, train loss: 6.3779, avg nll: 1.4154, avg wnll: 32.1246, avg kl: 0.0053, mse: 0.991442, wmse: 8.045858, mae: 0.807467, val nll: 1.4299, val mse 1.0218, lr 0.000100000\n",
      "test nll: 1.3939, test mse: 0.9485\n",
      "11,12,13,14,15,16,17,18,19,20,\tIter: 20, train loss: 6.3917, avg nll: 1.4161, avg wnll: 32.1908, avg kl: 0.0039, mse: 0.994362, wmse: 7.994544, mae: 0.811893, val nll: 1.4339, val mse 1.0298, lr 0.000100000\n",
      "test nll: 1.4570, test mse: 1.0753\n",
      "21,22,23,24,25,26,27,28,29,30,\tIter: 30, train loss: 5.0586, avg nll: 1.2789, avg wnll: 26.1715, avg kl: 0.0565, mse: 0.744644, wmse: 6.019409, mae: 0.695316, val nll: 1.2262, val mse 0.6606, lr 0.000100000\n",
      "test nll: 1.2442, test mse: 0.6869\n",
      "31,32,33,34,35,36,37,38,39,40,\tIter: 40, train loss: 1.2509, avg nll: 0.5401, avg wnll: 10.4701, avg kl: 0.1984, mse: 0.102466, wmse: 0.840570, mae: 0.250452, val nll: 0.5556, val mse 0.1163, lr 0.000100000\n",
      "test nll: 0.5635, test mse: 0.1443\n",
      "41,42,43,44,45,46,47,48,49,50,\tIter: 50, train loss: 0.8459, avg nll: 0.2704, avg wnll: 19.3035, avg kl: 0.1632, mse: 0.082465, wmse: 0.680999, mae: 0.222653, val nll: 0.3835, val mse 0.1299, lr 0.000100000\n",
      "test nll: 0.1246, test mse: 0.0458\n",
      "51,52,53,54,55,56,57,58,59,60,\tIter: 60, train loss: 0.6975, avg nll: 0.1672, avg wnll: 29.2398, avg kl: 0.1367, mse: 0.078719, wmse: 0.647731, mae: 0.211601, val nll: 0.0314, val mse 0.0508, lr 0.000100000\n",
      "test nll: 0.2189, test mse: 0.0898\n",
      "61,62,63,64,65,66,67,68,69,70,\tIter: 70, train loss: 0.2298, avg nll: -0.1072, avg wnll: 22.1845, avg kl: 0.1271, mse: 0.041974, wmse: 0.348880, mae: 0.162734, val nll: -0.1765, val mse 0.0372, lr 0.000100000\n",
      "test nll: -0.0419, test mse: 0.0505\n",
      "71,72,73,74,75,76,77,78,79,80,\tIter: 80, train loss: 0.1442, avg nll: -0.1621, avg wnll: 29.0899, avg kl: 0.1123, mse: 0.038818, wmse: 0.323001, mae: 0.155548, val nll: -0.1452, val mse 0.0437, lr 0.000100000\n",
      "test nll: -0.1664, test mse: 0.0420\n",
      "81,82,83,84,85,86,87,88,89,90,\tIter: 90, train loss: 0.0755, avg nll: -0.2210, avg wnll: 28.9738, avg kl: 0.1049, mse: 0.038303, wmse: 0.320736, mae: 0.157181, val nll: -0.3846, val mse 0.0209, lr 0.000100000\n",
      "test nll: -0.3127, test mse: 0.0255\n",
      "91,92,93,94,95,96,97,98,99,100,\tIter: 100, train loss: -0.3272, avg nll: -0.5153, avg wnll: 29.5400, avg kl: 0.0853, mse: 0.020538, wmse: 0.170605, mae: 0.113201, val nll: -0.4325, val mse 0.0245, lr 0.000100000\n",
      "test nll: -0.5536, test mse: 0.0194\n",
      "101,102,103,104,105,106,107,108,109,110,\tIter: 110, train loss: -0.4017, avg nll: -0.5602, avg wnll: 21.4806, avg kl: 0.0702, mse: 0.017656, wmse: 0.146107, mae: 0.103236, val nll: -0.5347, val mse 0.0175, lr 0.000100000\n",
      "test nll: -0.5571, test mse: 0.0167\n",
      "111,112,113,114,115,116,117,118,119,120,\tIter: 120, train loss: -0.2397, avg nll: -0.4163, avg wnll: 39.2360, avg kl: 0.0558, mse: 0.024162, wmse: 0.201386, mae: 0.121332, val nll: -0.5163, val mse 0.0205, lr 0.000100000\n",
      "test nll: -0.6206, test mse: 0.0176\n",
      "121,122,123,124,125,126,127,128,129,130,\tIter: 130, train loss: -0.7331, avg nll: -0.8356, avg wnll: 26.1712, avg kl: 0.0495, mse: 0.010603, wmse: 0.088690, mae: 0.080899, val nll: -0.5772, val mse 0.0178, lr 0.000100000\n",
      "test nll: -0.5177, test mse: 0.0195\n",
      "131,132,133,134,135,136,137,138,139,140,\tIter: 140, train loss: -0.5999, avg nll: -0.7045, avg wnll: 17.2828, avg kl: 0.0435, mse: 0.012242, wmse: 0.101009, mae: 0.085375, val nll: -0.7252, val mse 0.0108, lr 0.000100000\n",
      "test nll: -0.7857, test mse: 0.0093\n",
      "141,142,143,144,145,146,147,148,149,150,\tIter: 150, train loss: -0.5952, avg nll: -0.7031, avg wnll: 29.2312, avg kl: 0.0361, mse: 0.014353, wmse: 0.123787, mae: 0.089312, val nll: -0.3708, val mse 0.0216, lr 0.000100000\n",
      "test nll: -0.8358, test mse: 0.0100\n",
      "151,152,153,154,155,156,157,158,159,160,\tIter: 160, train loss: -0.5445, avg nll: -0.6516, avg wnll: 44.8093, avg kl: 0.0340, mse: 0.014616, wmse: 0.123329, mae: 0.095662, val nll: -0.7452, val mse 0.0132, lr 0.000100000\n",
      "test nll: -0.8549, test mse: 0.0103\n",
      "161,162,163,164,165,166,167,168,169,170,\tIter: 170, train loss: -0.8244, avg nll: -0.8985, avg wnll: 28.7090, avg kl: 0.0265, mse: 0.009531, wmse: 0.079391, mae: 0.075528, val nll: -0.9003, val mse 0.0097, lr 0.000100000\n",
      "test nll: -0.9789, test mse: 0.0081\n",
      "171,172,173,174,175,176,177,178,179,180,\tIter: 180, train loss: -0.8707, avg nll: -0.9406, avg wnll: 32.7936, avg kl: 0.0259, mse: 0.008806, wmse: 0.073706, mae: 0.071451, val nll: -0.7973, val mse 0.0104, lr 0.000100000\n",
      "test nll: -0.9325, test mse: 0.0089\n",
      "181,182,183,184,185,186,187,188,189,190,\tIter: 190, train loss: -0.9120, avg nll: -0.9715, avg wnll: 29.5124, avg kl: 0.0179, mse: 0.008330, wmse: 0.069019, mae: 0.069955, val nll: -0.9967, val mse 0.0086, lr 0.000100000\n",
      "test nll: -1.0304, test mse: 0.0081\n",
      "191,192,193,194,195,196,197,198,199,200,\tIter: 200, train loss: -0.8261, avg nll: -0.8905, avg wnll: 37.5271, avg kl: 0.0162, mse: 0.009625, wmse: 0.080967, mae: 0.076907, val nll: -1.1082, val mse 0.0062, lr 0.000100000\n",
      "test nll: -1.0631, test mse: 0.0066\n",
      "saving.................\n",
      "done\n",
      "201,202,203,204,205,206,207,208,209,210,\tIter: 210, train loss: -0.8626, avg nll: -0.9246, avg wnll: 30.1538, avg kl: 0.0155, mse: 0.009308, wmse: 0.076869, mae: 0.073945, val nll: -0.7950, val mse 0.0120, lr 0.000100000\n",
      "test nll: -0.8875, test mse: 0.0100\n",
      "211,212,213,214,215,216,217,218,219,220,\tIter: 220, train loss: -0.8295, avg nll: -0.8915, avg wnll: 35.4909, avg kl: 0.0138, mse: 0.009665, wmse: 0.080465, mae: 0.078205, val nll: -0.9452, val mse 0.0088, lr 0.000100000\n",
      "test nll: -0.9886, test mse: 0.0077\n",
      "221,222,223,224,225,226,227,228,229,230,\tIter: 230, train loss: -0.8673, avg nll: -0.9232, avg wnll: 20.1367, avg kl: 0.0152, mse: 0.008150, wmse: 0.067548, mae: 0.070004, val nll: -0.9556, val mse 0.0077, lr 0.000100000\n",
      "test nll: -0.8698, test mse: 0.0087\n",
      "231,232,233,234,235,236,237,238,239,240,\tIter: 240, train loss: -1.0523, avg nll: -1.1049, avg wnll: 31.0344, avg kl: 0.0204, mse: 0.006421, wmse: 0.053541, mae: 0.060345, val nll: -1.0580, val mse 0.0070, lr 0.000100000\n",
      "test nll: -0.9289, test mse: 0.0089\n",
      "241,242,243,244,245,246,247,248,249,250,\tIter: 250, train loss: -0.8494, avg nll: -0.9071, avg wnll: 34.8360, avg kl: 0.0114, mse: 0.009244, wmse: 0.078953, mae: 0.075593, val nll: -1.0534, val mse 0.0066, lr 0.000100000\n",
      "test nll: -0.8404, test mse: 0.0105\n",
      "251,252,253,254,255,256,257,258,259,260,\tIter: 260, train loss: -1.0191, avg nll: -1.0642, avg wnll: 33.5919, avg kl: 0.0096, mse: 0.007100, wmse: 0.059219, mae: 0.064476, val nll: -1.0052, val mse 0.0079, lr 0.000100000\n",
      "test nll: -0.8743, test mse: 0.0098\n",
      "261,262,263,264,265,266,267,268,269,270,\tIter: 270, train loss: -0.8911, avg nll: -0.9423, avg wnll: 46.4617, avg kl: 0.0103, mse: 0.008171, wmse: 0.068757, mae: 0.069455, val nll: -0.7750, val mse 0.0118, lr 0.000100000\n",
      "test nll: -0.8444, test mse: 0.0097\n",
      "271,272,273,274,275,276,277,278,279,280,\tIter: 280, train loss: -0.6854, avg nll: -0.7496, avg wnll: 55.4433, avg kl: 0.0085, mse: 0.011129, wmse: 0.093374, mae: 0.084950, val nll: -0.0167, val mse 0.0209, lr 0.000100000\n",
      "test nll: 0.0960, test mse: 0.0232\n",
      "281,282,283,284,285,286,287,288,289,290,\tIter: 290, train loss: -0.9680, avg nll: -1.0150, avg wnll: 27.7032, avg kl: 0.0107, mse: 0.007271, wmse: 0.061983, mae: 0.066436, val nll: -1.1156, val mse 0.0062, lr 0.000100000\n",
      "test nll: -1.0552, test mse: 0.0069\n",
      "291,292,293,294,295,296,297,298,299,300,\tIter: 300, train loss: -1.1027, avg nll: -1.1397, avg wnll: 26.4377, avg kl: 0.0080, mse: 0.005815, wmse: 0.049108, mae: 0.058675, val nll: -1.1861, val mse 0.0050, lr 0.000100000\n",
      "test nll: -0.9611, test mse: 0.0085\n",
      "301,302,303,304,305,306,307,308,309,310,\tIter: 310, train loss: -1.0996, avg nll: -1.1352, avg wnll: 26.0877, avg kl: 0.0064, mse: 0.005832, wmse: 0.048993, mae: 0.058729, val nll: -1.0596, val mse 0.0071, lr 0.000100000\n",
      "test nll: -0.9955, test mse: 0.0081\n",
      "311,312,313,314,315,316,317,318,319,320,\tIter: 320, train loss: -1.0459, avg nll: -1.0839, avg wnll: 31.6119, avg kl: 0.0054, mse: 0.006540, wmse: 0.054440, mae: 0.063221, val nll: -1.0698, val mse 0.0067, lr 0.000100000\n",
      "test nll: -1.1357, test mse: 0.0059\n",
      "321,322,323,324,325,326,327,328,329,330,\tIter: 330, train loss: -1.1851, avg nll: -1.2153, avg wnll: 33.4471, avg kl: 0.0045, mse: 0.005154, wmse: 0.044198, mae: 0.054584, val nll: -1.1966, val mse 0.0054, lr 0.000100000\n",
      "test nll: -1.2638, test mse: 0.0048\n",
      "331,332,333,334,335,336,337,338,339,340,\tIter: 340, train loss: -1.0766, avg nll: -1.1133, avg wnll: 27.9373, avg kl: 0.0061, mse: 0.006135, wmse: 0.051205, mae: 0.060407, val nll: -1.0823, val mse 0.0067, lr 0.000100000\n",
      "test nll: -1.1049, test mse: 0.0065\n",
      "341,342,343,344,345,346,347,348,349,350,\tIter: 350, train loss: -1.0922, avg nll: -1.1271, avg wnll: 28.9514, avg kl: 0.0053, mse: 0.005931, wmse: 0.050538, mae: 0.061478, val nll: -0.9548, val mse 0.0085, lr 0.000100000\n",
      "test nll: -1.1408, test mse: 0.0060\n",
      "351,352,353,354,355,356,357,358,359,360,\tIter: 360, train loss: -0.8752, avg nll: -0.9284, avg wnll: 29.0597, avg kl: 0.0079, mse: 0.009049, wmse: 0.076260, mae: 0.075380, val nll: -0.8573, val mse 0.0099, lr 0.000100000\n",
      "test nll: -1.0511, test mse: 0.0060\n",
      "361,362,363,364,365,366,367,368,369,370,\tIter: 370, train loss: -1.0649, avg nll: -1.1024, avg wnll: 32.9511, avg kl: 0.0057, mse: 0.006360, wmse: 0.053153, mae: 0.063964, val nll: -0.9096, val mse 0.0089, lr 0.000100000\n",
      "test nll: -0.9261, test mse: 0.0087\n",
      "371,372,373,374,375,376,377,378,379,380,\tIter: 380, train loss: -0.9102, avg nll: -0.9564, avg wnll: 50.6985, avg kl: 0.0059, mse: 0.008045, wmse: 0.067075, mae: 0.069353, val nll: -1.1218, val mse 0.0063, lr 0.000100000\n",
      "test nll: -1.0210, test mse: 0.0077\n",
      "381,382,383,384,385,386,387,388,389,390,\tIter: 390, train loss: -1.0855, avg nll: -1.1211, avg wnll: 34.1084, avg kl: 0.0049, mse: 0.006127, wmse: 0.051094, mae: 0.061329, val nll: -1.2455, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.1642, test mse: 0.0056\n",
      "391,392,393,394,395,396,397,398,399,400,\tIter: 400, train loss: -1.1125, avg nll: -1.1461, avg wnll: 34.8543, avg kl: 0.0035, mse: 0.006025, wmse: 0.049757, mae: 0.059036, val nll: -1.1699, val mse 0.0057, lr 0.000100000\n",
      "test nll: -1.1697, test mse: 0.0058\n",
      "saving.................\n",
      "done\n",
      "401,402,403,404,405,406,407,408,409,410,\tIter: 410, train loss: -1.1638, avg nll: -1.1951, avg wnll: 29.4083, avg kl: 0.0050, mse: 0.005245, wmse: 0.043452, mae: 0.055069, val nll: -1.1705, val mse 0.0056, lr 0.000100000\n",
      "test nll: -1.0871, test mse: 0.0066\n",
      "411,412,413,414,415,416,417,418,419,420,\tIter: 420, train loss: -1.0653, avg nll: -1.1025, avg wnll: 28.8081, avg kl: 0.0059, mse: 0.006260, wmse: 0.051885, mae: 0.060951, val nll: -1.1844, val mse 0.0052, lr 0.000100000\n",
      "test nll: -1.0455, test mse: 0.0073\n",
      "421,422,423,424,425,426,427,428,429,430,\tIter: 430, train loss: -1.0655, avg nll: -1.1036, avg wnll: 29.6968, avg kl: 0.0063, mse: 0.006358, wmse: 0.052847, mae: 0.060810, val nll: -1.1567, val mse 0.0056, lr 0.000100000\n",
      "test nll: -1.0935, test mse: 0.0065\n",
      "431,432,433,434,435,436,437,438,439,440,\tIter: 440, train loss: -1.1944, avg nll: -1.2232, avg wnll: 36.2941, avg kl: 0.0042, mse: 0.004933, wmse: 0.041694, mae: 0.052520, val nll: -1.1495, val mse 0.0059, lr 0.000100000\n",
      "test nll: -1.0991, test mse: 0.0061\n",
      "441,442,443,444,445,446,447,448,449,450,\tIter: 450, train loss: -1.0431, avg nll: -1.0794, avg wnll: 41.6518, avg kl: 0.0028, mse: 0.006683, wmse: 0.056482, mae: 0.062925, val nll: -1.2524, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.1590, test mse: 0.0057\n",
      "451,452,453,454,455,456,457,458,459,460,\tIter: 460, train loss: -1.1678, avg nll: -1.1973, avg wnll: 31.5422, avg kl: 0.0029, mse: 0.005318, wmse: 0.044477, mae: 0.056033, val nll: -1.2511, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.1750, test mse: 0.0058\n",
      "461,462,463,464,465,466,467,468,469,470,\tIter: 470, train loss: -1.1837, avg nll: -1.2132, avg wnll: 29.6669, avg kl: 0.0043, mse: 0.005039, wmse: 0.042889, mae: 0.054569, val nll: -1.2962, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2047, test mse: 0.0053\n",
      "471,472,473,474,475,476,477,478,479,480,\tIter: 480, train loss: -1.2143, avg nll: -1.2429, avg wnll: 34.5020, avg kl: 0.0042, mse: 0.004873, wmse: 0.041054, mae: 0.053133, val nll: -1.1065, val mse 0.0061, lr 0.000100000\n",
      "test nll: -1.2247, test mse: 0.0051\n",
      "481,482,483,484,485,486,487,488,489,490,\tIter: 490, train loss: -1.1599, avg nll: -1.1895, avg wnll: 33.1175, avg kl: 0.0022, mse: 0.005480, wmse: 0.046227, mae: 0.056990, val nll: -1.0498, val mse 0.0070, lr 0.000100000\n",
      "test nll: -1.2697, test mse: 0.0046\n",
      "491,492,493,494,495,496,497,498,499,500,\tIter: 500, train loss: -1.1025, avg nll: -1.1345, avg wnll: 37.6870, avg kl: 0.0021, mse: 0.005970, wmse: 0.049804, mae: 0.058663, val nll: -1.2123, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.2977, test mse: 0.0042\n",
      "501,502,503,504,505,506,507,508,509,510,\tIter: 510, train loss: -1.1526, avg nll: -1.1831, avg wnll: 38.8033, avg kl: 0.0028, mse: 0.005547, wmse: 0.047899, mae: 0.055767, val nll: -1.2082, val mse 0.0054, lr 0.000100000\n",
      "test nll: -1.2014, test mse: 0.0054\n",
      "511,512,513,514,515,516,517,518,519,520,\tIter: 520, train loss: -1.2724, avg nll: -1.2970, avg wnll: 31.7728, avg kl: 0.0027, mse: 0.004383, wmse: 0.037152, mae: 0.049882, val nll: -1.3558, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.1460, test mse: 0.0060\n",
      "521,522,523,524,525,526,527,528,529,530,\tIter: 530, train loss: -1.2283, avg nll: -1.2542, avg wnll: 30.5560, avg kl: 0.0022, mse: 0.004741, wmse: 0.039452, mae: 0.050896, val nll: -1.2730, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.2343, test mse: 0.0051\n",
      "531,532,533,534,535,536,537,538,539,540,\tIter: 540, train loss: -1.2556, avg nll: -1.2797, avg wnll: 33.8870, avg kl: 0.0018, mse: 0.004468, wmse: 0.037823, mae: 0.051516, val nll: -1.2707, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.2207, test mse: 0.0051\n",
      "541,542,543,544,545,546,547,548,549,550,\tIter: 550, train loss: -1.2412, avg nll: -1.2665, avg wnll: 33.4602, avg kl: 0.0021, mse: 0.004639, wmse: 0.039557, mae: 0.053018, val nll: -1.1950, val mse 0.0055, lr 0.000100000\n",
      "test nll: -1.0378, test mse: 0.0069\n",
      "551,552,553,554,555,556,557,558,559,560,\tIter: 560, train loss: -1.2424, avg nll: -1.2672, avg wnll: 33.8147, avg kl: 0.0017, mse: 0.004614, wmse: 0.039282, mae: 0.051604, val nll: -1.2571, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.1651, test mse: 0.0057\n",
      "561,562,563,564,565,566,567,568,569,570,\tIter: 570, train loss: -1.1800, avg nll: -1.2082, avg wnll: 36.9728, avg kl: 0.0016, mse: 0.005316, wmse: 0.044564, mae: 0.054906, val nll: -1.2253, val mse 0.0049, lr 0.000100000\n",
      "test nll: -1.2439, test mse: 0.0050\n",
      "571,572,573,574,575,576,577,578,579,580,\tIter: 580, train loss: -1.2242, avg nll: -1.2506, avg wnll: 29.4185, avg kl: 0.0024, mse: 0.004818, wmse: 0.040253, mae: 0.052591, val nll: -1.1099, val mse 0.0061, lr 0.000100000\n",
      "test nll: -1.0721, test mse: 0.0068\n",
      "581,582,583,584,585,586,587,588,589,590,\tIter: 590, train loss: -1.2098, avg nll: -1.2367, avg wnll: 35.9566, avg kl: 0.0025, mse: 0.004871, wmse: 0.041718, mae: 0.054415, val nll: -1.2526, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.2412, test mse: 0.0047\n",
      "591,592,593,594,595,596,597,598,599,600,\tIter: 600, train loss: -1.1456, avg nll: -1.1761, avg wnll: 34.2347, avg kl: 0.0024, mse: 0.005633, wmse: 0.046923, mae: 0.055564, val nll: -1.1201, val mse 0.0063, lr 0.000100000\n",
      "test nll: -1.2434, test mse: 0.0048\n",
      "saving.................\n",
      "done\n",
      "601,602,603,604,605,606,607,608,609,610,\tIter: 610, train loss: -1.1336, avg nll: -1.1644, avg wnll: 41.1635, avg kl: 0.0023, mse: 0.005700, wmse: 0.047589, mae: 0.057861, val nll: -1.2982, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.0734, test mse: 0.0065\n",
      "611,612,613,614,615,616,617,618,619,620,\tIter: 620, train loss: -1.2447, avg nll: -1.2695, avg wnll: 28.0606, avg kl: 0.0020, mse: 0.004558, wmse: 0.038765, mae: 0.050861, val nll: -1.3244, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.2681, test mse: 0.0046\n",
      "621,622,623,624,625,626,627,628,629,630,\tIter: 630, train loss: -1.0390, avg nll: -1.0744, avg wnll: 45.8939, avg kl: 0.0027, mse: 0.006539, wmse: 0.054669, mae: 0.063365, val nll: -1.0350, val mse 0.0077, lr 0.000100000\n",
      "test nll: -1.1525, test mse: 0.0061\n",
      "631,632,633,634,635,636,637,638,639,640,\tIter: 640, train loss: -1.1239, avg nll: -1.1552, avg wnll: 36.1977, avg kl: 0.0024, mse: 0.005767, wmse: 0.047875, mae: 0.057982, val nll: -1.2326, val mse 0.0049, lr 0.000100000\n",
      "test nll: -1.1805, test mse: 0.0055\n",
      "641,642,643,644,645,646,647,648,649,650,\tIter: 650, train loss: -1.2113, avg nll: -1.2371, avg wnll: 26.9782, avg kl: 0.0019, mse: 0.004794, wmse: 0.040355, mae: 0.052375, val nll: -1.1579, val mse 0.0060, lr 0.000100000\n",
      "test nll: -1.2749, test mse: 0.0045\n",
      "651,652,653,654,655,656,657,658,659,660,\tIter: 660, train loss: -1.2421, avg nll: -1.2668, avg wnll: 32.6609, avg kl: 0.0015, mse: 0.004643, wmse: 0.038858, mae: 0.052048, val nll: -1.0170, val mse 0.0068, lr 0.000100000\n",
      "test nll: -1.1238, test mse: 0.0063\n",
      "661,662,663,664,665,666,667,668,669,670,\tIter: 670, train loss: -1.2430, avg nll: -1.2684, avg wnll: 24.6058, avg kl: 0.0028, mse: 0.004527, wmse: 0.037365, mae: 0.050799, val nll: -1.2660, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.2518, test mse: 0.0048\n",
      "671,672,673,674,675,676,677,678,679,680,\tIter: 680, train loss: -1.1073, avg nll: -1.1390, avg wnll: 24.9265, avg kl: 0.0035, mse: 0.005640, wmse: 0.047287, mae: 0.057543, val nll: -1.1982, val mse 0.0050, lr 0.000100000\n",
      "test nll: -1.1121, test mse: 0.0063\n",
      "681,682,683,684,685,686,687,688,689,690,\tIter: 690, train loss: -1.2623, avg nll: -1.2871, avg wnll: 34.0615, avg kl: 0.0023, mse: 0.004511, wmse: 0.037861, mae: 0.051349, val nll: -1.0374, val mse 0.0068, lr 0.000100000\n",
      "test nll: -1.0911, test mse: 0.0064\n",
      "691,692,693,694,695,696,697,698,699,700,\tIter: 700, train loss: -1.1853, avg nll: -1.2133, avg wnll: 37.7776, avg kl: 0.0018, mse: 0.005234, wmse: 0.043946, mae: 0.056314, val nll: -1.3162, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.1868, test mse: 0.0056\n",
      "701,702,703,704,705,706,707,708,709,710,\tIter: 710, train loss: -1.0669, avg nll: -1.1028, avg wnll: 39.3598, avg kl: 0.0033, mse: 0.006530, wmse: 0.056239, mae: 0.062672, val nll: -1.2140, val mse 0.0049, lr 0.000100000\n",
      "test nll: -1.1782, test mse: 0.0054\n",
      "711,712,713,714,715,716,717,718,719,720,\tIter: 720, train loss: -1.2186, avg nll: -1.2452, avg wnll: 36.3581, avg kl: 0.0025, mse: 0.004817, wmse: 0.039950, mae: 0.053608, val nll: -1.2284, val mse 0.0050, lr 0.000100000\n",
      "test nll: -1.3143, test mse: 0.0043\n",
      "721,722,723,724,725,726,727,728,729,730,\tIter: 730, train loss: -1.2000, avg nll: -1.2278, avg wnll: 29.8710, avg kl: 0.0024, mse: 0.005084, wmse: 0.041998, mae: 0.054266, val nll: -0.9335, val mse 0.0083, lr 0.000100000\n",
      "test nll: -1.1031, test mse: 0.0067\n",
      "731,732,733,734,735,736,737,738,739,740,\tIter: 740, train loss: -1.1838, avg nll: -1.2115, avg wnll: 42.2027, avg kl: 0.0023, mse: 0.005066, wmse: 0.042679, mae: 0.055925, val nll: -1.1472, val mse 0.0058, lr 0.000100000\n",
      "test nll: -1.2062, test mse: 0.0053\n",
      "741,742,743,744,745,746,747,748,749,750,\tIter: 750, train loss: -1.1161, avg nll: -1.1479, avg wnll: 38.1208, avg kl: 0.0021, mse: 0.005946, wmse: 0.050326, mae: 0.058402, val nll: -1.1578, val mse 0.0060, lr 0.000100000\n",
      "test nll: -1.0496, test mse: 0.0070\n",
      "751,752,753,754,755,756,757,758,759,760,\tIter: 760, train loss: -1.2459, avg nll: -1.2711, avg wnll: 30.7678, avg kl: 0.0018, mse: 0.004682, wmse: 0.039233, mae: 0.051696, val nll: -1.2721, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.2728, test mse: 0.0044\n",
      "761,762,763,764,765,766,767,768,769,770,\tIter: 770, train loss: -1.2850, avg nll: -1.3081, avg wnll: 30.6427, avg kl: 0.0016, mse: 0.004297, wmse: 0.036198, mae: 0.050565, val nll: -0.9891, val mse 0.0071, lr 0.000100000\n",
      "test nll: -1.3252, test mse: 0.0042\n",
      "771,772,773,774,775,776,777,778,779,780,\tIter: 780, train loss: -1.2046, avg nll: -1.2318, avg wnll: 33.7231, avg kl: 0.0021, mse: 0.005038, wmse: 0.042147, mae: 0.054160, val nll: -1.2460, val mse 0.0049, lr 0.000100000\n",
      "test nll: -1.1279, test mse: 0.0063\n",
      "781,782,783,784,785,786,787,788,789,790,\tIter: 790, train loss: -1.2384, avg nll: -1.2637, avg wnll: 30.8916, avg kl: 0.0016, mse: 0.004746, wmse: 0.039243, mae: 0.051148, val nll: -0.7468, val mse 0.0094, lr 0.000100000\n",
      "test nll: -1.1976, test mse: 0.0055\n",
      "791,792,793,794,795,796,797,798,799,800,\tIter: 800, train loss: -1.1306, avg nll: -1.1621, avg wnll: 33.1755, avg kl: 0.0027, mse: 0.005773, wmse: 0.047597, mae: 0.058585, val nll: -1.1688, val mse 0.0059, lr 0.000100000\n",
      "test nll: -0.9639, test mse: 0.0077\n",
      "saving.................\n",
      "done\n",
      "801,802,803,804,805,806,807,808,809,810,\tIter: 810, train loss: -1.1310, avg nll: -1.1625, avg wnll: 36.5598, avg kl: 0.0028, mse: 0.005721, wmse: 0.047348, mae: 0.058263, val nll: -0.9362, val mse 0.0082, lr 0.000100000\n",
      "test nll: -0.8773, test mse: 0.0091\n",
      "811,812,813,814,815,816,817,818,819,820,\tIter: 820, train loss: -1.1520, avg nll: -1.1812, avg wnll: 29.4130, avg kl: 0.0023, mse: 0.005373, wmse: 0.045638, mae: 0.057385, val nll: -1.2246, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.2248, test mse: 0.0050\n",
      "821,822,823,824,825,826,827,828,829,830,\tIter: 830, train loss: -1.1845, avg nll: -1.2125, avg wnll: 34.1803, avg kl: 0.0017, mse: 0.005251, wmse: 0.043777, mae: 0.056064, val nll: -1.2431, val mse 0.0049, lr 0.000100000\n",
      "test nll: -0.9430, test mse: 0.0080\n",
      "831,832,833,834,835,836,837,838,839,840,\tIter: 840, train loss: -1.0797, avg nll: -1.1121, avg wnll: 46.1858, avg kl: 0.0014, mse: 0.006195, wmse: 0.051723, mae: 0.060145, val nll: -1.0492, val mse 0.0068, lr 0.000100000\n",
      "test nll: -1.3734, test mse: 0.0036\n",
      "841,842,843,844,845,846,847,848,849,850,\tIter: 850, train loss: -1.2125, avg nll: -1.2388, avg wnll: 35.2501, avg kl: 0.0013, mse: 0.005010, wmse: 0.041475, mae: 0.052534, val nll: -1.3313, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.1573, test mse: 0.0056\n",
      "851,852,853,854,855,856,857,858,859,860,\tIter: 860, train loss: -1.0721, avg nll: -1.1067, avg wnll: 27.1356, avg kl: 0.0034, mse: 0.006226, wmse: 0.052822, mae: 0.060900, val nll: -1.1701, val mse 0.0055, lr 0.000100000\n",
      "test nll: -1.2264, test mse: 0.0045\n",
      "861,862,863,864,865,866,867,868,869,870,\tIter: 870, train loss: -1.1652, avg nll: -1.1944, avg wnll: 40.0913, avg kl: 0.0026, mse: 0.005337, wmse: 0.044830, mae: 0.056678, val nll: -1.2192, val mse 0.0053, lr 0.000100000\n",
      "test nll: -1.2394, test mse: 0.0050\n",
      "871,872,873,874,875,876,877,878,879,880,\tIter: 880, train loss: -1.1231, avg nll: -1.1541, avg wnll: 40.6679, avg kl: 0.0018, mse: 0.005841, wmse: 0.048824, mae: 0.058979, val nll: -1.2995, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2352, test mse: 0.0051\n",
      "881,882,883,884,885,886,887,888,889,890,\tIter: 890, train loss: -1.1489, avg nll: -1.1792, avg wnll: 33.5355, avg kl: 0.0021, mse: 0.005646, wmse: 0.047789, mae: 0.057663, val nll: -1.1822, val mse 0.0057, lr 0.000100000\n",
      "test nll: -1.0556, test mse: 0.0071\n",
      "891,892,893,894,895,896,897,898,899,900,\tIter: 900, train loss: -1.1955, avg nll: -1.2224, avg wnll: 31.9877, avg kl: 0.0015, mse: 0.005077, wmse: 0.042886, mae: 0.053984, val nll: -1.2300, val mse 0.0050, lr 0.000100000\n",
      "test nll: -1.2459, test mse: 0.0049\n",
      "901,902,903,904,905,906,907,908,909,910,\tIter: 910, train loss: -1.1162, avg nll: -1.1487, avg wnll: 41.8201, avg kl: 0.0025, mse: 0.005999, wmse: 0.050946, mae: 0.059331, val nll: -1.3044, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2715, test mse: 0.0048\n",
      "911,912,913,914,915,916,917,918,919,920,\tIter: 920, train loss: -1.2637, avg nll: -1.2876, avg wnll: 34.5181, avg kl: 0.0012, mse: 0.004524, wmse: 0.038150, mae: 0.052287, val nll: -1.3262, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2872, test mse: 0.0047\n",
      "921,922,923,924,925,926,927,928,929,930,\tIter: 930, train loss: -1.2589, avg nll: -1.2835, avg wnll: 36.7050, avg kl: 0.0011, mse: 0.004699, wmse: 0.039986, mae: 0.051993, val nll: -1.3254, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3168, test mse: 0.0043\n",
      "931,932,933,934,935,936,937,938,939,940,\tIter: 940, train loss: -1.2891, avg nll: -1.3112, avg wnll: 32.4062, avg kl: 0.0009, mse: 0.004245, wmse: 0.035654, mae: 0.049450, val nll: -1.2585, val mse 0.0049, lr 0.000100000\n",
      "test nll: -1.2912, test mse: 0.0046\n",
      "941,942,943,944,945,946,947,948,949,950,\tIter: 950, train loss: -1.2842, avg nll: -1.3070, avg wnll: 34.5679, avg kl: 0.0010, mse: 0.004352, wmse: 0.037007, mae: 0.049976, val nll: -1.3027, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.3089, test mse: 0.0044\n",
      "951,952,953,954,955,956,957,958,959,960,\tIter: 960, train loss: -1.2502, avg nll: -1.2749, avg wnll: 35.3456, avg kl: 0.0013, mse: 0.004663, wmse: 0.039144, mae: 0.051675, val nll: -1.2920, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2647, test mse: 0.0047\n",
      "961,962,963,964,965,966,967,968,969,970,\tIter: 970, train loss: -1.2404, avg nll: -1.2654, avg wnll: 33.5192, avg kl: 0.0011, mse: 0.004785, wmse: 0.039284, mae: 0.052214, val nll: -1.2397, val mse 0.0050, lr 0.000100000\n",
      "test nll: -1.2145, test mse: 0.0053\n",
      "971,972,973,974,975,976,977,978,979,980,\tIter: 980, train loss: -1.2417, avg nll: -1.2669, avg wnll: 31.8190, avg kl: 0.0018, mse: 0.004680, wmse: 0.039425, mae: 0.052106, val nll: -1.2717, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.2726, test mse: 0.0047\n",
      "981,982,983,984,985,986,987,988,989,990,\tIter: 990, train loss: -1.3011, avg nll: -1.3233, avg wnll: 36.6741, avg kl: 0.0009, mse: 0.004244, wmse: 0.035549, mae: 0.048182, val nll: -1.3281, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3751, test mse: 0.0039\n",
      "991,992,993,994,995,996,997,998,999,1000,\tIter: 1000, train loss: -1.2399, avg nll: -1.2646, avg wnll: 34.9422, avg kl: 0.0013, mse: 0.004689, wmse: 0.039636, mae: 0.052802, val nll: -1.2314, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.1997, test mse: 0.0054\n",
      "saving.................\n",
      "done\n",
      "1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,\tIter: 1010, train loss: -1.3007, avg nll: -1.3230, avg wnll: 36.2899, avg kl: 0.0012, mse: 0.004227, wmse: 0.035304, mae: 0.048756, val nll: -1.3414, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3234, test mse: 0.0042\n",
      "1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,\tIter: 1020, train loss: -1.3114, avg nll: -1.3332, avg wnll: 29.3226, avg kl: 0.0016, mse: 0.004041, wmse: 0.033866, mae: 0.048636, val nll: -1.3881, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.3730, test mse: 0.0038\n",
      "1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,\tIter: 1030, train loss: -1.3270, avg nll: -1.3478, avg wnll: 30.8547, avg kl: 0.0007, mse: 0.004035, wmse: 0.034177, mae: 0.048937, val nll: -1.3165, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.2704, test mse: 0.0048\n",
      "1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,\tIter: 1040, train loss: -1.2029, avg nll: -1.2291, avg wnll: 42.3676, avg kl: 0.0008, mse: 0.005059, wmse: 0.042864, mae: 0.054825, val nll: -1.1674, val mse 0.0054, lr 0.000100000\n",
      "test nll: -1.3136, test mse: 0.0044\n",
      "1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,\tIter: 1050, train loss: -1.2785, avg nll: -1.3012, avg wnll: 33.9826, avg kl: 0.0009, mse: 0.004354, wmse: 0.036150, mae: 0.049912, val nll: -1.1007, val mse 0.0059, lr 0.000100000\n",
      "test nll: -1.2906, test mse: 0.0045\n",
      "1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,\tIter: 1060, train loss: -1.2971, avg nll: -1.3201, avg wnll: 31.7857, avg kl: 0.0014, mse: 0.004305, wmse: 0.036535, mae: 0.049000, val nll: -1.3184, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.3514, test mse: 0.0040\n",
      "1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,\tIter: 1070, train loss: -1.2908, avg nll: -1.3134, avg wnll: 35.3410, avg kl: 0.0010, mse: 0.004346, wmse: 0.036768, mae: 0.048811, val nll: -1.3238, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3802, test mse: 0.0038\n",
      "1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,\tIter: 1080, train loss: -1.2450, avg nll: -1.2696, avg wnll: 36.6081, avg kl: 0.0011, mse: 0.004700, wmse: 0.039320, mae: 0.054107, val nll: -1.1650, val mse 0.0057, lr 0.000100000\n",
      "test nll: -1.0487, test mse: 0.0068\n",
      "1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,\tIter: 1090, train loss: -1.2172, avg nll: -1.2434, avg wnll: 36.7092, avg kl: 0.0013, mse: 0.004985, wmse: 0.042856, mae: 0.053759, val nll: -1.2145, val mse 0.0053, lr 0.000100000\n",
      "test nll: -1.2063, test mse: 0.0053\n",
      "1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,\tIter: 1100, train loss: -1.2631, avg nll: -1.2865, avg wnll: 23.6482, avg kl: 0.0023, mse: 0.004200, wmse: 0.035126, mae: 0.050754, val nll: -1.3449, val mse 0.0036, lr 0.000100000\n",
      "test nll: -1.2617, test mse: 0.0046\n",
      "1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,\tIter: 1110, train loss: -1.2887, avg nll: -1.3115, avg wnll: 33.4856, avg kl: 0.0012, mse: 0.004313, wmse: 0.036162, mae: 0.050303, val nll: -1.3700, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.3145, test mse: 0.0044\n",
      "1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,\tIter: 1120, train loss: -1.1697, avg nll: -1.1984, avg wnll: 40.1450, avg kl: 0.0016, mse: 0.005434, wmse: 0.046444, mae: 0.057790, val nll: -1.2654, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.2252, test mse: 0.0052\n",
      "1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,\tIter: 1130, train loss: -1.2588, avg nll: -1.2828, avg wnll: 36.9295, avg kl: 0.0010, mse: 0.004598, wmse: 0.038772, mae: 0.051124, val nll: -1.3333, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2941, test mse: 0.0045\n",
      "1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,\tIter: 1140, train loss: -1.1822, avg nll: -1.2105, avg wnll: 35.9706, avg kl: 0.0014, mse: 0.005380, wmse: 0.045369, mae: 0.054592, val nll: -1.2661, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.2719, test mse: 0.0047\n",
      "1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,\tIter: 1150, train loss: -1.2058, avg nll: -1.2324, avg wnll: 38.1311, avg kl: 0.0016, mse: 0.005004, wmse: 0.041979, mae: 0.055324, val nll: -1.2938, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.3017, test mse: 0.0045\n",
      "1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,\tIter: 1160, train loss: -1.2004, avg nll: -1.2269, avg wnll: 28.9578, avg kl: 0.0018, mse: 0.004942, wmse: 0.041197, mae: 0.053937, val nll: -1.2942, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2096, test mse: 0.0055\n",
      "1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,\tIter: 1170, train loss: -1.2811, avg nll: -1.3048, avg wnll: 30.6856, avg kl: 0.0018, mse: 0.004379, wmse: 0.036402, mae: 0.049997, val nll: -1.2592, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.3056, test mse: 0.0044\n",
      "1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,\tIter: 1180, train loss: -1.2860, avg nll: -1.3092, avg wnll: 33.2008, avg kl: 0.0013, mse: 0.004377, wmse: 0.037171, mae: 0.050308, val nll: -1.3939, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.2986, test mse: 0.0045\n",
      "1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,\tIter: 1190, train loss: -1.2887, avg nll: -1.3115, avg wnll: 28.9407, avg kl: 0.0014, mse: 0.004271, wmse: 0.035567, mae: 0.049983, val nll: -1.3564, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.2064, test mse: 0.0055\n",
      "1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,\tIter: 1200, train loss: -1.2809, avg nll: -1.3041, avg wnll: 34.8830, avg kl: 0.0012, mse: 0.004406, wmse: 0.036982, mae: 0.051224, val nll: -1.3231, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3811, test mse: 0.0037\n",
      "saving.................\n",
      "done\n",
      "1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,\tIter: 1210, train loss: -1.1746, avg nll: -1.2021, avg wnll: 39.9010, avg kl: 0.0011, mse: 0.005271, wmse: 0.044635, mae: 0.055385, val nll: -0.9399, val mse 0.0079, lr 0.000100000\n",
      "test nll: -0.8197, test mse: 0.0091\n",
      "1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,\tIter: 1220, train loss: -1.3304, avg nll: -1.3517, avg wnll: 27.9749, avg kl: 0.0016, mse: 0.003922, wmse: 0.033057, mae: 0.047635, val nll: -1.0562, val mse 0.0070, lr 0.000100000\n",
      "test nll: -1.2921, test mse: 0.0046\n",
      "1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,\tIter: 1230, train loss: -1.2142, avg nll: -1.2409, avg wnll: 31.6380, avg kl: 0.0021, mse: 0.004914, wmse: 0.041664, mae: 0.054990, val nll: -1.2244, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.0925, test mse: 0.0068\n",
      "1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,\tIter: 1240, train loss: -1.3022, avg nll: -1.3249, avg wnll: 31.1386, avg kl: 0.0015, mse: 0.004226, wmse: 0.035649, mae: 0.050746, val nll: -1.3680, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.2300, test mse: 0.0054\n",
      "1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,\tIter: 1250, train loss: -1.3407, avg nll: -1.3616, avg wnll: 30.9217, avg kl: 0.0009, mse: 0.004009, wmse: 0.033459, mae: 0.047102, val nll: -1.3074, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.3762, test mse: 0.0038\n",
      "1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,\tIter: 1260, train loss: -1.2591, avg nll: -1.2829, avg wnll: 36.7726, avg kl: 0.0007, mse: 0.004611, wmse: 0.038644, mae: 0.053101, val nll: -1.2672, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.2569, test mse: 0.0049\n",
      "1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,\tIter: 1270, train loss: -1.3225, avg nll: -1.3444, avg wnll: 29.7062, avg kl: 0.0016, mse: 0.004074, wmse: 0.034191, mae: 0.048938, val nll: -1.3600, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.3534, test mse: 0.0039\n",
      "1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,\tIter: 1280, train loss: -1.1938, avg nll: -1.2225, avg wnll: 30.7288, avg kl: 0.0026, mse: 0.005225, wmse: 0.043127, mae: 0.055338, val nll: -1.2353, val mse 0.0049, lr 0.000100000\n",
      "test nll: -1.2039, test mse: 0.0054\n",
      "1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,\tIter: 1290, train loss: -1.2095, avg nll: -1.2364, avg wnll: 39.0113, avg kl: 0.0015, mse: 0.005099, wmse: 0.042798, mae: 0.054031, val nll: -1.3076, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.1920, test mse: 0.0057\n",
      "1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,\tIter: 1300, train loss: -1.2370, avg nll: -1.2622, avg wnll: 34.1441, avg kl: 0.0012, mse: 0.004814, wmse: 0.040716, mae: 0.051959, val nll: -1.2790, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.3816, test mse: 0.0035\n",
      "1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,\tIter: 1310, train loss: -1.1940, avg nll: -1.2206, avg wnll: 37.3412, avg kl: 0.0012, mse: 0.005084, wmse: 0.042235, mae: 0.054255, val nll: -1.2586, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.2112, test mse: 0.0053\n",
      "1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,\tIter: 1320, train loss: -1.2595, avg nll: -1.2834, avg wnll: 38.2216, avg kl: 0.0008, mse: 0.004620, wmse: 0.038910, mae: 0.051368, val nll: -1.2793, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.4174, test mse: 0.0034\n",
      "1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,\tIter: 1330, train loss: -1.2285, avg nll: -1.2547, avg wnll: 32.5615, avg kl: 0.0018, mse: 0.004895, wmse: 0.040662, mae: 0.051377, val nll: -1.3637, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.2245, test mse: 0.0053\n",
      "1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,\tIter: 1340, train loss: -1.2243, avg nll: -1.2502, avg wnll: 39.3880, avg kl: 0.0013, mse: 0.004912, wmse: 0.040883, mae: 0.054222, val nll: -1.3333, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.3519, test mse: 0.0042\n",
      "1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,\tIter: 1350, train loss: -1.2567, avg nll: -1.2806, avg wnll: 37.0160, avg kl: 0.0011, mse: 0.004564, wmse: 0.038295, mae: 0.051382, val nll: -1.2164, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.3321, test mse: 0.0041\n",
      "1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,\tIter: 1360, train loss: -1.2276, avg nll: -1.2532, avg wnll: 39.7412, avg kl: 0.0012, mse: 0.004873, wmse: 0.041208, mae: 0.053016, val nll: -1.2135, val mse 0.0053, lr 0.000100000\n",
      "test nll: -1.2283, test mse: 0.0051\n",
      "1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,\tIter: 1370, train loss: -1.2457, avg nll: -1.2718, avg wnll: 31.4218, avg kl: 0.0025, mse: 0.004730, wmse: 0.039986, mae: 0.052522, val nll: -1.1932, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.1478, test mse: 0.0059\n",
      "1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,\tIter: 1380, train loss: -1.1350, avg nll: -1.1647, avg wnll: 40.5111, avg kl: 0.0017, mse: 0.005589, wmse: 0.046214, mae: 0.057887, val nll: -1.0896, val mse 0.0064, lr 0.000100000\n",
      "test nll: -1.0695, test mse: 0.0067\n",
      "1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,\tIter: 1390, train loss: -1.2721, avg nll: -1.2952, avg wnll: 35.2221, avg kl: 0.0009, mse: 0.004445, wmse: 0.036869, mae: 0.050162, val nll: -1.3252, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3447, test mse: 0.0042\n",
      "1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,\tIter: 1400, train loss: -1.2782, avg nll: -1.3017, avg wnll: 28.3133, avg kl: 0.0013, mse: 0.004428, wmse: 0.037273, mae: 0.049787, val nll: -1.2906, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2167, test mse: 0.0054\n",
      "saving.................\n",
      "done\n",
      "1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,\tIter: 1410, train loss: -1.2684, avg nll: -1.2922, avg wnll: 39.5763, avg kl: 0.0010, mse: 0.004570, wmse: 0.038430, mae: 0.051530, val nll: -1.2833, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.2743, test mse: 0.0049\n",
      "1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,\tIter: 1420, train loss: -1.2109, avg nll: -1.2373, avg wnll: 31.9945, avg kl: 0.0012, mse: 0.005051, wmse: 0.042332, mae: 0.054194, val nll: -1.1654, val mse 0.0058, lr 0.000100000\n",
      "test nll: -1.2050, test mse: 0.0055\n",
      "1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,\tIter: 1430, train loss: -1.2847, avg nll: -1.3074, avg wnll: 36.8314, avg kl: 0.0012, mse: 0.004296, wmse: 0.035833, mae: 0.050143, val nll: -1.3344, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2918, test mse: 0.0047\n",
      "1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,\tIter: 1440, train loss: -1.2187, avg nll: -1.2447, avg wnll: 36.3741, avg kl: 0.0008, mse: 0.005042, wmse: 0.041825, mae: 0.053900, val nll: -1.2741, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.1706, test mse: 0.0058\n",
      "1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,\tIter: 1450, train loss: -1.2737, avg nll: -1.2977, avg wnll: 36.9482, avg kl: 0.0011, mse: 0.004570, wmse: 0.038666, mae: 0.050841, val nll: -1.2530, val mse 0.0049, lr 0.000100000\n",
      "test nll: -1.3029, test mse: 0.0047\n",
      "1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,\tIter: 1460, train loss: -1.2409, avg nll: -1.2656, avg wnll: 33.3027, avg kl: 0.0008, mse: 0.004792, wmse: 0.039936, mae: 0.052332, val nll: -1.4126, val mse 0.0033, lr 0.000100000\n",
      "test nll: -1.3584, test mse: 0.0038\n",
      "1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,\tIter: 1470, train loss: -1.3803, avg nll: -1.3993, avg wnll: 32.1350, avg kl: 0.0007, mse: 0.003658, wmse: 0.030629, mae: 0.046710, val nll: -1.3103, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.3474, test mse: 0.0043\n",
      "1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,\tIter: 1480, train loss: -1.2788, avg nll: -1.3025, avg wnll: 35.6329, avg kl: 0.0010, mse: 0.004547, wmse: 0.037911, mae: 0.050919, val nll: -1.3211, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3096, test mse: 0.0046\n",
      "1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,\tIter: 1490, train loss: -1.1356, avg nll: -1.1656, avg wnll: 42.9658, avg kl: 0.0012, mse: 0.005753, wmse: 0.048894, mae: 0.058333, val nll: -1.1374, val mse 0.0062, lr 0.000100000\n",
      "test nll: -1.1729, test mse: 0.0058\n",
      "1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,\tIter: 1500, train loss: -1.2935, avg nll: -1.3162, avg wnll: 37.8997, avg kl: 0.0006, mse: 0.004430, wmse: 0.037524, mae: 0.050407, val nll: -1.4040, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3056, test mse: 0.0046\n",
      "1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,\tIter: 1510, train loss: -1.3105, avg nll: -1.3322, avg wnll: 32.1358, avg kl: 0.0008, mse: 0.004193, wmse: 0.034759, mae: 0.049166, val nll: -1.3470, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3017, test mse: 0.0047\n",
      "1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,\tIter: 1520, train loss: -1.3527, avg nll: -1.3734, avg wnll: 34.0094, avg kl: 0.0010, mse: 0.003938, wmse: 0.033359, mae: 0.047096, val nll: -1.2978, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3368, test mse: 0.0043\n",
      "1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,\tIter: 1530, train loss: -1.3430, avg nll: -1.3641, avg wnll: 31.8933, avg kl: 0.0009, mse: 0.004018, wmse: 0.033768, mae: 0.047326, val nll: -1.3806, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.3043, test mse: 0.0045\n",
      "1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,\tIter: 1540, train loss: -1.2485, avg nll: -1.2735, avg wnll: 38.5825, avg kl: 0.0009, mse: 0.004820, wmse: 0.041005, mae: 0.051727, val nll: -1.3422, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.1650, test mse: 0.0059\n",
      "1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,\tIter: 1550, train loss: -1.2609, avg nll: -1.2844, avg wnll: 22.3992, avg kl: 0.0020, mse: 0.004286, wmse: 0.035786, mae: 0.049383, val nll: -1.3487, val mse 0.0034, lr 0.000100000\n",
      "test nll: -1.1149, test mse: 0.0063\n",
      "1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,\tIter: 1560, train loss: -1.2350, avg nll: -1.2603, avg wnll: 34.4308, avg kl: 0.0014, mse: 0.004783, wmse: 0.039944, mae: 0.053320, val nll: -1.1329, val mse 0.0062, lr 0.000100000\n",
      "test nll: -1.1760, test mse: 0.0060\n",
      "1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,\tIter: 1570, train loss: -1.1186, avg nll: -1.1496, avg wnll: 38.0257, avg kl: 0.0016, mse: 0.005876, wmse: 0.048834, mae: 0.058707, val nll: -1.2690, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.2702, test mse: 0.0047\n",
      "1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,\tIter: 1580, train loss: -1.2448, avg nll: -1.2701, avg wnll: 30.5699, avg kl: 0.0019, mse: 0.004669, wmse: 0.038640, mae: 0.052750, val nll: -1.3171, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.1361, test mse: 0.0061\n",
      "1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,\tIter: 1590, train loss: -1.2221, avg nll: -1.2488, avg wnll: 33.6282, avg kl: 0.0016, mse: 0.005033, wmse: 0.041505, mae: 0.052948, val nll: -1.2889, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.2195, test mse: 0.0051\n",
      "1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,\tIter: 1600, train loss: -1.1599, avg nll: -1.1893, avg wnll: 39.1616, avg kl: 0.0014, mse: 0.005608, wmse: 0.047307, mae: 0.055507, val nll: -1.3466, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.1343, test mse: 0.0063\n",
      "saving.................\n",
      "done\n",
      "1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,\tIter: 1610, train loss: -1.3270, avg nll: -1.3488, avg wnll: 38.4566, avg kl: 0.0007, mse: 0.004216, wmse: 0.035682, mae: 0.047346, val nll: -1.4103, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3577, test mse: 0.0042\n",
      "1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,\tIter: 1620, train loss: -1.3334, avg nll: -1.3551, avg wnll: 31.2636, avg kl: 0.0012, mse: 0.004094, wmse: 0.034368, mae: 0.048301, val nll: -1.3402, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3425, test mse: 0.0041\n",
      "1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,\tIter: 1630, train loss: -1.3328, avg nll: -1.3539, avg wnll: 30.3734, avg kl: 0.0008, mse: 0.004062, wmse: 0.034088, mae: 0.047836, val nll: -1.3101, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.3460, test mse: 0.0044\n",
      "1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,\tIter: 1640, train loss: -1.3230, avg nll: -1.3449, avg wnll: 32.0850, avg kl: 0.0009, mse: 0.004190, wmse: 0.034936, mae: 0.048417, val nll: -1.3511, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.3204, test mse: 0.0045\n",
      "1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,\tIter: 1650, train loss: -1.2335, avg nll: -1.2598, avg wnll: 37.4099, avg kl: 0.0013, mse: 0.004991, wmse: 0.041293, mae: 0.053439, val nll: -1.0985, val mse 0.0064, lr 0.000100000\n",
      "test nll: -0.9817, test mse: 0.0074\n",
      "1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,\tIter: 1660, train loss: -1.2335, avg nll: -1.2595, avg wnll: 33.5212, avg kl: 0.0015, mse: 0.004901, wmse: 0.041734, mae: 0.052100, val nll: -1.3963, val mse 0.0034, lr 0.000100000\n",
      "test nll: -1.2616, test mse: 0.0048\n",
      "1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,\tIter: 1670, train loss: -1.1523, avg nll: -1.1820, avg wnll: 40.3937, avg kl: 0.0016, mse: 0.005620, wmse: 0.047079, mae: 0.059793, val nll: -1.2665, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.0018, test mse: 0.0069\n",
      "1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,\tIter: 1680, train loss: -1.2681, avg nll: -1.2922, avg wnll: 38.8944, avg kl: 0.0011, mse: 0.004596, wmse: 0.038923, mae: 0.051394, val nll: -1.2335, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.2371, test mse: 0.0052\n",
      "1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,\tIter: 1690, train loss: -1.2591, avg nll: -1.2839, avg wnll: 33.7587, avg kl: 0.0013, mse: 0.004703, wmse: 0.039485, mae: 0.051914, val nll: -1.1281, val mse 0.0063, lr 0.000100000\n",
      "test nll: -1.3090, test mse: 0.0045\n",
      "1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,\tIter: 1700, train loss: -1.3476, avg nll: -1.3686, avg wnll: 36.3632, avg kl: 0.0009, mse: 0.004021, wmse: 0.034094, mae: 0.047850, val nll: -1.3082, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3123, test mse: 0.0044\n",
      "1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,\tIter: 1710, train loss: -1.0565, avg nll: -1.0916, avg wnll: 40.6401, avg kl: 0.0017, mse: 0.006680, wmse: 0.056225, mae: 0.063374, val nll: -1.1935, val mse 0.0055, lr 0.000100000\n",
      "test nll: -1.0756, test mse: 0.0069\n",
      "1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,\tIter: 1720, train loss: -1.1778, avg nll: -1.2071, avg wnll: 38.4075, avg kl: 0.0020, mse: 0.005474, wmse: 0.045456, mae: 0.056303, val nll: -1.2444, val mse 0.0053, lr 0.000100000\n",
      "test nll: -1.1326, test mse: 0.0061\n",
      "1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,\tIter: 1730, train loss: -1.3266, avg nll: -1.3485, avg wnll: 30.8720, avg kl: 0.0012, mse: 0.004145, wmse: 0.034684, mae: 0.049200, val nll: -1.3160, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.2927, test mse: 0.0049\n",
      "1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,\tIter: 1740, train loss: -1.3176, avg nll: -1.3396, avg wnll: 36.6144, avg kl: 0.0007, mse: 0.004246, wmse: 0.035497, mae: 0.048238, val nll: -1.3386, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.4245, test mse: 0.0036\n",
      "1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,\tIter: 1750, train loss: -1.3768, avg nll: -1.3959, avg wnll: 31.7012, avg kl: 0.0007, mse: 0.003688, wmse: 0.031119, mae: 0.045370, val nll: -1.3974, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3161, test mse: 0.0045\n",
      "1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,\tIter: 1760, train loss: -1.3553, avg nll: -1.3754, avg wnll: 26.8783, avg kl: 0.0011, mse: 0.003778, wmse: 0.031838, mae: 0.047414, val nll: -1.2824, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.3601, test mse: 0.0042\n",
      "1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,\tIter: 1770, train loss: -1.2690, avg nll: -1.2931, avg wnll: 35.9129, avg kl: 0.0014, mse: 0.004536, wmse: 0.037743, mae: 0.050774, val nll: -1.3399, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3683, test mse: 0.0038\n",
      "1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,\tIter: 1780, train loss: -1.3093, avg nll: -1.3316, avg wnll: 33.8742, avg kl: 0.0007, mse: 0.004312, wmse: 0.035825, mae: 0.049510, val nll: -1.3817, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.2654, test mse: 0.0050\n",
      "1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,\tIter: 1790, train loss: -1.3039, avg nll: -1.3267, avg wnll: 35.5193, avg kl: 0.0006, mse: 0.004454, wmse: 0.037852, mae: 0.050356, val nll: -1.3143, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.3362, test mse: 0.0043\n",
      "1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,\tIter: 1800, train loss: -1.3653, avg nll: -1.3847, avg wnll: 33.0445, avg kl: 0.0006, mse: 0.003770, wmse: 0.031314, mae: 0.046659, val nll: -1.3891, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.3550, test mse: 0.0040\n",
      "saving.................\n",
      "done\n",
      "1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,\tIter: 1810, train loss: -1.3611, avg nll: -1.3811, avg wnll: 31.0990, avg kl: 0.0009, mse: 0.003823, wmse: 0.031619, mae: 0.047245, val nll: -1.4044, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3596, test mse: 0.0042\n",
      "1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,\tIter: 1820, train loss: -1.4099, avg nll: -1.4284, avg wnll: 32.0030, avg kl: 0.0004, mse: 0.003608, wmse: 0.030270, mae: 0.044603, val nll: -1.4368, val mse 0.0033, lr 0.000100000\n",
      "test nll: -1.4380, test mse: 0.0035\n",
      "1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,\tIter: 1830, train loss: -1.3032, avg nll: -1.3256, avg wnll: 35.9183, avg kl: 0.0006, mse: 0.004361, wmse: 0.037015, mae: 0.050924, val nll: -1.3518, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3450, test mse: 0.0043\n",
      "1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,\tIter: 1840, train loss: -1.2642, avg nll: -1.2887, avg wnll: 39.5235, avg kl: 0.0006, mse: 0.004791, wmse: 0.041043, mae: 0.050830, val nll: -1.3669, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3087, test mse: 0.0045\n",
      "1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,\tIter: 1850, train loss: -1.1677, avg nll: -1.1946, avg wnll: 45.4228, avg kl: 0.0006, mse: 0.005260, wmse: 0.043515, mae: 0.054901, val nll: -1.3244, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2989, test mse: 0.0048\n",
      "1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,\tIter: 1860, train loss: -1.3415, avg nll: -1.3623, avg wnll: 31.0948, avg kl: 0.0005, mse: 0.004057, wmse: 0.033985, mae: 0.048457, val nll: -1.3730, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3526, test mse: 0.0043\n",
      "1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,\tIter: 1870, train loss: -1.2756, avg nll: -1.2992, avg wnll: 38.6982, avg kl: 0.0012, mse: 0.004475, wmse: 0.037236, mae: 0.050738, val nll: -1.3734, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.2732, test mse: 0.0048\n",
      "1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,\tIter: 1880, train loss: -1.3635, avg nll: -1.3836, avg wnll: 32.6753, avg kl: 0.0007, mse: 0.003891, wmse: 0.032448, mae: 0.045645, val nll: -1.3414, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2470, test mse: 0.0050\n",
      "1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,\tIter: 1890, train loss: -1.3281, avg nll: -1.3497, avg wnll: 37.6668, avg kl: 0.0009, mse: 0.004136, wmse: 0.034873, mae: 0.048496, val nll: -1.2916, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.2345, test mse: 0.0052\n",
      "1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,\tIter: 1900, train loss: -1.1969, avg nll: -1.2239, avg wnll: 40.8838, avg kl: 0.0008, mse: 0.005242, wmse: 0.044405, mae: 0.057932, val nll: -1.4249, val mse 0.0034, lr 0.000100000\n",
      "test nll: -1.3795, test mse: 0.0039\n",
      "1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,\tIter: 1910, train loss: -1.2813, avg nll: -1.3047, avg wnll: 31.8937, avg kl: 0.0017, mse: 0.004340, wmse: 0.036229, mae: 0.051012, val nll: -1.1168, val mse 0.0062, lr 0.000100000\n",
      "test nll: -1.2653, test mse: 0.0045\n",
      "1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,\tIter: 1920, train loss: -1.3497, avg nll: -1.3705, avg wnll: 29.9447, avg kl: 0.0016, mse: 0.003844, wmse: 0.032317, mae: 0.048271, val nll: -1.4040, val mse 0.0033, lr 0.000100000\n",
      "test nll: -1.3028, test mse: 0.0047\n",
      "1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,\tIter: 1930, train loss: -1.2583, avg nll: -1.2838, avg wnll: 34.7862, avg kl: 0.0010, mse: 0.004898, wmse: 0.041036, mae: 0.051992, val nll: -1.1681, val mse 0.0057, lr 0.000100000\n",
      "test nll: -1.1531, test mse: 0.0061\n",
      "1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,\tIter: 1940, train loss: -1.2885, avg nll: -1.3123, avg wnll: 32.7362, avg kl: 0.0012, mse: 0.004506, wmse: 0.038065, mae: 0.050877, val nll: -1.2755, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.2391, test mse: 0.0051\n",
      "1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,\tIter: 1950, train loss: -1.2164, avg nll: -1.2429, avg wnll: 30.7999, avg kl: 0.0017, mse: 0.004967, wmse: 0.041366, mae: 0.055002, val nll: -1.2501, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.2713, test mse: 0.0046\n",
      "1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,\tIter: 1960, train loss: -1.3529, avg nll: -1.3741, avg wnll: 30.2768, avg kl: 0.0016, mse: 0.003922, wmse: 0.033327, mae: 0.047795, val nll: -1.3560, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.4040, test mse: 0.0036\n",
      "1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,\tIter: 1970, train loss: -1.2899, avg nll: -1.3132, avg wnll: 29.5498, avg kl: 0.0015, mse: 0.004362, wmse: 0.036533, mae: 0.050079, val nll: -1.2463, val mse 0.0052, lr 0.000100000\n",
      "test nll: -1.1104, test mse: 0.0062\n",
      "1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,\tIter: 1980, train loss: -1.2611, avg nll: -1.2856, avg wnll: 27.6010, avg kl: 0.0020, mse: 0.004490, wmse: 0.037443, mae: 0.051292, val nll: -1.3753, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.1991, test mse: 0.0058\n",
      "1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,\tIter: 1990, train loss: -1.3047, avg nll: -1.3282, avg wnll: 34.9800, avg kl: 0.0015, mse: 0.004405, wmse: 0.036857, mae: 0.049633, val nll: -1.3182, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.2594, test mse: 0.0050\n",
      "1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,\tIter: 2000, train loss: -1.3280, avg nll: -1.3499, avg wnll: 32.6888, avg kl: 0.0008, mse: 0.004232, wmse: 0.035169, mae: 0.048192, val nll: -1.3704, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.2495, test mse: 0.0051\n",
      "saving.................\n",
      "done\n",
      "2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,\tIter: 2010, train loss: -1.3088, avg nll: -1.3307, avg wnll: 35.7664, avg kl: 0.0006, mse: 0.004255, wmse: 0.035917, mae: 0.049983, val nll: -1.2519, val mse 0.0053, lr 0.000100000\n",
      "test nll: -1.2722, test mse: 0.0049\n",
      "2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,\tIter: 2020, train loss: -1.3465, avg nll: -1.3671, avg wnll: 28.4260, avg kl: 0.0011, mse: 0.003889, wmse: 0.032682, mae: 0.047994, val nll: -1.2108, val mse 0.0055, lr 0.000100000\n",
      "test nll: -1.3833, test mse: 0.0036\n",
      "2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,\tIter: 2030, train loss: -1.3042, avg nll: -1.3270, avg wnll: 33.7015, avg kl: 0.0012, mse: 0.004321, wmse: 0.035855, mae: 0.050020, val nll: -1.4897, val mse 0.0029, lr 0.000100000\n",
      "test nll: -1.3148, test mse: 0.0048\n",
      "2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,\tIter: 2040, train loss: -1.3451, avg nll: -1.3667, avg wnll: 35.4054, avg kl: 0.0011, mse: 0.004094, wmse: 0.034355, mae: 0.048074, val nll: -1.3610, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3359, test mse: 0.0047\n",
      "2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,\tIter: 2050, train loss: -1.1332, avg nll: -1.1636, avg wnll: 41.7564, avg kl: 0.0014, mse: 0.005791, wmse: 0.048373, mae: 0.058521, val nll: -1.3806, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3229, test mse: 0.0042\n",
      "2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,\tIter: 2060, train loss: -1.2748, avg nll: -1.2984, avg wnll: 33.6971, avg kl: 0.0010, mse: 0.004512, wmse: 0.037714, mae: 0.050679, val nll: -1.2175, val mse 0.0053, lr 0.000100000\n",
      "test nll: -1.1574, test mse: 0.0059\n",
      "2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,\tIter: 2070, train loss: -1.2835, avg nll: -1.3068, avg wnll: 37.0328, avg kl: 0.0010, mse: 0.004456, wmse: 0.037335, mae: 0.050879, val nll: -1.2090, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.1018, test mse: 0.0060\n",
      "2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,\tIter: 2080, train loss: -1.3101, avg nll: -1.3328, avg wnll: 34.7849, avg kl: 0.0007, mse: 0.004399, wmse: 0.036359, mae: 0.048882, val nll: -1.3148, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2641, test mse: 0.0046\n",
      "2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,\tIter: 2090, train loss: -0.8273, avg nll: -0.8724, avg wnll: 58.0853, avg kl: 0.0018, mse: 0.008665, wmse: 0.072545, mae: 0.075366, val nll: -1.1204, val mse 0.0059, lr 0.000100000\n",
      "test nll: -1.1662, test mse: 0.0059\n",
      "2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,\tIter: 2100, train loss: -0.9635, avg nll: -1.0067, avg wnll: 44.8291, avg kl: 0.0047, mse: 0.007697, wmse: 0.064311, mae: 0.068915, val nll: -1.2176, val mse 0.0053, lr 0.000100000\n",
      "test nll: -1.1714, test mse: 0.0058\n",
      "2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,\tIter: 2110, train loss: -1.2638, avg nll: -1.2889, avg wnll: 39.4036, avg kl: 0.0012, mse: 0.004761, wmse: 0.040487, mae: 0.052247, val nll: -1.4293, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.3325, test mse: 0.0043\n",
      "2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,\tIter: 2120, train loss: -1.3581, avg nll: -1.3787, avg wnll: 31.5215, avg kl: 0.0008, mse: 0.003957, wmse: 0.032961, mae: 0.047513, val nll: -1.3858, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3218, test mse: 0.0046\n",
      "2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,\tIter: 2130, train loss: -1.3289, avg nll: -1.3507, avg wnll: 32.4655, avg kl: 0.0009, mse: 0.004177, wmse: 0.034579, mae: 0.048977, val nll: -1.1142, val mse 0.0058, lr 0.000100000\n",
      "test nll: -1.3091, test mse: 0.0046\n",
      "2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,\tIter: 2140, train loss: -1.1915, avg nll: -1.2200, avg wnll: 38.3554, avg kl: 0.0013, mse: 0.005440, wmse: 0.045725, mae: 0.056708, val nll: -1.1929, val mse 0.0055, lr 0.000100000\n",
      "test nll: -1.2512, test mse: 0.0052\n",
      "2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,\tIter: 2150, train loss: -1.2564, avg nll: -1.2814, avg wnll: 39.4076, avg kl: 0.0011, mse: 0.004768, wmse: 0.039842, mae: 0.052257, val nll: -1.3352, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.3547, test mse: 0.0042\n",
      "2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,\tIter: 2160, train loss: -1.3342, avg nll: -1.3556, avg wnll: 35.0268, avg kl: 0.0007, mse: 0.004145, wmse: 0.035091, mae: 0.049957, val nll: -1.4374, val mse 0.0033, lr 0.000100000\n",
      "test nll: -1.3004, test mse: 0.0048\n",
      "2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,\tIter: 2170, train loss: -1.3174, avg nll: -1.3399, avg wnll: 37.9134, avg kl: 0.0005, mse: 0.004396, wmse: 0.036716, mae: 0.049548, val nll: -1.4174, val mse 0.0036, lr 0.000100000\n",
      "test nll: -1.3786, test mse: 0.0042\n",
      "2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,\tIter: 2180, train loss: -1.1971, avg nll: -1.2239, avg wnll: 41.9513, avg kl: 0.0010, mse: 0.005151, wmse: 0.042946, mae: 0.054553, val nll: -1.2259, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.2300, test mse: 0.0050\n",
      "2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,\tIter: 2190, train loss: -1.2977, avg nll: -1.3211, avg wnll: 35.1915, avg kl: 0.0007, mse: 0.004539, wmse: 0.038380, mae: 0.051619, val nll: -1.3260, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.3484, test mse: 0.0044\n",
      "2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,\tIter: 2200, train loss: -1.3082, avg nll: -1.3313, avg wnll: 30.1261, avg kl: 0.0014, mse: 0.004333, wmse: 0.036233, mae: 0.049300, val nll: -1.3782, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.2675, test mse: 0.0052\n",
      "saving.................\n",
      "done\n",
      "2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,\tIter: 2210, train loss: -1.3222, avg nll: -1.3443, avg wnll: 32.6428, avg kl: 0.0010, mse: 0.004218, wmse: 0.035702, mae: 0.049925, val nll: -1.3325, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.3081, test mse: 0.0045\n",
      "2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,\tIter: 2220, train loss: -1.2725, avg nll: -1.2959, avg wnll: 36.0400, avg kl: 0.0005, mse: 0.004595, wmse: 0.038038, mae: 0.050010, val nll: -1.4195, val mse 0.0034, lr 0.000100000\n",
      "test nll: -1.3618, test mse: 0.0037\n",
      "2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,\tIter: 2230, train loss: -1.3808, avg nll: -1.3999, avg wnll: 33.8472, avg kl: 0.0005, mse: 0.003726, wmse: 0.031050, mae: 0.046332, val nll: -1.3803, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.3303, test mse: 0.0044\n",
      "2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,\tIter: 2240, train loss: -1.3535, avg nll: -1.3744, avg wnll: 32.4711, avg kl: 0.0008, mse: 0.004007, wmse: 0.033317, mae: 0.048046, val nll: -1.4353, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.2197, test mse: 0.0053\n",
      "2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,\tIter: 2250, train loss: -1.3616, avg nll: -1.3824, avg wnll: 34.6932, avg kl: 0.0006, mse: 0.004024, wmse: 0.033634, mae: 0.046170, val nll: -1.3792, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3033, test mse: 0.0045\n",
      "2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,\tIter: 2260, train loss: -1.3665, avg nll: -1.3868, avg wnll: 33.2086, avg kl: 0.0004, mse: 0.003962, wmse: 0.033518, mae: 0.047378, val nll: -1.4020, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.3305, test mse: 0.0044\n",
      "2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,\tIter: 2270, train loss: -1.3928, avg nll: -1.4124, avg wnll: 31.5229, avg kl: 0.0007, mse: 0.003769, wmse: 0.031390, mae: 0.044648, val nll: -1.4903, val mse 0.0031, lr 0.000100000\n",
      "test nll: -1.2837, test mse: 0.0046\n",
      "2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,\tIter: 2280, train loss: -1.3751, avg nll: -1.3951, avg wnll: 33.8463, avg kl: 0.0010, mse: 0.003812, wmse: 0.032282, mae: 0.046711, val nll: -1.2888, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.4093, test mse: 0.0039\n",
      "2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,\tIter: 2290, train loss: -1.2692, avg nll: -1.2946, avg wnll: 40.1517, avg kl: 0.0014, mse: 0.004795, wmse: 0.040612, mae: 0.052206, val nll: -1.3315, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.2007, test mse: 0.0056\n",
      "2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,\tIter: 2300, train loss: -1.2840, avg nll: -1.3075, avg wnll: 33.8927, avg kl: 0.0010, mse: 0.004504, wmse: 0.037829, mae: 0.051937, val nll: -1.4486, val mse 0.0031, lr 0.000100000\n",
      "test nll: -1.2819, test mse: 0.0047\n",
      "2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,\tIter: 2310, train loss: -1.3445, avg nll: -1.3661, avg wnll: 31.9081, avg kl: 0.0010, mse: 0.004120, wmse: 0.034625, mae: 0.047830, val nll: -1.3626, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.3084, test mse: 0.0044\n",
      "2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,\tIter: 2320, train loss: -1.3641, avg nll: -1.3845, avg wnll: 32.2836, avg kl: 0.0010, mse: 0.003885, wmse: 0.032661, mae: 0.047984, val nll: -1.3857, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3533, test mse: 0.0038\n",
      "2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,\tIter: 2330, train loss: -1.2005, avg nll: -1.2273, avg wnll: 45.0584, avg kl: 0.0006, mse: 0.005246, wmse: 0.044407, mae: 0.055438, val nll: -1.3854, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.3929, test mse: 0.0037\n",
      "2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,\tIter: 2340, train loss: -1.3336, avg nll: -1.3554, avg wnll: 33.3975, avg kl: 0.0007, mse: 0.004208, wmse: 0.035175, mae: 0.049503, val nll: -1.2785, val mse 0.0050, lr 0.000100000\n",
      "test nll: -1.4186, test mse: 0.0036\n",
      "2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,\tIter: 2350, train loss: -1.2997, avg nll: -1.3223, avg wnll: 35.9875, avg kl: 0.0008, mse: 0.004356, wmse: 0.036484, mae: 0.050554, val nll: -1.2393, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.3215, test mse: 0.0042\n",
      "2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,\tIter: 2360, train loss: -1.2468, avg nll: -1.2720, avg wnll: 25.2187, avg kl: 0.0021, mse: 0.004618, wmse: 0.039020, mae: 0.053478, val nll: -1.3643, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.2568, test mse: 0.0047\n",
      "2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,\tIter: 2370, train loss: -1.2537, avg nll: -1.2782, avg wnll: 40.0482, avg kl: 0.0008, mse: 0.004726, wmse: 0.040253, mae: 0.052215, val nll: -1.3766, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.2395, test mse: 0.0054\n",
      "2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,\tIter: 2380, train loss: -1.3938, avg nll: -1.4131, avg wnll: 29.8546, avg kl: 0.0005, mse: 0.003752, wmse: 0.031326, mae: 0.045547, val nll: -1.3658, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.2702, test mse: 0.0047\n",
      "2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,\tIter: 2390, train loss: -1.3142, avg nll: -1.3367, avg wnll: 29.2473, avg kl: 0.0013, mse: 0.004243, wmse: 0.035930, mae: 0.050005, val nll: -1.2296, val mse 0.0054, lr 0.000100000\n",
      "test nll: -1.1434, test mse: 0.0063\n",
      "2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,\tIter: 2400, train loss: -1.3117, avg nll: -1.3346, avg wnll: 36.3444, avg kl: 0.0013, mse: 0.004325, wmse: 0.036999, mae: 0.050084, val nll: -1.3199, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2083, test mse: 0.0056\n",
      "saving.................\n",
      "done\n",
      "2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,\tIter: 2410, train loss: -1.2743, avg nll: -1.2982, avg wnll: 36.1062, avg kl: 0.0008, mse: 0.004640, wmse: 0.038231, mae: 0.051370, val nll: -1.3716, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.3326, test mse: 0.0045\n",
      "2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,\tIter: 2420, train loss: -1.3565, avg nll: -1.3780, avg wnll: 33.4393, avg kl: 0.0012, mse: 0.004054, wmse: 0.034486, mae: 0.048444, val nll: -1.4090, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.4056, test mse: 0.0038\n",
      "2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,\tIter: 2430, train loss: -1.3345, avg nll: -1.3557, avg wnll: 38.6089, avg kl: 0.0008, mse: 0.004096, wmse: 0.034835, mae: 0.048748, val nll: -1.2668, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.2556, test mse: 0.0050\n",
      "2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,\tIter: 2440, train loss: -1.2906, avg nll: -1.3145, avg wnll: 34.1280, avg kl: 0.0011, mse: 0.004569, wmse: 0.038220, mae: 0.051097, val nll: -1.3838, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.3591, test mse: 0.0044\n",
      "2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,\tIter: 2450, train loss: -1.3461, avg nll: -1.3668, avg wnll: 25.9598, avg kl: 0.0009, mse: 0.003954, wmse: 0.033233, mae: 0.047312, val nll: -1.3808, val mse 0.0038, lr 0.000100000\n",
      "test nll: -1.3497, test mse: 0.0039\n",
      "2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,\tIter: 2460, train loss: -1.2862, avg nll: -1.3103, avg wnll: 35.1222, avg kl: 0.0015, mse: 0.004519, wmse: 0.038731, mae: 0.052663, val nll: -1.4054, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3419, test mse: 0.0042\n",
      "2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,\tIter: 2470, train loss: -1.3383, avg nll: -1.3596, avg wnll: 29.9434, avg kl: 0.0012, mse: 0.004043, wmse: 0.033909, mae: 0.047836, val nll: -1.4434, val mse 0.0033, lr 0.000100000\n",
      "test nll: -1.2838, test mse: 0.0050\n",
      "2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,\tIter: 2480, train loss: -1.3370, avg nll: -1.3587, avg wnll: 35.2439, avg kl: 0.0011, mse: 0.004115, wmse: 0.034431, mae: 0.048803, val nll: -1.3107, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.3985, test mse: 0.0037\n",
      "2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,\tIter: 2490, train loss: -1.3522, avg nll: -1.3734, avg wnll: 31.3877, avg kl: 0.0009, mse: 0.004052, wmse: 0.033993, mae: 0.049024, val nll: -1.3632, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.2103, test mse: 0.0051\n",
      "2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,\tIter: 2500, train loss: -1.2664, avg nll: -1.2912, avg wnll: 32.6777, avg kl: 0.0015, mse: 0.004650, wmse: 0.039317, mae: 0.051545, val nll: -1.3540, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3006, test mse: 0.0044\n",
      "2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,\tIter: 2510, train loss: -1.2319, avg nll: -1.2568, avg wnll: 40.4157, avg kl: 0.0010, mse: 0.004789, wmse: 0.040185, mae: 0.052948, val nll: -1.3274, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2788, test mse: 0.0048\n",
      "2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,\tIter: 2520, train loss: -1.3486, avg nll: -1.3701, avg wnll: 34.9132, avg kl: 0.0008, mse: 0.004127, wmse: 0.034225, mae: 0.048027, val nll: -1.4090, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.4008, test mse: 0.0038\n",
      "2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,\tIter: 2530, train loss: -1.3380, avg nll: -1.3598, avg wnll: 32.4427, avg kl: 0.0011, mse: 0.004148, wmse: 0.034153, mae: 0.048705, val nll: -1.3804, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.4137, test mse: 0.0037\n",
      "2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,\tIter: 2540, train loss: -1.3042, avg nll: -1.3268, avg wnll: 36.8864, avg kl: 0.0007, mse: 0.004382, wmse: 0.037123, mae: 0.050605, val nll: -1.2996, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3537, test mse: 0.0042\n",
      "2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,\tIter: 2550, train loss: -1.3699, avg nll: -1.3898, avg wnll: 32.8829, avg kl: 0.0007, mse: 0.003834, wmse: 0.031962, mae: 0.046665, val nll: -1.4724, val mse 0.0032, lr 0.000100000\n",
      "test nll: -1.4463, test mse: 0.0035\n",
      "2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,\tIter: 2560, train loss: -1.2570, avg nll: -1.2812, avg wnll: 37.9961, avg kl: 0.0004, mse: 0.004759, wmse: 0.040369, mae: 0.051531, val nll: -1.3197, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.2711, test mse: 0.0050\n",
      "2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,\tIter: 2570, train loss: -1.3804, avg nll: -1.4004, avg wnll: 31.8698, avg kl: 0.0011, mse: 0.003799, wmse: 0.031969, mae: 0.046984, val nll: -1.4384, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.3606, test mse: 0.0042\n",
      "2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,\tIter: 2580, train loss: -1.3615, avg nll: -1.3828, avg wnll: 32.5799, avg kl: 0.0009, mse: 0.004084, wmse: 0.034613, mae: 0.047241, val nll: -1.3935, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3326, test mse: 0.0047\n",
      "2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,\tIter: 2590, train loss: -1.2379, avg nll: -1.2639, avg wnll: 38.7325, avg kl: 0.0006, mse: 0.005072, wmse: 0.042590, mae: 0.053343, val nll: -1.2808, val mse 0.0046, lr 0.000100000\n",
      "test nll: -1.4359, test mse: 0.0036\n",
      "2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,\tIter: 2600, train loss: -1.3414, avg nll: -1.3633, avg wnll: 31.5733, avg kl: 0.0012, mse: 0.004139, wmse: 0.034446, mae: 0.048997, val nll: -1.3411, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.3387, test mse: 0.0041\n",
      "saving.................\n",
      "done\n",
      "2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,\tIter: 2610, train loss: -1.3128, avg nll: -1.3353, avg wnll: 36.3374, avg kl: 0.0007, mse: 0.004369, wmse: 0.036402, mae: 0.050513, val nll: -1.3352, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2924, test mse: 0.0048\n",
      "2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,\tIter: 2620, train loss: -1.2735, avg nll: -1.2973, avg wnll: 32.1489, avg kl: 0.0009, mse: 0.004590, wmse: 0.038128, mae: 0.051195, val nll: -1.2943, val mse 0.0050, lr 0.000100000\n",
      "test nll: -1.3983, test mse: 0.0038\n",
      "2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,\tIter: 2630, train loss: -1.3468, avg nll: -1.3677, avg wnll: 30.6557, avg kl: 0.0012, mse: 0.003953, wmse: 0.033146, mae: 0.048189, val nll: -1.2588, val mse 0.0051, lr 0.000100000\n",
      "test nll: -1.3064, test mse: 0.0043\n",
      "2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,\tIter: 2640, train loss: -1.3244, avg nll: -1.3474, avg wnll: 34.1760, avg kl: 0.0009, mse: 0.004408, wmse: 0.036916, mae: 0.048809, val nll: -1.4662, val mse 0.0035, lr 0.000100000\n",
      "test nll: -1.3857, test mse: 0.0038\n",
      "2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,\tIter: 2650, train loss: -1.3761, avg nll: -1.3967, avg wnll: 30.7728, avg kl: 0.0014, mse: 0.003846, wmse: 0.032663, mae: 0.046989, val nll: -1.4181, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3505, test mse: 0.0040\n",
      "2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,\tIter: 2660, train loss: -1.2280, avg nll: -1.2546, avg wnll: 33.9683, avg kl: 0.0016, mse: 0.004991, wmse: 0.041403, mae: 0.052791, val nll: -1.3019, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.2825, test mse: 0.0048\n",
      "2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,\tIter: 2670, train loss: -1.3825, avg nll: -1.4031, avg wnll: 34.1993, avg kl: 0.0007, mse: 0.003982, wmse: 0.033991, mae: 0.046584, val nll: -1.4898, val mse 0.0030, lr 0.000100000\n",
      "test nll: -1.4123, test mse: 0.0038\n",
      "2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,\tIter: 2680, train loss: -1.3829, avg nll: -1.4023, avg wnll: 32.6235, avg kl: 0.0005, mse: 0.003762, wmse: 0.031844, mae: 0.047080, val nll: -1.4775, val mse 0.0030, lr 0.000100000\n",
      "test nll: -1.3580, test mse: 0.0042\n",
      "2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,\tIter: 2690, train loss: -1.3223, avg nll: -1.3448, avg wnll: 35.8524, avg kl: 0.0007, mse: 0.004377, wmse: 0.036561, mae: 0.049759, val nll: -1.5371, val mse 0.0025, lr 0.000100000\n",
      "test nll: -1.3642, test mse: 0.0042\n",
      "2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,\tIter: 2700, train loss: -1.2580, avg nll: -1.2823, avg wnll: 39.6661, avg kl: 0.0007, mse: 0.004708, wmse: 0.039687, mae: 0.051191, val nll: -1.3106, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.3196, test mse: 0.0046\n",
      "2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,\tIter: 2710, train loss: -1.3330, avg nll: -1.3553, avg wnll: 33.7526, avg kl: 0.0009, mse: 0.004291, wmse: 0.035787, mae: 0.048872, val nll: -1.4150, val mse 0.0037, lr 0.000100000\n",
      "test nll: -1.3503, test mse: 0.0043\n",
      "2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,\tIter: 2720, train loss: -1.3277, avg nll: -1.3494, avg wnll: 32.2648, avg kl: 0.0007, mse: 0.004195, wmse: 0.035011, mae: 0.048744, val nll: -1.3596, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.3177, test mse: 0.0047\n",
      "2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,\tIter: 2730, train loss: -1.3592, avg nll: -1.3803, avg wnll: 33.2227, avg kl: 0.0010, mse: 0.004025, wmse: 0.034104, mae: 0.048423, val nll: -1.4102, val mse 0.0040, lr 0.000100000\n",
      "test nll: -1.3700, test mse: 0.0042\n",
      "2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,\tIter: 2740, train loss: -1.2604, avg nll: -1.2856, avg wnll: 37.8079, avg kl: 0.0011, mse: 0.004812, wmse: 0.040140, mae: 0.052091, val nll: -1.3816, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.3074, test mse: 0.0042\n",
      "2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,\tIter: 2750, train loss: -1.3172, avg nll: -1.3401, avg wnll: 32.6926, avg kl: 0.0009, mse: 0.004418, wmse: 0.036904, mae: 0.048747, val nll: -1.3661, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3977, test mse: 0.0037\n",
      "2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,\tIter: 2760, train loss: -1.2372, avg nll: -1.2632, avg wnll: 37.3848, avg kl: 0.0012, mse: 0.004961, wmse: 0.041526, mae: 0.054893, val nll: -1.4102, val mse 0.0036, lr 0.000100000\n",
      "test nll: -1.3244, test mse: 0.0045\n",
      "2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,\tIter: 2770, train loss: -1.3932, avg nll: -1.4123, avg wnll: 29.9419, avg kl: 0.0013, mse: 0.003570, wmse: 0.029950, mae: 0.045231, val nll: -1.2634, val mse 0.0050, lr 0.000100000\n",
      "test nll: -1.4420, test mse: 0.0032\n",
      "2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,\tIter: 2780, train loss: -1.3288, avg nll: -1.3506, avg wnll: 30.0859, avg kl: 0.0007, mse: 0.004219, wmse: 0.035066, mae: 0.048254, val nll: -1.3348, val mse 0.0045, lr 0.000100000\n",
      "test nll: -1.3639, test mse: 0.0040\n",
      "2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,\tIter: 2790, train loss: -1.2710, avg nll: -1.2950, avg wnll: 40.3661, avg kl: 0.0006, mse: 0.004685, wmse: 0.039170, mae: 0.051962, val nll: -1.4086, val mse 0.0039, lr 0.000100000\n",
      "test nll: -1.2310, test mse: 0.0050\n",
      "2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,\tIter: 2800, train loss: -1.3144, avg nll: -1.3370, avg wnll: 34.9068, avg kl: 0.0012, mse: 0.004282, wmse: 0.036085, mae: 0.049384, val nll: -1.3646, val mse 0.0042, lr 0.000100000\n",
      "test nll: -1.2268, test mse: 0.0052\n",
      "saving.................\n",
      "done\n",
      "2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,\tIter: 2810, train loss: -1.2963, avg nll: -1.3197, avg wnll: 29.5649, avg kl: 0.0016, mse: 0.004371, wmse: 0.037494, mae: 0.049856, val nll: -1.2985, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.2759, test mse: 0.0048\n",
      "2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,\tIter: 2820, train loss: -1.3177, avg nll: -1.3408, avg wnll: 36.8881, avg kl: 0.0011, mse: 0.004391, wmse: 0.037696, mae: 0.050109, val nll: -1.4388, val mse 0.0036, lr 0.000100000\n",
      "test nll: -1.1446, test mse: 0.0061\n",
      "2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,\tIter: 2830, train loss: -1.2851, avg nll: -1.3096, avg wnll: 35.3106, avg kl: 0.0011, mse: 0.004690, wmse: 0.040177, mae: 0.051632, val nll: -1.3294, val mse 0.0044, lr 0.000100000\n",
      "test nll: -1.3750, test mse: 0.0037\n",
      "2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,\tIter: 2840, train loss: -1.3264, avg nll: -1.3485, avg wnll: 35.1159, avg kl: 0.0009, mse: 0.004240, wmse: 0.035605, mae: 0.049370, val nll: -1.4512, val mse 0.0032, lr 0.000100000\n",
      "test nll: -1.3490, test mse: 0.0042\n",
      "2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,\tIter: 2850, train loss: -1.3114, avg nll: -1.3338, avg wnll: 36.7657, avg kl: 0.0009, mse: 0.004323, wmse: 0.036532, mae: 0.049209, val nll: -1.2802, val mse 0.0048, lr 0.000100000\n",
      "test nll: -1.2981, test mse: 0.0046\n",
      "2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,\tIter: 2860, train loss: -1.3616, avg nll: -1.3828, avg wnll: 34.5693, avg kl: 0.0006, mse: 0.004111, wmse: 0.034759, mae: 0.048146, val nll: -1.4939, val mse 0.0031, lr 0.000100000\n",
      "test nll: -1.3131, test mse: 0.0050\n",
      "2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,\tIter: 2870, train loss: -1.2644, avg nll: -1.2885, avg wnll: 35.0223, avg kl: 0.0008, mse: 0.004664, wmse: 0.039598, mae: 0.052513, val nll: -1.3511, val mse 0.0043, lr 0.000100000\n",
      "test nll: -1.3239, test mse: 0.0046\n",
      "2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,\tIter: 2880, train loss: -1.2984, avg nll: -1.3220, avg wnll: 36.6566, avg kl: 0.0008, mse: 0.004564, wmse: 0.038119, mae: 0.051437, val nll: -1.2999, val mse 0.0047, lr 0.000100000\n",
      "test nll: -1.3791, test mse: 0.0036\n",
      "2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,\tIter: 2890, train loss: -1.3658, avg nll: -1.3862, avg wnll: 31.7770, avg kl: 0.0007, mse: 0.003940, wmse: 0.033437, mae: 0.047701, val nll: -1.3534, val mse 0.0041, lr 0.000100000\n",
      "test nll: -1.4171, test mse: 0.0036\n",
      "2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,\tIter: 2900, train loss: -1.4066, avg nll: -1.4253, avg wnll: 32.1346, avg kl: 0.0006, mse: 0.003623, wmse: 0.030459, mae: 0.045518, val nll: -1.3871, val mse 0.0043, lr 0.000090000\n",
      "test nll: -1.3205, test mse: 0.0047\n",
      "2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,\tIter: 2910, train loss: -1.3619, avg nll: -1.3821, avg wnll: 32.3338, avg kl: 0.0004, mse: 0.003966, wmse: 0.033370, mae: 0.047182, val nll: -1.3068, val mse 0.0046, lr 0.000090000\n",
      "test nll: -1.4398, test mse: 0.0035\n",
      "2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,\tIter: 2920, train loss: -1.3858, avg nll: -1.4055, avg wnll: 33.8672, avg kl: 0.0005, mse: 0.003831, wmse: 0.032099, mae: 0.046023, val nll: -1.3786, val mse 0.0037, lr 0.000090000\n",
      "test nll: -1.4505, test mse: 0.0037\n",
      "2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,\tIter: 2930, train loss: -1.4295, avg nll: -1.4479, avg wnll: 31.1101, avg kl: 0.0006, mse: 0.003558, wmse: 0.030110, mae: 0.044206, val nll: -1.3324, val mse 0.0045, lr 0.000090000\n",
      "test nll: -1.4220, test mse: 0.0038\n",
      "2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,\tIter: 2940, train loss: -1.3704, avg nll: -1.3908, avg wnll: 31.1750, avg kl: 0.0004, mse: 0.003995, wmse: 0.033780, mae: 0.047420, val nll: -1.4342, val mse 0.0036, lr 0.000090000\n",
      "test nll: -1.4278, test mse: 0.0036\n",
      "2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,\tIter: 2950, train loss: -1.2476, avg nll: -1.2725, avg wnll: 39.2419, avg kl: 0.0006, mse: 0.004851, wmse: 0.040394, mae: 0.052249, val nll: -1.2834, val mse 0.0048, lr 0.000090000\n",
      "test nll: -1.3815, test mse: 0.0039\n",
      "2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,\tIter: 2960, train loss: -1.3749, avg nll: -1.3946, avg wnll: 34.3285, avg kl: 0.0004, mse: 0.003836, wmse: 0.032240, mae: 0.046872, val nll: -1.4378, val mse 0.0037, lr 0.000090000\n",
      "test nll: -1.4118, test mse: 0.0038\n",
      "2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,\tIter: 2970, train loss: -1.2763, avg nll: -1.2999, avg wnll: 38.2405, avg kl: 0.0009, mse: 0.004527, wmse: 0.037994, mae: 0.052875, val nll: -1.4171, val mse 0.0035, lr 0.000090000\n",
      "test nll: -1.2314, test mse: 0.0053\n",
      "2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,\tIter: 2980, train loss: -1.3849, avg nll: -1.4049, avg wnll: 26.8069, avg kl: 0.0013, mse: 0.003756, wmse: 0.031748, mae: 0.045976, val nll: -1.4348, val mse 0.0034, lr 0.000090000\n",
      "test nll: -1.3507, test mse: 0.0045\n",
      "2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,\tIter: 2990, train loss: -1.3501, avg nll: -1.3712, avg wnll: 35.7797, avg kl: 0.0005, mse: 0.004097, wmse: 0.034320, mae: 0.047597, val nll: -1.4386, val mse 0.0033, lr 0.000090000\n",
      "test nll: -1.4258, test mse: 0.0035\n",
      "2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,\tIter: 3000, train loss: -1.3740, avg nll: -1.3945, avg wnll: 32.4281, avg kl: 0.0008, mse: 0.003943, wmse: 0.033151, mae: 0.046700, val nll: -1.3631, val mse 0.0043, lr 0.000090000\n",
      "test nll: -1.3376, test mse: 0.0046\n",
      "saving.................\n",
      "done\n",
      "3001,3002,3003,3004,3005,3006,3007,3008,3009,3010,\tIter: 3010, train loss: -1.3409, avg nll: -1.3621, avg wnll: 37.4753, avg kl: 0.0008, mse: 0.004066, wmse: 0.034864, mae: 0.049053, val nll: -1.3774, val mse 0.0041, lr 0.000090000\n",
      "test nll: -1.3574, test mse: 0.0044\n",
      "3011,3012,3013,3014,3015,3016,3017,3018,3019,3020,\tIter: 3020, train loss: -1.1583, avg nll: -1.1867, avg wnll: 41.7255, avg kl: 0.0009, mse: 0.005499, wmse: 0.045732, mae: 0.057590, val nll: -1.3970, val mse 0.0037, lr 0.000090000\n",
      "test nll: -1.3353, test mse: 0.0043\n",
      "3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,\tIter: 3030, train loss: -1.3836, avg nll: -1.4038, avg wnll: 33.5274, avg kl: 0.0005, mse: 0.003945, wmse: 0.033082, mae: 0.046416, val nll: -1.5006, val mse 0.0031, lr 0.000090000\n",
      "test nll: -1.4200, test mse: 0.0036\n",
      "3031,3032,3033,3034,3035,3036,3037,3038,3039,3040,\tIter: 3040, train loss: -1.3287, avg nll: -1.3507, avg wnll: 35.2577, avg kl: 0.0006, mse: 0.004288, wmse: 0.036092, mae: 0.049663, val nll: -1.3616, val mse 0.0044, lr 0.000090000\n",
      "test nll: -1.3653, test mse: 0.0040\n",
      "3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,\tIter: 3050, train loss: -1.3629, avg nll: -1.3835, avg wnll: 35.1814, avg kl: 0.0006, mse: 0.004004, wmse: 0.033672, mae: 0.047444, val nll: -1.4892, val mse 0.0033, lr 0.000090000\n",
      "test nll: -1.2836, test mse: 0.0050\n",
      "3051,3052,3053,3054,3055,3056,3057,3058,3059,3060,\tIter: 3060, train loss: -1.3707, avg nll: -1.3907, avg wnll: 34.2054, avg kl: 0.0005, mse: 0.003902, wmse: 0.032369, mae: 0.048279, val nll: -1.2137, val mse 0.0053, lr 0.000090000\n",
      "test nll: -1.1637, test mse: 0.0054\n",
      "3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,\tIter: 3070, train loss: -1.4360, avg nll: -1.4537, avg wnll: 33.1247, avg kl: 0.0004, mse: 0.003455, wmse: 0.029286, mae: 0.044787, val nll: -1.4130, val mse 0.0036, lr 0.000090000\n",
      "test nll: -1.4038, test mse: 0.0038\n",
      "3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,\tIter: 3080, train loss: -1.3116, avg nll: -1.3342, avg wnll: 37.2922, avg kl: 0.0007, mse: 0.004384, wmse: 0.036785, mae: 0.049676, val nll: -1.2400, val mse 0.0048, lr 0.000090000\n",
      "test nll: -1.2300, test mse: 0.0053\n",
      "3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,\tIter: 3090, train loss: -1.3657, avg nll: -1.3855, avg wnll: 27.5539, avg kl: 0.0009, mse: 0.003774, wmse: 0.032049, mae: 0.047549, val nll: -1.3331, val mse 0.0043, lr 0.000090000\n",
      "test nll: -1.3155, test mse: 0.0048\n",
      "3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,\tIter: 3100, train loss: -1.3358, avg nll: -1.3578, avg wnll: 32.8178, avg kl: 0.0010, mse: 0.004208, wmse: 0.034960, mae: 0.048732, val nll: -1.3668, val mse 0.0043, lr 0.000090000\n",
      "test nll: -1.3468, test mse: 0.0041\n",
      "3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,\tIter: 3110, train loss: -1.3365, avg nll: -1.3580, avg wnll: 36.8367, avg kl: 0.0008, mse: 0.004158, wmse: 0.035338, mae: 0.048603, val nll: -1.4651, val mse 0.0035, lr 0.000090000\n",
      "test nll: -1.4064, test mse: 0.0037\n",
      "3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,\tIter: 3120, train loss: -1.3930, avg nll: -1.4119, avg wnll: 36.3666, avg kl: 0.0004, mse: 0.003703, wmse: 0.030755, mae: 0.045467, val nll: -1.4325, val mse 0.0034, lr 0.000090000\n",
      "test nll: -1.3376, test mse: 0.0048\n",
      "3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,\tIter: 3130, train loss: -1.3982, avg nll: -1.4164, avg wnll: 30.3726, avg kl: 0.0003, mse: 0.003570, wmse: 0.029662, mae: 0.045278, val nll: -1.3005, val mse 0.0048, lr 0.000090000\n",
      "test nll: -1.3222, test mse: 0.0042\n",
      "3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,\tIter: 3140, train loss: -1.3920, avg nll: -1.4115, avg wnll: 32.0379, avg kl: 0.0004, mse: 0.003812, wmse: 0.031836, mae: 0.045353, val nll: -1.3549, val mse 0.0043, lr 0.000090000\n",
      "test nll: -1.4840, test mse: 0.0033\n",
      "3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,\tIter: 3150, train loss: -1.3965, avg nll: -1.4162, avg wnll: 35.9827, avg kl: 0.0006, mse: 0.003816, wmse: 0.032000, mae: 0.046841, val nll: -1.4383, val mse 0.0038, lr 0.000090000\n",
      "test nll: -1.4230, test mse: 0.0037\n",
      "3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,\tIter: 3160, train loss: -1.3932, avg nll: -1.4131, avg wnll: 35.9757, avg kl: 0.0003, mse: 0.003901, wmse: 0.032410, mae: 0.046173, val nll: -1.4029, val mse 0.0038, lr 0.000090000\n",
      "test nll: -1.3535, test mse: 0.0044\n",
      "3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,\tIter: 3170, train loss: -1.3321, avg nll: -1.3541, avg wnll: 37.5508, avg kl: 0.0003, mse: 0.004346, wmse: 0.035870, mae: 0.048478, val nll: -1.4294, val mse 0.0038, lr 0.000090000\n",
      "test nll: -1.3359, test mse: 0.0047\n",
      "3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,\tIter: 3180, train loss: -1.3718, avg nll: -1.3923, avg wnll: 39.1349, avg kl: 0.0005, mse: 0.004001, wmse: 0.034362, mae: 0.046947, val nll: -1.2858, val mse 0.0045, lr 0.000090000\n",
      "test nll: -1.2770, test mse: 0.0049\n",
      "3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,\tIter: 3190, train loss: -1.3928, avg nll: -1.4127, avg wnll: 32.2438, avg kl: 0.0008, mse: 0.003805, wmse: 0.032312, mae: 0.046671, val nll: -1.3580, val mse 0.0042, lr 0.000090000\n",
      "test nll: -1.4016, test mse: 0.0039\n",
      "3191,3192,3193,3194,3195,3196,3197,3198,3199,3200,\tIter: 3200, train loss: -1.3660, avg nll: -1.3868, avg wnll: 35.5427, avg kl: 0.0007, mse: 0.004017, wmse: 0.033414, mae: 0.047944, val nll: -1.3107, val mse 0.0045, lr 0.000090000\n",
      "test nll: -1.3135, test mse: 0.0043\n",
      "saving.................\n",
      "done\n",
      "3201,3202,3203,3204,3205,3206,3207,3208,3209,3210,\tIter: 3210, train loss: -1.3691, avg nll: -1.3896, avg wnll: 31.7293, avg kl: 0.0009, mse: 0.003928, wmse: 0.033252, mae: 0.047232, val nll: -1.4199, val mse 0.0035, lr 0.000090000\n",
      "test nll: -1.4527, test mse: 0.0035\n",
      "3211,3212,3213,3214,3215,3216,3217,3218,3219,3220,\tIter: 3220, train loss: -1.4026, avg nll: -1.4217, avg wnll: 35.4025, avg kl: 0.0004, mse: 0.003737, wmse: 0.031759, mae: 0.046650, val nll: -1.3299, val mse 0.0045, lr 0.000090000\n",
      "test nll: -1.3927, test mse: 0.0039\n",
      "3221,3222,3223,3224,3225,3226,3227,3228,3229,3230,\tIter: 3230, train loss: -1.4146, avg nll: -1.4337, avg wnll: 32.3159, avg kl: 0.0007, mse: 0.003687, wmse: 0.031407, mae: 0.046497, val nll: -1.5150, val mse 0.0030, lr 0.000090000\n",
      "test nll: -1.3550, test mse: 0.0045\n",
      "3231,3232,3233,3234,3235,3236,3237,3238,3239,3240,\tIter: 3240, train loss: -1.3413, avg nll: -1.3633, avg wnll: 37.7584, avg kl: 0.0005, mse: 0.004303, wmse: 0.035985, mae: 0.048535, val nll: -1.4917, val mse 0.0030, lr 0.000090000\n",
      "test nll: -1.3691, test mse: 0.0041\n",
      "3241,3242,3243,3244,3245,3246,3247,3248,3249,3250,\tIter: 3250, train loss: -1.2958, avg nll: -1.3190, avg wnll: 29.5948, avg kl: 0.0015, mse: 0.004351, wmse: 0.036333, mae: 0.050553, val nll: -1.3647, val mse 0.0039, lr 0.000090000\n",
      "test nll: -1.3582, test mse: 0.0040\n",
      "3251,3252,3253,3254,3255,3256,3257,3258,3259,3260,\tIter: 3260, train loss: -1.3628, avg nll: -1.3830, avg wnll: 33.9156, avg kl: 0.0006, mse: 0.003910, wmse: 0.032927, mae: 0.049225, val nll: -1.3976, val mse 0.0042, lr 0.000090000\n",
      "test nll: -1.2660, test mse: 0.0050\n",
      "3261,3262,3263,3264,3265,3266,3267,3268,3269,3270,\tIter: 3270, train loss: -1.3530, avg nll: -1.3736, avg wnll: 26.6869, avg kl: 0.0012, mse: 0.003879, wmse: 0.032013, mae: 0.046658, val nll: -1.3268, val mse 0.0044, lr 0.000090000\n",
      "test nll: -1.1269, test mse: 0.0060\n",
      "3271,3272,3273,3274,3275,3276,3277,3278,3279,3280,\tIter: 3280, train loss: -1.2843, avg nll: -1.3079, avg wnll: 35.5177, avg kl: 0.0010, mse: 0.004524, wmse: 0.038171, mae: 0.050942, val nll: -1.3391, val mse 0.0042, lr 0.000090000\n",
      "test nll: -1.3387, test mse: 0.0041\n",
      "3281,3282,3283,3284,3285,3286,3287,3288,3289,3290,\tIter: 3290, train loss: -1.2760, avg nll: -1.2991, avg wnll: 41.6622, avg kl: 0.0007, mse: 0.004476, wmse: 0.037807, mae: 0.051310, val nll: -1.2331, val mse 0.0052, lr 0.000090000\n",
      "test nll: -1.4370, test mse: 0.0036\n",
      "3291,3292,3293,3294,3295,3296,3297,3298,3299,3300,\tIter: 3300, train loss: -1.3705, avg nll: -1.3914, avg wnll: 31.7628, avg kl: 0.0007, mse: 0.004056, wmse: 0.033575, mae: 0.047262, val nll: -1.3637, val mse 0.0046, lr 0.000090000\n",
      "test nll: -1.3067, test mse: 0.0048\n",
      "3301,3302,3303,3304,3305,3306,3307,3308,3309,3310,\tIter: 3310, train loss: -1.3030, avg nll: -1.3258, avg wnll: 39.9585, avg kl: 0.0006, mse: 0.004438, wmse: 0.037597, mae: 0.050901, val nll: -1.2596, val mse 0.0048, lr 0.000090000\n",
      "test nll: -1.2927, test mse: 0.0050\n",
      "3311,3312,3313,3314,3315,3316,3317,3318,3319,3320,\tIter: 3320, train loss: -1.4051, avg nll: -1.4248, avg wnll: 30.8463, avg kl: 0.0012, mse: 0.003707, wmse: 0.031520, mae: 0.046010, val nll: -1.4486, val mse 0.0035, lr 0.000090000\n",
      "test nll: -1.3394, test mse: 0.0044\n",
      "3321,3322,3323,3324,3325,3326,3327,3328,3329,3330,\tIter: 3330, train loss: -1.4216, avg nll: -1.4403, avg wnll: 27.0375, avg kl: 0.0013, mse: 0.003479, wmse: 0.029130, mae: 0.044824, val nll: -1.4755, val mse 0.0035, lr 0.000090000\n",
      "test nll: -1.3780, test mse: 0.0041\n",
      "3331,3332,3333,3334,3335,3336,3337,3338,3339,3340,\tIter: 3340, train loss: -1.3902, avg nll: -1.4097, avg wnll: 35.7846, avg kl: 0.0005, mse: 0.003800, wmse: 0.032250, mae: 0.047007, val nll: -1.4125, val mse 0.0039, lr 0.000090000\n",
      "test nll: -1.3946, test mse: 0.0041\n",
      "3341,3342,3343,3344,3345,3346,3347,3348,3349,3350,\tIter: 3350, train loss: -1.2920, avg nll: -1.3158, avg wnll: 40.3885, avg kl: 0.0007, mse: 0.004617, wmse: 0.039608, mae: 0.052369, val nll: -1.3058, val mse 0.0046, lr 0.000090000\n",
      "test nll: -1.1144, test mse: 0.0059\n",
      "3351,3352,3353,3354,3355,3356,3357,3358,3359,3360,\tIter: 3360, train loss: -1.3038, avg nll: -1.3260, avg wnll: 39.7038, avg kl: 0.0006, mse: 0.004312, wmse: 0.036155, mae: 0.051789, val nll: -1.3437, val mse 0.0044, lr 0.000090000\n",
      "test nll: -1.3706, test mse: 0.0043\n",
      "3361,3362,3363,3364,3365,3366,3367,3368,3369,3370,\tIter: 3370, train loss: -1.4111, avg nll: -1.4304, avg wnll: 34.3809, avg kl: 0.0004, mse: 0.003782, wmse: 0.031502, mae: 0.044867, val nll: -1.3999, val mse 0.0044, lr 0.000090000\n",
      "test nll: -1.4227, test mse: 0.0040\n",
      "3371,3372,3373,3374,3375,3376,3377,3378,3379,3380,\tIter: 3380, train loss: -1.3998, avg nll: -1.4187, avg wnll: 31.0139, avg kl: 0.0003, mse: 0.003695, wmse: 0.030899, mae: 0.044871, val nll: -1.3738, val mse 0.0041, lr 0.000090000\n",
      "test nll: -1.3577, test mse: 0.0046\n",
      "3381,3382,3383,3384,3385,3386,3387,3388,3389,3390,\tIter: 3390, train loss: -1.3539, avg nll: -1.3749, avg wnll: 33.3576, avg kl: 0.0004, mse: 0.004127, wmse: 0.034589, mae: 0.048170, val nll: -1.4611, val mse 0.0033, lr 0.000090000\n",
      "test nll: -1.3183, test mse: 0.0045\n",
      "3391,3392,3393,3394,3395,3396,3397,3398,3399,3400,\tIter: 3400, train loss: -1.4254, avg nll: -1.4431, avg wnll: 33.6371, avg kl: 0.0005, mse: 0.003439, wmse: 0.028761, mae: 0.045246, val nll: -1.4842, val mse 0.0032, lr 0.000081000\n",
      "test nll: -1.4365, test mse: 0.0035\n",
      "saving.................\n",
      "done\n",
      "3401,3402,3403,3404,3405,3406,3407,3408,3409,3410,\tIter: 3410, train loss: -1.3847, avg nll: -1.4053, avg wnll: 32.3231, avg kl: 0.0008, mse: 0.003954, wmse: 0.033471, mae: 0.046950, val nll: -1.2717, val mse 0.0049, lr 0.000081000\n",
      "test nll: -1.3753, test mse: 0.0039\n",
      "3411,3412,3413,3414,3415,3416,3417,3418,3419,3420,\tIter: 3420, train loss: -1.3756, avg nll: -1.3962, avg wnll: 33.7028, avg kl: 0.0006, mse: 0.004014, wmse: 0.033805, mae: 0.048617, val nll: -1.3103, val mse 0.0045, lr 0.000081000\n",
      "test nll: -1.4215, test mse: 0.0035\n",
      "3421,3422,3423,3424,3425,3426,3427,3428,3429,3430,\tIter: 3430, train loss: -1.3485, avg nll: -1.3700, avg wnll: 38.2108, avg kl: 0.0006, mse: 0.004175, wmse: 0.034901, mae: 0.047716, val nll: -1.3348, val mse 0.0044, lr 0.000081000\n",
      "test nll: -1.4341, test mse: 0.0037\n",
      "3431,3432,3433,3434,3435,3436,3437,3438,3439,3440,\tIter: 3440, train loss: -1.4507, avg nll: -1.4681, avg wnll: 31.6596, avg kl: 0.0004, mse: 0.003404, wmse: 0.029155, mae: 0.044614, val nll: -1.3789, val mse 0.0044, lr 0.000081000\n",
      "test nll: -1.3743, test mse: 0.0041\n",
      "3441,3442,3443,3444,3445,3446,3447,3448,3449,3450,\tIter: 3450, train loss: -1.4716, avg nll: -1.4883, avg wnll: 31.6289, avg kl: 0.0002, mse: 0.003286, wmse: 0.027551, mae: 0.043269, val nll: -1.3446, val mse 0.0043, lr 0.000081000\n",
      "test nll: -1.3162, test mse: 0.0047\n",
      "3451,3452,3453,3454,3455,3456,3457,3458,3459,3460,\tIter: 3460, train loss: -1.4034, avg nll: -1.4230, avg wnll: 35.5944, avg kl: 0.0004, mse: 0.003840, wmse: 0.032907, mae: 0.046203, val nll: -1.4986, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.3962, test mse: 0.0043\n",
      "3461,3462,3463,3464,3465,3466,3467,3468,3469,3470,\tIter: 3470, train loss: -1.3924, avg nll: -1.4123, avg wnll: 35.9576, avg kl: 0.0003, mse: 0.003918, wmse: 0.032898, mae: 0.046241, val nll: -1.2215, val mse 0.0054, lr 0.000081000\n",
      "test nll: -1.3922, test mse: 0.0042\n",
      "3471,3472,3473,3474,3475,3476,3477,3478,3479,3480,\tIter: 3480, train loss: -1.4284, avg nll: -1.4465, avg wnll: 33.2940, avg kl: 0.0004, mse: 0.003542, wmse: 0.029503, mae: 0.044557, val nll: -1.4977, val mse 0.0031, lr 0.000081000\n",
      "test nll: -1.4343, test mse: 0.0036\n",
      "3481,3482,3483,3484,3485,3486,3487,3488,3489,3490,\tIter: 3490, train loss: -1.3886, avg nll: -1.4085, avg wnll: 33.5720, avg kl: 0.0005, mse: 0.003872, wmse: 0.032779, mae: 0.047681, val nll: -1.4389, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4068, test mse: 0.0040\n",
      "3491,3492,3493,3494,3495,3496,3497,3498,3499,3500,\tIter: 3500, train loss: -1.4150, avg nll: -1.4339, avg wnll: 33.4825, avg kl: 0.0006, mse: 0.003664, wmse: 0.030559, mae: 0.045399, val nll: -1.4573, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.3400, test mse: 0.0041\n",
      "3501,3502,3503,3504,3505,3506,3507,3508,3509,3510,\tIter: 3510, train loss: -1.4201, avg nll: -1.4385, avg wnll: 27.4607, avg kl: 0.0008, mse: 0.003528, wmse: 0.029717, mae: 0.044826, val nll: -1.3947, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4507, test mse: 0.0031\n",
      "3511,3512,3513,3514,3515,3516,3517,3518,3519,3520,\tIter: 3520, train loss: -1.3991, avg nll: -1.4181, avg wnll: 30.2298, avg kl: 0.0007, mse: 0.003664, wmse: 0.030712, mae: 0.045641, val nll: -1.4404, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4116, test mse: 0.0040\n",
      "3521,3522,3523,3524,3525,3526,3527,3528,3529,3530,\tIter: 3530, train loss: -1.3155, avg nll: -1.3371, avg wnll: 38.3138, avg kl: 0.0004, mse: 0.004236, wmse: 0.035402, mae: 0.048416, val nll: -1.4407, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.2890, test mse: 0.0046\n",
      "3531,3532,3533,3534,3535,3536,3537,3538,3539,3540,\tIter: 3540, train loss: -1.4312, avg nll: -1.4497, avg wnll: 35.6518, avg kl: 0.0003, mse: 0.003650, wmse: 0.030936, mae: 0.044893, val nll: -1.4855, val mse 0.0034, lr 0.000081000\n",
      "test nll: -1.5360, test mse: 0.0028\n",
      "3541,3542,3543,3544,3545,3546,3547,3548,3549,3550,\tIter: 3550, train loss: -1.4528, avg nll: -1.4704, avg wnll: 30.9861, avg kl: 0.0005, mse: 0.003412, wmse: 0.029011, mae: 0.044136, val nll: -1.4443, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4975, test mse: 0.0030\n",
      "3551,3552,3553,3554,3555,3556,3557,3558,3559,3560,\tIter: 3560, train loss: -1.3827, avg nll: -1.4039, avg wnll: 35.2762, avg kl: 0.0005, mse: 0.004128, wmse: 0.034682, mae: 0.046944, val nll: -1.4254, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.3819, test mse: 0.0042\n",
      "3561,3562,3563,3564,3565,3566,3567,3568,3569,3570,\tIter: 3570, train loss: -1.4143, avg nll: -1.4327, avg wnll: 32.3682, avg kl: 0.0007, mse: 0.003548, wmse: 0.029454, mae: 0.046005, val nll: -1.4820, val mse 0.0032, lr 0.000081000\n",
      "test nll: -1.3288, test mse: 0.0047\n",
      "3571,3572,3573,3574,3575,3576,3577,3578,3579,3580,\tIter: 3580, train loss: -1.3068, avg nll: -1.3289, avg wnll: 37.6816, avg kl: 0.0006, mse: 0.004310, wmse: 0.035774, mae: 0.050020, val nll: -1.3571, val mse 0.0041, lr 0.000081000\n",
      "test nll: -1.2545, test mse: 0.0049\n",
      "3581,3582,3583,3584,3585,3586,3587,3588,3589,3590,\tIter: 3590, train loss: -1.4005, avg nll: -1.4203, avg wnll: 35.7930, avg kl: 0.0007, mse: 0.003826, wmse: 0.032779, mae: 0.047114, val nll: -1.3396, val mse 0.0044, lr 0.000081000\n",
      "test nll: -1.3709, test mse: 0.0041\n",
      "3591,3592,3593,3594,3595,3596,3597,3598,3599,3600,\tIter: 3600, train loss: -1.3280, avg nll: -1.3496, avg wnll: 36.8311, avg kl: 0.0004, mse: 0.004228, wmse: 0.035233, mae: 0.049411, val nll: -1.1489, val mse 0.0056, lr 0.000081000\n",
      "test nll: -1.4100, test mse: 0.0034\n",
      "saving.................\n",
      "done\n",
      "3601,3602,3603,3604,3605,3606,3607,3608,3609,3610,\tIter: 3610, train loss: -1.4327, avg nll: -1.4515, avg wnll: 34.3630, avg kl: 0.0005, mse: 0.003665, wmse: 0.031119, mae: 0.045778, val nll: -1.3917, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4094, test mse: 0.0038\n",
      "3611,3612,3613,3614,3615,3616,3617,3618,3619,3620,\tIter: 3620, train loss: -1.3995, avg nll: -1.4198, avg wnll: 31.3115, avg kl: 0.0005, mse: 0.003946, wmse: 0.033719, mae: 0.047106, val nll: -1.4185, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.4983, test mse: 0.0029\n",
      "3621,3622,3623,3624,3625,3626,3627,3628,3629,3630,\tIter: 3630, train loss: -1.3960, avg nll: -1.4163, avg wnll: 33.8998, avg kl: 0.0004, mse: 0.003991, wmse: 0.033659, mae: 0.047344, val nll: -1.4104, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.4272, test mse: 0.0039\n",
      "3631,3632,3633,3634,3635,3636,3637,3638,3639,3640,\tIter: 3640, train loss: -1.3450, avg nll: -1.3661, avg wnll: 36.3110, avg kl: 0.0007, mse: 0.004074, wmse: 0.034223, mae: 0.049348, val nll: -1.4502, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.3788, test mse: 0.0040\n",
      "3641,3642,3643,3644,3645,3646,3647,3648,3649,3650,\tIter: 3650, train loss: -1.3468, avg nll: -1.3682, avg wnll: 37.8953, avg kl: 0.0004, mse: 0.004206, wmse: 0.035363, mae: 0.048863, val nll: -1.3581, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.4008, test mse: 0.0040\n",
      "3651,3652,3653,3654,3655,3656,3657,3658,3659,3660,\tIter: 3660, train loss: -1.3940, avg nll: -1.4138, avg wnll: 34.6726, avg kl: 0.0004, mse: 0.003861, wmse: 0.032576, mae: 0.045983, val nll: -1.4161, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.4134, test mse: 0.0039\n",
      "3661,3662,3663,3664,3665,3666,3667,3668,3669,3670,\tIter: 3670, train loss: -1.4090, avg nll: -1.4280, avg wnll: 34.0900, avg kl: 0.0004, mse: 0.003722, wmse: 0.031472, mae: 0.045742, val nll: -1.4058, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.4482, test mse: 0.0032\n",
      "3671,3672,3673,3674,3675,3676,3677,3678,3679,3680,\tIter: 3680, train loss: -1.3910, avg nll: -1.4109, avg wnll: 33.2082, avg kl: 0.0004, mse: 0.003915, wmse: 0.032373, mae: 0.046448, val nll: -1.4037, val mse 0.0041, lr 0.000081000\n",
      "test nll: -1.3790, test mse: 0.0042\n",
      "3681,3682,3683,3684,3685,3686,3687,3688,3689,3690,\tIter: 3690, train loss: -1.3082, avg nll: -1.3308, avg wnll: 40.3617, avg kl: 0.0008, mse: 0.004369, wmse: 0.036286, mae: 0.049531, val nll: -1.4545, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4189, test mse: 0.0038\n",
      "3691,3692,3693,3694,3695,3696,3697,3698,3699,3700,\tIter: 3700, train loss: -1.3823, avg nll: -1.4028, avg wnll: 39.3928, avg kl: 0.0003, mse: 0.004032, wmse: 0.034642, mae: 0.046628, val nll: -1.4354, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4780, test mse: 0.0031\n",
      "3701,3702,3703,3704,3705,3706,3707,3708,3709,3710,\tIter: 3710, train loss: -1.3644, avg nll: -1.3853, avg wnll: 33.3207, avg kl: 0.0004, mse: 0.004092, wmse: 0.034402, mae: 0.048353, val nll: -1.3843, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.3038, test mse: 0.0049\n",
      "3711,3712,3713,3714,3715,3716,3717,3718,3719,3720,\tIter: 3720, train loss: -1.2788, avg nll: -1.3028, avg wnll: 36.5955, avg kl: 0.0009, mse: 0.004635, wmse: 0.038531, mae: 0.051839, val nll: -1.3061, val mse 0.0046, lr 0.000081000\n",
      "test nll: -1.2788, test mse: 0.0047\n",
      "3721,3722,3723,3724,3725,3726,3727,3728,3729,3730,\tIter: 3730, train loss: -1.3396, avg nll: -1.3611, avg wnll: 36.3004, avg kl: 0.0006, mse: 0.004180, wmse: 0.034923, mae: 0.049175, val nll: -1.3492, val mse 0.0047, lr 0.000081000\n",
      "test nll: -1.3980, test mse: 0.0038\n",
      "3731,3732,3733,3734,3735,3736,3737,3738,3739,3740,\tIter: 3740, train loss: -1.3396, avg nll: -1.3607, avg wnll: 40.0381, avg kl: 0.0003, mse: 0.004176, wmse: 0.035227, mae: 0.048893, val nll: -1.4560, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.2881, test mse: 0.0048\n",
      "3741,3742,3743,3744,3745,3746,3747,3748,3749,3750,\tIter: 3750, train loss: -1.4205, avg nll: -1.4385, avg wnll: 34.2474, avg kl: 0.0005, mse: 0.003501, wmse: 0.029409, mae: 0.045491, val nll: -1.3939, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.3845, test mse: 0.0042\n",
      "3751,3752,3753,3754,3755,3756,3757,3758,3759,3760,\tIter: 3760, train loss: -1.4289, avg nll: -1.4476, avg wnll: 34.1250, avg kl: 0.0004, mse: 0.003680, wmse: 0.030871, mae: 0.045281, val nll: -1.4236, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.4132, test mse: 0.0039\n",
      "3761,3762,3763,3764,3765,3766,3767,3768,3769,3770,\tIter: 3770, train loss: -1.4638, avg nll: -1.4809, avg wnll: 30.7458, avg kl: 0.0004, mse: 0.003359, wmse: 0.027973, mae: 0.043776, val nll: -1.5347, val mse 0.0031, lr 0.000081000\n",
      "test nll: -1.3269, test mse: 0.0045\n",
      "3771,3772,3773,3774,3775,3776,3777,3778,3779,3780,\tIter: 3780, train loss: -1.4004, avg nll: -1.4195, avg wnll: 33.7766, avg kl: 0.0002, mse: 0.003752, wmse: 0.031489, mae: 0.045046, val nll: -1.4363, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4622, test mse: 0.0035\n",
      "3781,3782,3783,3784,3785,3786,3787,3788,3789,3790,\tIter: 3790, train loss: -1.3767, avg nll: -1.3973, avg wnll: 36.0552, avg kl: 0.0004, mse: 0.004024, wmse: 0.033752, mae: 0.046835, val nll: -1.4641, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.3815, test mse: 0.0039\n",
      "3791,3792,3793,3794,3795,3796,3797,3798,3799,3800,\tIter: 3800, train loss: -1.2245, avg nll: -1.2484, avg wnll: 45.4931, avg kl: 0.0004, mse: 0.004710, wmse: 0.039518, mae: 0.052741, val nll: -1.2772, val mse 0.0048, lr 0.000081000\n",
      "test nll: -1.0255, test mse: 0.0062\n",
      "saving.................\n",
      "done\n",
      "3801,3802,3803,3804,3805,3806,3807,3808,3809,3810,\tIter: 3810, train loss: -1.3205, avg nll: -1.3432, avg wnll: 38.7408, avg kl: 0.0010, mse: 0.004327, wmse: 0.036508, mae: 0.050432, val nll: -1.3910, val mse 0.0042, lr 0.000081000\n",
      "test nll: -1.3769, test mse: 0.0044\n",
      "3811,3812,3813,3814,3815,3816,3817,3818,3819,3820,\tIter: 3820, train loss: -1.2960, avg nll: -1.3188, avg wnll: 40.8147, avg kl: 0.0006, mse: 0.004445, wmse: 0.037313, mae: 0.050535, val nll: -1.1159, val mse 0.0054, lr 0.000081000\n",
      "test nll: -1.1027, test mse: 0.0065\n",
      "3821,3822,3823,3824,3825,3826,3827,3828,3829,3830,\tIter: 3830, train loss: -1.3976, avg nll: -1.4178, avg wnll: 33.5599, avg kl: 0.0006, mse: 0.003923, wmse: 0.032726, mae: 0.046122, val nll: -1.5301, val mse 0.0029, lr 0.000081000\n",
      "test nll: -1.4680, test mse: 0.0032\n",
      "3831,3832,3833,3834,3835,3836,3837,3838,3839,3840,\tIter: 3840, train loss: -1.2124, avg nll: -1.2374, avg wnll: 43.0388, avg kl: 0.0008, mse: 0.004842, wmse: 0.040083, mae: 0.054293, val nll: -1.4707, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.3379, test mse: 0.0045\n",
      "3841,3842,3843,3844,3845,3846,3847,3848,3849,3850,\tIter: 3850, train loss: -1.3631, avg nll: -1.3845, avg wnll: 34.2144, avg kl: 0.0009, mse: 0.004116, wmse: 0.034588, mae: 0.047807, val nll: -1.3769, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.3314, test mse: 0.0046\n",
      "3851,3852,3853,3854,3855,3856,3857,3858,3859,3860,\tIter: 3860, train loss: -1.3794, avg nll: -1.4008, avg wnll: 35.0973, avg kl: 0.0014, mse: 0.003998, wmse: 0.034163, mae: 0.047868, val nll: -1.3545, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.3924, test mse: 0.0040\n",
      "3861,3862,3863,3864,3865,3866,3867,3868,3869,3870,\tIter: 3870, train loss: -1.3494, avg nll: -1.3701, avg wnll: 37.7828, avg kl: 0.0005, mse: 0.004059, wmse: 0.034553, mae: 0.047997, val nll: -1.4784, val mse 0.0031, lr 0.000081000\n",
      "test nll: -1.3702, test mse: 0.0045\n",
      "3871,3872,3873,3874,3875,3876,3877,3878,3879,3880,\tIter: 3880, train loss: -1.4438, avg nll: -1.4619, avg wnll: 32.7623, avg kl: 0.0003, mse: 0.003546, wmse: 0.029872, mae: 0.044190, val nll: -1.5179, val mse 0.0030, lr 0.000081000\n",
      "test nll: -1.4532, test mse: 0.0034\n",
      "3881,3882,3883,3884,3885,3886,3887,3888,3889,3890,\tIter: 3890, train loss: -1.3229, avg nll: -1.3454, avg wnll: 35.7712, avg kl: 0.0005, mse: 0.004400, wmse: 0.036995, mae: 0.050393, val nll: -1.4645, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.3640, test mse: 0.0044\n",
      "3891,3892,3893,3894,3895,3896,3897,3898,3899,3900,\tIter: 3900, train loss: -1.3413, avg nll: -1.3628, avg wnll: 36.0508, avg kl: 0.0005, mse: 0.004194, wmse: 0.034804, mae: 0.048798, val nll: -1.4332, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.4555, test mse: 0.0038\n",
      "3901,3902,3903,3904,3905,3906,3907,3908,3909,3910,\tIter: 3910, train loss: -1.2515, avg nll: -1.2762, avg wnll: 39.2066, avg kl: 0.0006, mse: 0.004810, wmse: 0.040470, mae: 0.052565, val nll: -1.4269, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.3198, test mse: 0.0046\n",
      "3911,3912,3913,3914,3915,3916,3917,3918,3919,3920,\tIter: 3920, train loss: -1.1841, avg nll: -1.2108, avg wnll: 44.3620, avg kl: 0.0010, mse: 0.005138, wmse: 0.042503, mae: 0.055221, val nll: -1.1382, val mse 0.0056, lr 0.000081000\n",
      "test nll: -1.3915, test mse: 0.0036\n",
      "3921,3922,3923,3924,3925,3926,3927,3928,3929,3930,\tIter: 3930, train loss: -1.4192, avg nll: -1.4387, avg wnll: 33.3142, avg kl: 0.0008, mse: 0.003755, wmse: 0.031501, mae: 0.045744, val nll: -1.3178, val mse 0.0048, lr 0.000081000\n",
      "test nll: -1.4029, test mse: 0.0040\n",
      "3931,3932,3933,3934,3935,3936,3937,3938,3939,3940,\tIter: 3940, train loss: -1.4176, avg nll: -1.4362, avg wnll: 32.4806, avg kl: 0.0004, mse: 0.003635, wmse: 0.030869, mae: 0.044819, val nll: -1.2733, val mse 0.0046, lr 0.000081000\n",
      "test nll: -1.3644, test mse: 0.0044\n",
      "3941,3942,3943,3944,3945,3946,3947,3948,3949,3950,\tIter: 3950, train loss: -1.3909, avg nll: -1.4110, avg wnll: 28.9851, avg kl: 0.0007, mse: 0.003854, wmse: 0.032609, mae: 0.047087, val nll: -1.1849, val mse 0.0055, lr 0.000081000\n",
      "test nll: -1.4918, test mse: 0.0030\n",
      "3951,3952,3953,3954,3955,3956,3957,3958,3959,3960,\tIter: 3960, train loss: -1.3983, avg nll: -1.4184, avg wnll: 35.1556, avg kl: 0.0004, mse: 0.003935, wmse: 0.032721, mae: 0.046189, val nll: -1.4262, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.4230, test mse: 0.0037\n",
      "3961,3962,3963,3964,3965,3966,3967,3968,3969,3970,\tIter: 3970, train loss: -1.3739, avg nll: -1.3937, avg wnll: 35.5693, avg kl: 0.0004, mse: 0.003893, wmse: 0.032616, mae: 0.047002, val nll: -1.5159, val mse 0.0028, lr 0.000081000\n",
      "test nll: -1.2806, test mse: 0.0051\n",
      "3971,3972,3973,3974,3975,3976,3977,3978,3979,3980,\tIter: 3980, train loss: -1.4262, avg nll: -1.4445, avg wnll: 34.4667, avg kl: 0.0003, mse: 0.003590, wmse: 0.029988, mae: 0.044888, val nll: -1.4163, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.4012, test mse: 0.0041\n",
      "3981,3982,3983,3984,3985,3986,3987,3988,3989,3990,\tIter: 3990, train loss: -1.4348, avg nll: -1.4527, avg wnll: 34.3507, avg kl: 0.0004, mse: 0.003493, wmse: 0.029089, mae: 0.045603, val nll: -1.3592, val mse 0.0041, lr 0.000081000\n",
      "test nll: -1.3749, test mse: 0.0042\n",
      "3991,3992,3993,3994,3995,3996,3997,3998,3999,4000,\tIter: 4000, train loss: -1.4002, avg nll: -1.4205, avg wnll: 32.7136, avg kl: 0.0007, mse: 0.003910, wmse: 0.032996, mae: 0.047168, val nll: -1.3736, val mse 0.0044, lr 0.000081000\n",
      "test nll: -1.4188, test mse: 0.0041\n",
      "saving.................\n",
      "done\n",
      "4001,4002,4003,4004,4005,4006,4007,4008,4009,4010,\tIter: 4010, train loss: -1.3492, avg nll: -1.3701, avg wnll: 33.2645, avg kl: 0.0010, mse: 0.003989, wmse: 0.033387, mae: 0.048523, val nll: -1.4084, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.3292, test mse: 0.0043\n",
      "4011,4012,4013,4014,4015,4016,4017,4018,4019,4020,\tIter: 4020, train loss: -1.3849, avg nll: -1.4049, avg wnll: 32.1079, avg kl: 0.0008, mse: 0.003848, wmse: 0.032276, mae: 0.047367, val nll: -1.3890, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.3256, test mse: 0.0040\n",
      "4021,4022,4023,4024,4025,4026,4027,4028,4029,4030,\tIter: 4030, train loss: -1.4389, avg nll: -1.4579, avg wnll: 34.3853, avg kl: 0.0006, mse: 0.003675, wmse: 0.031427, mae: 0.045737, val nll: -1.4295, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.5071, test mse: 0.0032\n",
      "4031,4032,4033,4034,4035,4036,4037,4038,4039,4040,\tIter: 4040, train loss: -1.4033, avg nll: -1.4224, avg wnll: 35.4153, avg kl: 0.0004, mse: 0.003760, wmse: 0.032251, mae: 0.046635, val nll: -1.4747, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.4156, test mse: 0.0041\n",
      "4041,4042,4043,4044,4045,4046,4047,4048,4049,4050,\tIter: 4050, train loss: -1.3345, avg nll: -1.3563, avg wnll: 37.8974, avg kl: 0.0004, mse: 0.004279, wmse: 0.036091, mae: 0.049241, val nll: -1.3895, val mse 0.0042, lr 0.000081000\n",
      "test nll: -1.3822, test mse: 0.0043\n",
      "4051,4052,4053,4054,4055,4056,4057,4058,4059,4060,\tIter: 4060, train loss: -1.3756, avg nll: -1.3961, avg wnll: 37.9456, avg kl: 0.0003, mse: 0.004051, wmse: 0.034103, mae: 0.047645, val nll: -1.3286, val mse 0.0047, lr 0.000081000\n",
      "test nll: -1.5076, test mse: 0.0031\n",
      "4061,4062,4063,4064,4065,4066,4067,4068,4069,4070,\tIter: 4070, train loss: -1.4063, avg nll: -1.4252, avg wnll: 37.6683, avg kl: 0.0003, mse: 0.003722, wmse: 0.031649, mae: 0.046583, val nll: -1.3245, val mse 0.0047, lr 0.000081000\n",
      "test nll: -1.3470, test mse: 0.0044\n",
      "4071,4072,4073,4074,4075,4076,4077,4078,4079,4080,\tIter: 4080, train loss: -1.4283, avg nll: -1.4473, avg wnll: 34.2695, avg kl: 0.0003, mse: 0.003728, wmse: 0.031128, mae: 0.045127, val nll: -1.4139, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.3266, test mse: 0.0044\n",
      "4081,4082,4083,4084,4085,4086,4087,4088,4089,4090,\tIter: 4090, train loss: -1.3480, avg nll: -1.3699, avg wnll: 30.6406, avg kl: 0.0012, mse: 0.004143, wmse: 0.034530, mae: 0.047594, val nll: -1.4429, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.4301, test mse: 0.0037\n",
      "4091,4092,4093,4094,4095,4096,4097,4098,4099,4100,\tIter: 4100, train loss: -1.3571, avg nll: -1.3790, avg wnll: 36.0009, avg kl: 0.0008, mse: 0.004244, wmse: 0.035580, mae: 0.047543, val nll: -1.3097, val mse 0.0043, lr 0.000081000\n",
      "test nll: -1.3662, test mse: 0.0043\n",
      "4101,4102,4103,4104,4105,4106,4107,4108,4109,4110,\tIter: 4110, train loss: -1.4256, avg nll: -1.4443, avg wnll: 33.1154, avg kl: 0.0006, mse: 0.003623, wmse: 0.030521, mae: 0.044822, val nll: -1.4394, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.3500, test mse: 0.0045\n",
      "4111,4112,4113,4114,4115,4116,4117,4118,4119,4120,\tIter: 4120, train loss: -1.3459, avg nll: -1.3678, avg wnll: 31.9071, avg kl: 0.0011, mse: 0.004173, wmse: 0.035581, mae: 0.048118, val nll: -1.3958, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.4098, test mse: 0.0040\n",
      "4121,4122,4123,4124,4125,4126,4127,4128,4129,4130,\tIter: 4130, train loss: -1.4385, avg nll: -1.4571, avg wnll: 32.2844, avg kl: 0.0006, mse: 0.003606, wmse: 0.030149, mae: 0.043657, val nll: -1.4391, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4197, test mse: 0.0035\n",
      "4131,4132,4133,4134,4135,4136,4137,4138,4139,4140,\tIter: 4140, train loss: -1.4147, avg nll: -1.4340, avg wnll: 34.6183, avg kl: 0.0005, mse: 0.003774, wmse: 0.031768, mae: 0.046003, val nll: -1.4304, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.3606, test mse: 0.0045\n",
      "4141,4142,4143,4144,4145,4146,4147,4148,4149,4150,\tIter: 4150, train loss: -1.3067, avg nll: -1.3294, avg wnll: 37.0524, avg kl: 0.0007, mse: 0.004410, wmse: 0.037122, mae: 0.050208, val nll: -1.3580, val mse 0.0043, lr 0.000081000\n",
      "test nll: -1.4080, test mse: 0.0040\n",
      "4151,4152,4153,4154,4155,4156,4157,4158,4159,4160,\tIter: 4160, train loss: -1.3630, avg nll: -1.3840, avg wnll: 36.2586, avg kl: 0.0004, mse: 0.004131, wmse: 0.034713, mae: 0.047812, val nll: -1.4577, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.4516, test mse: 0.0035\n",
      "4161,4162,4163,4164,4165,4166,4167,4168,4169,4170,\tIter: 4170, train loss: -1.3664, avg nll: -1.3873, avg wnll: 35.0944, avg kl: 0.0003, mse: 0.004116, wmse: 0.034738, mae: 0.048125, val nll: -1.3497, val mse 0.0047, lr 0.000081000\n",
      "test nll: -1.3519, test mse: 0.0042\n",
      "4171,4172,4173,4174,4175,4176,4177,4178,4179,4180,\tIter: 4180, train loss: -1.3978, avg nll: -1.4170, avg wnll: 32.5435, avg kl: 0.0004, mse: 0.003757, wmse: 0.031274, mae: 0.046330, val nll: -1.4492, val mse 0.0034, lr 0.000081000\n",
      "test nll: -1.3707, test mse: 0.0043\n",
      "4181,4182,4183,4184,4185,4186,4187,4188,4189,4190,\tIter: 4190, train loss: -1.4378, avg nll: -1.4558, avg wnll: 32.3852, avg kl: 0.0006, mse: 0.003487, wmse: 0.029426, mae: 0.044992, val nll: -1.5040, val mse 0.0032, lr 0.000081000\n",
      "test nll: -1.3200, test mse: 0.0044\n",
      "4191,4192,4193,4194,4195,4196,4197,4198,4199,4200,\tIter: 4200, train loss: -1.3007, avg nll: -1.3240, avg wnll: 39.7408, avg kl: 0.0004, mse: 0.004573, wmse: 0.038490, mae: 0.051173, val nll: -1.5312, val mse 0.0027, lr 0.000081000\n",
      "test nll: -1.3900, test mse: 0.0043\n",
      "saving.................\n",
      "done\n",
      "4201,4202,4203,4204,4205,4206,4207,4208,4209,4210,\tIter: 4210, train loss: -1.4483, avg nll: -1.4655, avg wnll: 33.0502, avg kl: 0.0004, mse: 0.003367, wmse: 0.027962, mae: 0.044269, val nll: -1.3970, val mse 0.0043, lr 0.000081000\n",
      "test nll: -1.3748, test mse: 0.0040\n",
      "4211,4212,4213,4214,4215,4216,4217,4218,4219,4220,\tIter: 4220, train loss: -1.4339, avg nll: -1.4522, avg wnll: 31.6504, avg kl: 0.0002, mse: 0.003610, wmse: 0.030908, mae: 0.045005, val nll: -1.4739, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.4162, test mse: 0.0037\n",
      "4221,4222,4223,4224,4225,4226,4227,4228,4229,4230,\tIter: 4230, train loss: -1.4608, avg nll: -1.4788, avg wnll: 32.5777, avg kl: 0.0003, mse: 0.003556, wmse: 0.029895, mae: 0.043942, val nll: -1.4373, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4840, test mse: 0.0035\n",
      "4231,4232,4233,4234,4235,4236,4237,4238,4239,4240,\tIter: 4240, train loss: -1.4091, avg nll: -1.4286, avg wnll: 33.7337, avg kl: 0.0004, mse: 0.003816, wmse: 0.031590, mae: 0.045300, val nll: -1.3155, val mse 0.0047, lr 0.000081000\n",
      "test nll: -1.3450, test mse: 0.0044\n",
      "4241,4242,4243,4244,4245,4246,4247,4248,4249,4250,\tIter: 4250, train loss: -1.4728, avg nll: -1.4892, avg wnll: 32.1858, avg kl: 0.0003, mse: 0.003217, wmse: 0.026756, mae: 0.042616, val nll: -1.3004, val mse 0.0044, lr 0.000081000\n",
      "test nll: -1.3874, test mse: 0.0036\n",
      "4251,4252,4253,4254,4255,4256,4257,4258,4259,4260,\tIter: 4260, train loss: -1.4280, avg nll: -1.4474, avg wnll: 30.0851, avg kl: 0.0006, mse: 0.003764, wmse: 0.031568, mae: 0.045477, val nll: -1.5101, val mse 0.0028, lr 0.000081000\n",
      "test nll: -1.4321, test mse: 0.0037\n",
      "4261,4262,4263,4264,4265,4266,4267,4268,4269,4270,\tIter: 4270, train loss: -1.4259, avg nll: -1.4443, avg wnll: 33.5278, avg kl: 0.0004, mse: 0.003602, wmse: 0.030427, mae: 0.045146, val nll: -1.3962, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.4149, test mse: 0.0035\n",
      "4271,4272,4273,4274,4275,4276,4277,4278,4279,4280,\tIter: 4280, train loss: -1.4544, avg nll: -1.4722, avg wnll: 33.0542, avg kl: 0.0002, mse: 0.003522, wmse: 0.029216, mae: 0.043538, val nll: -1.4426, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4533, test mse: 0.0037\n",
      "4281,4282,4283,4284,4285,4286,4287,4288,4289,4290,\tIter: 4290, train loss: -1.3335, avg nll: -1.3550, avg wnll: 41.2791, avg kl: 0.0003, mse: 0.004235, wmse: 0.035451, mae: 0.049044, val nll: -1.4140, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.3740, test mse: 0.0040\n",
      "4291,4292,4293,4294,4295,4296,4297,4298,4299,4300,\tIter: 4300, train loss: -1.4046, avg nll: -1.4239, avg wnll: 36.3156, avg kl: 0.0005, mse: 0.003767, wmse: 0.032024, mae: 0.046590, val nll: -1.4526, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4472, test mse: 0.0034\n",
      "4301,4302,4303,4304,4305,4306,4307,4308,4309,4310,\tIter: 4310, train loss: -1.4326, avg nll: -1.4522, avg wnll: 32.6793, avg kl: 0.0005, mse: 0.003818, wmse: 0.031865, mae: 0.044924, val nll: -1.4584, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.3680, test mse: 0.0043\n",
      "4311,4312,4313,4314,4315,4316,4317,4318,4319,4320,\tIter: 4320, train loss: -1.3270, avg nll: -1.3496, avg wnll: 35.9936, avg kl: 0.0008, mse: 0.004341, wmse: 0.036834, mae: 0.050262, val nll: -1.3529, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.2465, test mse: 0.0051\n",
      "4321,4322,4323,4324,4325,4326,4327,4328,4329,4330,\tIter: 4330, train loss: -1.4099, avg nll: -1.4302, avg wnll: 30.0554, avg kl: 0.0010, mse: 0.003878, wmse: 0.032301, mae: 0.045421, val nll: -1.4500, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.4388, test mse: 0.0038\n",
      "4331,4332,4333,4334,4335,4336,4337,4338,4339,4340,\tIter: 4340, train loss: -1.3774, avg nll: -1.3981, avg wnll: 30.0443, avg kl: 0.0010, mse: 0.003952, wmse: 0.032800, mae: 0.047261, val nll: -1.4759, val mse 0.0032, lr 0.000081000\n",
      "test nll: -1.3767, test mse: 0.0038\n",
      "4341,4342,4343,4344,4345,4346,4347,4348,4349,4350,\tIter: 4350, train loss: -1.4325, avg nll: -1.4507, avg wnll: 33.6423, avg kl: 0.0004, mse: 0.003573, wmse: 0.029771, mae: 0.043909, val nll: -1.3209, val mse 0.0042, lr 0.000081000\n",
      "test nll: -1.2366, test mse: 0.0052\n",
      "4351,4352,4353,4354,4355,4356,4357,4358,4359,4360,\tIter: 4360, train loss: -1.3243, avg nll: -1.3464, avg wnll: 40.7178, avg kl: 0.0006, mse: 0.004307, wmse: 0.035987, mae: 0.048925, val nll: -1.3645, val mse 0.0042, lr 0.000081000\n",
      "test nll: -1.3168, test mse: 0.0050\n",
      "4361,4362,4363,4364,4365,4366,4367,4368,4369,4370,\tIter: 4370, train loss: -1.3778, avg nll: -1.3984, avg wnll: 36.3974, avg kl: 0.0004, mse: 0.004041, wmse: 0.033636, mae: 0.047689, val nll: -1.3819, val mse 0.0044, lr 0.000081000\n",
      "test nll: -1.2326, test mse: 0.0051\n",
      "4371,4372,4373,4374,4375,4376,4377,4378,4379,4380,\tIter: 4380, train loss: -1.4383, avg nll: -1.4569, avg wnll: 32.5641, avg kl: 0.0006, mse: 0.003604, wmse: 0.030362, mae: 0.045827, val nll: -1.4397, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.4530, test mse: 0.0035\n",
      "4381,4382,4383,4384,4385,4386,4387,4388,4389,4390,\tIter: 4390, train loss: -1.4609, avg nll: -1.4782, avg wnll: 33.7652, avg kl: 0.0004, mse: 0.003390, wmse: 0.028326, mae: 0.043834, val nll: -1.4791, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.3336, test mse: 0.0045\n",
      "4391,4392,4393,4394,4395,4396,4397,4398,4399,4400,\tIter: 4400, train loss: -1.4437, avg nll: -1.4623, avg wnll: 34.7321, avg kl: 0.0003, mse: 0.003658, wmse: 0.031136, mae: 0.045197, val nll: -1.4661, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.3721, test mse: 0.0045\n",
      "saving.................\n",
      "done\n",
      "4401,4402,4403,4404,4405,4406,4407,4408,4409,4410,\tIter: 4410, train loss: -1.4478, avg nll: -1.4655, avg wnll: 33.8691, avg kl: 0.0003, mse: 0.003497, wmse: 0.029111, mae: 0.043529, val nll: -1.4406, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.3998, test mse: 0.0041\n",
      "4411,4412,4413,4414,4415,4416,4417,4418,4419,4420,\tIter: 4420, train loss: -1.4348, avg nll: -1.4533, avg wnll: 34.6378, avg kl: 0.0003, mse: 0.003635, wmse: 0.030979, mae: 0.045687, val nll: -1.4253, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.3915, test mse: 0.0041\n",
      "4421,4422,4423,4424,4425,4426,4427,4428,4429,4430,\tIter: 4430, train loss: -1.4171, avg nll: -1.4362, avg wnll: 33.3627, avg kl: 0.0004, mse: 0.003728, wmse: 0.031450, mae: 0.045802, val nll: -1.4866, val mse 0.0034, lr 0.000081000\n",
      "test nll: -1.2453, test mse: 0.0058\n",
      "4431,4432,4433,4434,4435,4436,4437,4438,4439,4440,\tIter: 4440, train loss: -1.3836, avg nll: -1.4033, avg wnll: 35.8292, avg kl: 0.0004, mse: 0.003874, wmse: 0.032742, mae: 0.047023, val nll: -1.5239, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.3586, test mse: 0.0040\n",
      "4441,4442,4443,4444,4445,4446,4447,4448,4449,4450,\tIter: 4450, train loss: -1.3456, avg nll: -1.3674, avg wnll: 39.0808, avg kl: 0.0004, mse: 0.004268, wmse: 0.035999, mae: 0.049977, val nll: -1.4158, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.3034, test mse: 0.0048\n",
      "4451,4452,4453,4454,4455,4456,4457,4458,4459,4460,\tIter: 4460, train loss: -1.2260, avg nll: -1.2524, avg wnll: 40.0031, avg kl: 0.0010, mse: 0.005074, wmse: 0.043127, mae: 0.053934, val nll: -1.3902, val mse 0.0041, lr 0.000081000\n",
      "test nll: -1.4190, test mse: 0.0038\n",
      "4461,4462,4463,4464,4465,4466,4467,4468,4469,4470,\tIter: 4470, train loss: -1.4125, avg nll: -1.4314, avg wnll: 30.6058, avg kl: 0.0012, mse: 0.003533, wmse: 0.029312, mae: 0.044535, val nll: -1.4685, val mse 0.0031, lr 0.000081000\n",
      "test nll: -1.4801, test mse: 0.0034\n",
      "4471,4472,4473,4474,4475,4476,4477,4478,4479,4480,\tIter: 4480, train loss: -1.4114, avg nll: -1.4308, avg wnll: 35.9531, avg kl: 0.0004, mse: 0.003797, wmse: 0.032322, mae: 0.046731, val nll: -1.3480, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.3847, test mse: 0.0044\n",
      "4481,4482,4483,4484,4485,4486,4487,4488,4489,4490,\tIter: 4490, train loss: -1.3654, avg nll: -1.3871, avg wnll: 30.6304, avg kl: 0.0008, mse: 0.004169, wmse: 0.034612, mae: 0.047074, val nll: -1.3750, val mse 0.0043, lr 0.000081000\n",
      "test nll: -1.3942, test mse: 0.0037\n",
      "4491,4492,4493,4494,4495,4496,4497,4498,4499,4500,\tIter: 4500, train loss: -1.3483, avg nll: -1.3693, avg wnll: 37.3316, avg kl: 0.0005, mse: 0.004098, wmse: 0.034095, mae: 0.048004, val nll: -1.4160, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.3351, test mse: 0.0044\n",
      "4501,4502,4503,4504,4505,4506,4507,4508,4509,4510,\tIter: 4510, train loss: -1.4187, avg nll: -1.4378, avg wnll: 35.7682, avg kl: 0.0004, mse: 0.003731, wmse: 0.031940, mae: 0.045614, val nll: -1.3321, val mse 0.0046, lr 0.000081000\n",
      "test nll: -1.4061, test mse: 0.0039\n",
      "4511,4512,4513,4514,4515,4516,4517,4518,4519,4520,\tIter: 4520, train loss: -1.3804, avg nll: -1.4018, avg wnll: 33.8140, avg kl: 0.0005, mse: 0.004179, wmse: 0.035120, mae: 0.047629, val nll: -1.4192, val mse 0.0041, lr 0.000081000\n",
      "test nll: -1.4126, test mse: 0.0037\n",
      "4521,4522,4523,4524,4525,4526,4527,4528,4529,4530,\tIter: 4530, train loss: -1.3895, avg nll: -1.4087, avg wnll: 37.8735, avg kl: 0.0003, mse: 0.003776, wmse: 0.031547, mae: 0.045722, val nll: -1.3714, val mse 0.0044, lr 0.000081000\n",
      "test nll: -1.4004, test mse: 0.0041\n",
      "4531,4532,4533,4534,4535,4536,4537,4538,4539,4540,\tIter: 4540, train loss: -1.4664, avg nll: -1.4836, avg wnll: 31.2396, avg kl: 0.0005, mse: 0.003339, wmse: 0.028129, mae: 0.043065, val nll: -1.5162, val mse 0.0030, lr 0.000081000\n",
      "test nll: -1.3003, test mse: 0.0049\n",
      "4541,4542,4543,4544,4545,4546,4547,4548,4549,4550,\tIter: 4550, train loss: -1.4135, avg nll: -1.4333, avg wnll: 31.8857, avg kl: 0.0004, mse: 0.003870, wmse: 0.032754, mae: 0.046052, val nll: -1.2776, val mse 0.0050, lr 0.000081000\n",
      "test nll: -1.2988, test mse: 0.0045\n",
      "4551,4552,4553,4554,4555,4556,4557,4558,4559,4560,\tIter: 4560, train loss: -1.4355, avg nll: -1.4540, avg wnll: 34.8648, avg kl: 0.0002, mse: 0.003647, wmse: 0.030653, mae: 0.045221, val nll: -1.4597, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.3521, test mse: 0.0047\n",
      "4561,4562,4563,4564,4565,4566,4567,4568,4569,4570,\tIter: 4570, train loss: -1.4377, avg nll: -1.4562, avg wnll: 33.5835, avg kl: 0.0003, mse: 0.003652, wmse: 0.030856, mae: 0.044566, val nll: -1.5247, val mse 0.0032, lr 0.000081000\n",
      "test nll: -1.4664, test mse: 0.0035\n",
      "4571,4572,4573,4574,4575,4576,4577,4578,4579,4580,\tIter: 4580, train loss: -1.4229, avg nll: -1.4421, avg wnll: 34.7740, avg kl: 0.0003, mse: 0.003775, wmse: 0.031741, mae: 0.045403, val nll: -1.4718, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.4763, test mse: 0.0032\n",
      "4581,4582,4583,4584,4585,4586,4587,4588,4589,4590,\tIter: 4590, train loss: -1.3823, avg nll: -1.4032, avg wnll: 35.9181, avg kl: 0.0005, mse: 0.004084, wmse: 0.034166, mae: 0.047469, val nll: -1.4487, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4050, test mse: 0.0041\n",
      "4591,4592,4593,4594,4595,4596,4597,4598,4599,4600,\tIter: 4600, train loss: -1.3988, avg nll: -1.4178, avg wnll: 37.0420, avg kl: 0.0002, mse: 0.003745, wmse: 0.031535, mae: 0.046374, val nll: -1.4470, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4272, test mse: 0.0035\n",
      "saving.................\n",
      "done\n",
      "4601,4602,4603,4604,4605,4606,4607,4608,4609,4610,\tIter: 4610, train loss: -1.4285, avg nll: -1.4472, avg wnll: 35.3753, avg kl: 0.0003, mse: 0.003670, wmse: 0.030720, mae: 0.044580, val nll: -1.4095, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.4299, test mse: 0.0036\n",
      "4611,4612,4613,4614,4615,4616,4617,4618,4619,4620,\tIter: 4620, train loss: -1.4009, avg nll: -1.4202, avg wnll: 33.2680, avg kl: 0.0005, mse: 0.003761, wmse: 0.031587, mae: 0.046850, val nll: -1.4073, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.3394, test mse: 0.0046\n",
      "4621,4622,4623,4624,4625,4626,4627,4628,4629,4630,\tIter: 4630, train loss: -1.4561, avg nll: -1.4740, avg wnll: 32.0518, avg kl: 0.0003, mse: 0.003519, wmse: 0.029442, mae: 0.044450, val nll: -1.4667, val mse 0.0034, lr 0.000081000\n",
      "test nll: -1.3558, test mse: 0.0044\n",
      "4631,4632,4633,4634,4635,4636,4637,4638,4639,4640,\tIter: 4640, train loss: -1.3844, avg nll: -1.4052, avg wnll: 38.3922, avg kl: 0.0004, mse: 0.004089, wmse: 0.033937, mae: 0.047777, val nll: -1.4643, val mse 0.0038, lr 0.000081000\n",
      "test nll: -1.3835, test mse: 0.0045\n",
      "4641,4642,4643,4644,4645,4646,4647,4648,4649,4650,\tIter: 4650, train loss: -1.3558, avg nll: -1.3778, avg wnll: 40.1547, avg kl: 0.0004, mse: 0.004309, wmse: 0.036541, mae: 0.049134, val nll: -1.4907, val mse 0.0032, lr 0.000081000\n",
      "test nll: -1.4074, test mse: 0.0041\n",
      "4651,4652,4653,4654,4655,4656,4657,4658,4659,4660,\tIter: 4660, train loss: -1.3546, avg nll: -1.3758, avg wnll: 35.9246, avg kl: 0.0007, mse: 0.004092, wmse: 0.034004, mae: 0.048982, val nll: -1.3853, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.4531, test mse: 0.0037\n",
      "4661,4662,4663,4664,4665,4666,4667,4668,4669,4670,\tIter: 4670, train loss: -1.4179, avg nll: -1.4366, avg wnll: 34.3314, avg kl: 0.0008, mse: 0.003582, wmse: 0.030129, mae: 0.045291, val nll: -1.3894, val mse 0.0042, lr 0.000081000\n",
      "test nll: -1.2638, test mse: 0.0049\n",
      "4671,4672,4673,4674,4675,4676,4677,4678,4679,4680,\tIter: 4680, train loss: -1.3351, avg nll: -1.3582, avg wnll: 37.2410, avg kl: 0.0006, mse: 0.004490, wmse: 0.037707, mae: 0.050349, val nll: -1.4130, val mse 0.0042, lr 0.000081000\n",
      "test nll: -1.3817, test mse: 0.0039\n",
      "4681,4682,4683,4684,4685,4686,4687,4688,4689,4690,\tIter: 4690, train loss: -1.4078, avg nll: -1.4274, avg wnll: 33.7741, avg kl: 0.0005, mse: 0.003823, wmse: 0.032203, mae: 0.045382, val nll: -1.4560, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4071, test mse: 0.0039\n",
      "4691,4692,4693,4694,4695,4696,4697,4698,4699,4700,\tIter: 4700, train loss: -1.3317, avg nll: -1.3536, avg wnll: 37.7946, avg kl: 0.0007, mse: 0.004234, wmse: 0.035368, mae: 0.048970, val nll: -1.2897, val mse 0.0046, lr 0.000081000\n",
      "test nll: -1.1781, test mse: 0.0057\n",
      "4701,4702,4703,4704,4705,4706,4707,4708,4709,4710,\tIter: 4710, train loss: -1.3137, avg nll: -1.3349, avg wnll: 42.2593, avg kl: 0.0006, mse: 0.004129, wmse: 0.035056, mae: 0.048628, val nll: -1.4143, val mse 0.0040, lr 0.000081000\n",
      "test nll: -1.3472, test mse: 0.0049\n",
      "4711,4712,4713,4714,4715,4716,4717,4718,4719,4720,\tIter: 4720, train loss: -1.3621, avg nll: -1.3833, avg wnll: 38.6255, avg kl: 0.0006, mse: 0.004112, wmse: 0.034932, mae: 0.047593, val nll: -1.4063, val mse 0.0035, lr 0.000081000\n",
      "test nll: -1.3997, test mse: 0.0040\n",
      "4721,4722,4723,4724,4725,4726,4727,4728,4729,4730,\tIter: 4730, train loss: -1.4164, avg nll: -1.4351, avg wnll: 33.4166, avg kl: 0.0005, mse: 0.003633, wmse: 0.031202, mae: 0.046527, val nll: -1.4508, val mse 0.0037, lr 0.000081000\n",
      "test nll: -1.4889, test mse: 0.0033\n",
      "4731,4732,4733,4734,4735,4736,4737,4738,4739,4740,\tIter: 4740, train loss: -1.4365, avg nll: -1.4551, avg wnll: 31.3870, avg kl: 0.0004, mse: 0.003648, wmse: 0.030242, mae: 0.044636, val nll: -1.4909, val mse 0.0034, lr 0.000081000\n",
      "test nll: -1.4227, test mse: 0.0040\n",
      "4741,4742,4743,4744,4745,4746,4747,4748,4749,4750,\tIter: 4750, train loss: -1.4028, avg nll: -1.4218, avg wnll: 34.0906, avg kl: 0.0005, mse: 0.003699, wmse: 0.031215, mae: 0.045600, val nll: -1.3763, val mse 0.0041, lr 0.000081000\n",
      "test nll: -1.3165, test mse: 0.0049\n",
      "4751,4752,4753,4754,4755,4756,4757,4758,4759,4760,\tIter: 4760, train loss: -1.3987, avg nll: -1.4182, avg wnll: 34.7889, avg kl: 0.0003, mse: 0.003841, wmse: 0.032618, mae: 0.047061, val nll: -1.4779, val mse 0.0034, lr 0.000081000\n",
      "test nll: -1.4624, test mse: 0.0036\n",
      "4761,4762,4763,4764,4765,4766,4767,4768,4769,4770,\tIter: 4770, train loss: -1.4254, avg nll: -1.4437, avg wnll: 36.1778, avg kl: 0.0003, mse: 0.003612, wmse: 0.030104, mae: 0.044857, val nll: -1.4790, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4259, test mse: 0.0037\n",
      "4771,4772,4773,4774,4775,4776,4777,4778,4779,4780,\tIter: 4780, train loss: -1.4227, avg nll: -1.4419, avg wnll: 35.8402, avg kl: 0.0003, mse: 0.003778, wmse: 0.031756, mae: 0.045739, val nll: -1.3116, val mse 0.0045, lr 0.000081000\n",
      "test nll: -1.3237, test mse: 0.0041\n",
      "4781,4782,4783,4784,4785,4786,4787,4788,4789,4790,\tIter: 4790, train loss: -1.4257, avg nll: -1.4443, avg wnll: 34.0002, avg kl: 0.0004, mse: 0.003620, wmse: 0.030577, mae: 0.045678, val nll: -1.4481, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.4488, test mse: 0.0037\n",
      "4791,4792,4793,4794,4795,4796,4797,4798,4799,4800,\tIter: 4800, train loss: -1.3681, avg nll: -1.3899, avg wnll: 31.6019, avg kl: 0.0007, mse: 0.004214, wmse: 0.035008, mae: 0.047773, val nll: -1.5119, val mse 0.0029, lr 0.000081000\n",
      "test nll: -1.3958, test mse: 0.0041\n",
      "saving.................\n",
      "done\n",
      "4801,4802,4803,4804,4805,4806,4807,4808,4809,4810,\tIter: 4810, train loss: -1.4307, avg nll: -1.4490, avg wnll: 29.6300, avg kl: 0.0005, mse: 0.003555, wmse: 0.030030, mae: 0.045001, val nll: -1.3956, val mse 0.0042, lr 0.000081000\n",
      "test nll: -1.4199, test mse: 0.0040\n",
      "4811,4812,4813,4814,4815,4816,4817,4818,4819,4820,\tIter: 4820, train loss: -1.4811, avg nll: -1.4985, avg wnll: 30.8214, avg kl: 0.0003, mse: 0.003432, wmse: 0.028464, mae: 0.043503, val nll: -1.4536, val mse 0.0033, lr 0.000081000\n",
      "test nll: -1.3841, test mse: 0.0039\n",
      "4821,4822,4823,4824,4825,4826,4827,4828,4829,4830,\tIter: 4830, train loss: -1.3844, avg nll: -1.4050, avg wnll: 37.0966, avg kl: 0.0003, mse: 0.004062, wmse: 0.033951, mae: 0.047175, val nll: -1.5144, val mse 0.0031, lr 0.000081000\n",
      "test nll: -1.4054, test mse: 0.0041\n",
      "4831,4832,4833,4834,4835,4836,4837,4838,4839,4840,\tIter: 4840, train loss: -1.4784, avg nll: -1.4965, avg wnll: 32.6533, avg kl: 0.0002, mse: 0.003575, wmse: 0.030221, mae: 0.043635, val nll: -1.4759, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4487, test mse: 0.0040\n",
      "4841,4842,4843,4844,4845,4846,4847,4848,4849,4850,\tIter: 4850, train loss: -1.4073, avg nll: -1.4261, avg wnll: 35.8188, avg kl: 0.0002, mse: 0.003704, wmse: 0.031653, mae: 0.045768, val nll: -1.4798, val mse 0.0034, lr 0.000081000\n",
      "test nll: -1.5141, test mse: 0.0031\n",
      "4851,4852,4853,4854,4855,4856,4857,4858,4859,4860,\tIter: 4860, train loss: -1.3734, avg nll: -1.3936, avg wnll: 38.5990, avg kl: 0.0002, mse: 0.003989, wmse: 0.033636, mae: 0.047648, val nll: -1.4269, val mse 0.0036, lr 0.000081000\n",
      "test nll: -1.4148, test mse: 0.0040\n",
      "4861,4862,4863,4864,4865,4866,4867,4868,4869,4870,\tIter: 4870, train loss: -1.4206, avg nll: -1.4393, avg wnll: 37.1749, avg kl: 0.0003, mse: 0.003687, wmse: 0.030902, mae: 0.044956, val nll: -1.4026, val mse 0.0039, lr 0.000081000\n",
      "test nll: -1.3574, test mse: 0.0044\n",
      "4871,4872,4873,4874,4875,4876,4877,4878,4879,4880,\tIter: 4880, train loss: -1.4374, avg nll: -1.4568, avg wnll: 34.2717, avg kl: 0.0003, mse: 0.003836, wmse: 0.032417, mae: 0.045237, val nll: -1.5058, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.4872, test mse: 0.0033\n",
      "4881,4882,4883,4884,4885,4886,4887,4888,4889,4890,\tIter: 4890, train loss: -1.4036, avg nll: -1.4230, avg wnll: 35.6132, avg kl: 0.0003, mse: 0.003836, wmse: 0.032079, mae: 0.045796, val nll: -1.4905, val mse 0.0033, lr 0.000072900\n",
      "test nll: -1.4730, test mse: 0.0031\n",
      "4891,4892,4893,4894,4895,4896,4897,4898,4899,4900,\tIter: 4900, train loss: -1.4268, avg nll: -1.4456, avg wnll: 34.4594, avg kl: 0.0004, mse: 0.003673, wmse: 0.030798, mae: 0.044982, val nll: -1.5137, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.4546, test mse: 0.0033\n",
      "4901,4902,4903,4904,4905,4906,4907,4908,4909,4910,\tIter: 4910, train loss: -1.4534, avg nll: -1.4709, avg wnll: 34.2306, avg kl: 0.0003, mse: 0.003428, wmse: 0.028797, mae: 0.043745, val nll: -1.4669, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.3666, test mse: 0.0045\n",
      "4911,4912,4913,4914,4915,4916,4917,4918,4919,4920,\tIter: 4920, train loss: -1.4230, avg nll: -1.4425, avg wnll: 35.1587, avg kl: 0.0002, mse: 0.003838, wmse: 0.032008, mae: 0.045000, val nll: -1.4235, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4861, test mse: 0.0032\n",
      "4921,4922,4923,4924,4925,4926,4927,4928,4929,4930,\tIter: 4930, train loss: -1.4186, avg nll: -1.4379, avg wnll: 35.6764, avg kl: 0.0003, mse: 0.003793, wmse: 0.032242, mae: 0.045646, val nll: -1.3914, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4531, test mse: 0.0038\n",
      "4931,4932,4933,4934,4935,4936,4937,4938,4939,4940,\tIter: 4940, train loss: -1.3689, avg nll: -1.3893, avg wnll: 39.3421, avg kl: 0.0003, mse: 0.004016, wmse: 0.034071, mae: 0.047161, val nll: -1.3468, val mse 0.0044, lr 0.000072900\n",
      "test nll: -1.3349, test mse: 0.0045\n",
      "4941,4942,4943,4944,4945,4946,4947,4948,4949,4950,\tIter: 4950, train loss: -1.4357, avg nll: -1.4546, avg wnll: 32.8548, avg kl: 0.0004, mse: 0.003712, wmse: 0.031342, mae: 0.045035, val nll: -1.3913, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.4473, test mse: 0.0037\n",
      "4951,4952,4953,4954,4955,4956,4957,4958,4959,4960,\tIter: 4960, train loss: -1.3774, avg nll: -1.3977, avg wnll: 34.1004, avg kl: 0.0004, mse: 0.003991, wmse: 0.033661, mae: 0.047936, val nll: -1.4959, val mse 0.0031, lr 0.000072900\n",
      "test nll: -1.4847, test mse: 0.0035\n",
      "4961,4962,4963,4964,4965,4966,4967,4968,4969,4970,\tIter: 4970, train loss: -1.3259, avg nll: -1.3484, avg wnll: 41.3624, avg kl: 0.0004, mse: 0.004430, wmse: 0.037421, mae: 0.050001, val nll: -1.3741, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.3405, test mse: 0.0043\n",
      "4971,4972,4973,4974,4975,4976,4977,4978,4979,4980,\tIter: 4980, train loss: -1.4296, avg nll: -1.4488, avg wnll: 32.8375, avg kl: 0.0007, mse: 0.003712, wmse: 0.031261, mae: 0.045336, val nll: -1.4531, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.4273, test mse: 0.0038\n",
      "4981,4982,4983,4984,4985,4986,4987,4988,4989,4990,\tIter: 4990, train loss: -1.3329, avg nll: -1.3547, avg wnll: 39.5547, avg kl: 0.0007, mse: 0.004212, wmse: 0.035502, mae: 0.049387, val nll: -1.4920, val mse 0.0031, lr 0.000072900\n",
      "test nll: -1.4493, test mse: 0.0036\n",
      "4991,4992,4993,4994,4995,4996,4997,4998,4999,5000,\tIter: 5000, train loss: -1.4475, avg nll: -1.4657, avg wnll: 34.1031, avg kl: 0.0003, mse: 0.003573, wmse: 0.029742, mae: 0.043985, val nll: -1.5004, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.4643, test mse: 0.0036\n",
      "saving.................\n",
      "done\n",
      "5001,5002,5003,5004,5005,5006,5007,5008,5009,5010,\tIter: 5010, train loss: -1.3796, avg nll: -1.4002, avg wnll: 37.8784, avg kl: 0.0005, mse: 0.004027, wmse: 0.033863, mae: 0.047282, val nll: -1.3949, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.4693, test mse: 0.0033\n",
      "5011,5012,5013,5014,5015,5016,5017,5018,5019,5020,\tIter: 5020, train loss: -1.4450, avg nll: -1.4628, avg wnll: 34.3104, avg kl: 0.0003, mse: 0.003501, wmse: 0.029086, mae: 0.044009, val nll: -1.4712, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.3351, test mse: 0.0046\n",
      "5021,5022,5023,5024,5025,5026,5027,5028,5029,5030,\tIter: 5030, train loss: -1.4260, avg nll: -1.4457, avg wnll: 31.6518, avg kl: 0.0006, mse: 0.003841, wmse: 0.032627, mae: 0.046145, val nll: -1.4134, val mse 0.0040, lr 0.000072900\n",
      "test nll: -1.4416, test mse: 0.0038\n",
      "5031,5032,5033,5034,5035,5036,5037,5038,5039,5040,\tIter: 5040, train loss: -1.4472, avg nll: -1.4648, avg wnll: 30.0748, avg kl: 0.0005, mse: 0.003419, wmse: 0.028906, mae: 0.044582, val nll: -1.3458, val mse 0.0046, lr 0.000072900\n",
      "test nll: -1.4042, test mse: 0.0041\n",
      "5041,5042,5043,5044,5045,5046,5047,5048,5049,5050,\tIter: 5050, train loss: -1.4201, avg nll: -1.4399, avg wnll: 34.5710, avg kl: 0.0006, mse: 0.003841, wmse: 0.032507, mae: 0.046104, val nll: -1.4767, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.4651, test mse: 0.0033\n",
      "5051,5052,5053,5054,5055,5056,5057,5058,5059,5060,\tIter: 5060, train loss: -1.3596, avg nll: -1.3804, avg wnll: 33.2315, avg kl: 0.0009, mse: 0.003971, wmse: 0.033073, mae: 0.048105, val nll: -1.4934, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.3335, test mse: 0.0049\n",
      "5061,5062,5063,5064,5065,5066,5067,5068,5069,5070,\tIter: 5070, train loss: -1.2864, avg nll: -1.3097, avg wnll: 39.2691, avg kl: 0.0009, mse: 0.004470, wmse: 0.037174, mae: 0.051335, val nll: -1.3062, val mse 0.0047, lr 0.000072900\n",
      "test nll: -1.3550, test mse: 0.0044\n",
      "5071,5072,5073,5074,5075,5076,5077,5078,5079,5080,\tIter: 5080, train loss: -1.4395, avg nll: -1.4590, avg wnll: 33.5583, avg kl: 0.0005, mse: 0.003797, wmse: 0.031695, mae: 0.045456, val nll: -1.2770, val mse 0.0049, lr 0.000072900\n",
      "test nll: -1.4356, test mse: 0.0041\n",
      "5081,5082,5083,5084,5085,5086,5087,5088,5089,5090,\tIter: 5090, train loss: -1.4212, avg nll: -1.4406, avg wnll: 35.9611, avg kl: 0.0004, mse: 0.003803, wmse: 0.031937, mae: 0.045399, val nll: -1.3677, val mse 0.0044, lr 0.000072900\n",
      "test nll: -1.2752, test mse: 0.0052\n",
      "5091,5092,5093,5094,5095,5096,5097,5098,5099,5100,\tIter: 5100, train loss: -1.3627, avg nll: -1.3836, avg wnll: 37.2952, avg kl: 0.0007, mse: 0.004053, wmse: 0.034134, mae: 0.048384, val nll: -1.4931, val mse 0.0033, lr 0.000072900\n",
      "test nll: -1.4105, test mse: 0.0041\n",
      "5101,5102,5103,5104,5105,5106,5107,5108,5109,5110,\tIter: 5110, train loss: -1.4784, avg nll: -1.4960, avg wnll: 31.1566, avg kl: 0.0003, mse: 0.003464, wmse: 0.029021, mae: 0.044148, val nll: -1.4432, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4528, test mse: 0.0035\n",
      "5111,5112,5113,5114,5115,5116,5117,5118,5119,5120,\tIter: 5120, train loss: -1.4520, avg nll: -1.4692, avg wnll: 33.1349, avg kl: 0.0003, mse: 0.003363, wmse: 0.027917, mae: 0.043400, val nll: -1.4537, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4407, test mse: 0.0037\n",
      "5121,5122,5123,5124,5125,5126,5127,5128,5129,5130,\tIter: 5130, train loss: -1.4303, avg nll: -1.4490, avg wnll: 33.7544, avg kl: 0.0003, mse: 0.003689, wmse: 0.031181, mae: 0.045026, val nll: -1.5396, val mse 0.0030, lr 0.000072900\n",
      "test nll: -1.4306, test mse: 0.0041\n",
      "5131,5132,5133,5134,5135,5136,5137,5138,5139,5140,\tIter: 5140, train loss: -1.4193, avg nll: -1.4386, avg wnll: 36.2917, avg kl: 0.0002, mse: 0.003832, wmse: 0.032109, mae: 0.045832, val nll: -1.2790, val mse 0.0050, lr 0.000072900\n",
      "test nll: -1.4761, test mse: 0.0031\n",
      "5141,5142,5143,5144,5145,5146,5147,5148,5149,5150,\tIter: 5150, train loss: -1.4247, avg nll: -1.4438, avg wnll: 31.8597, avg kl: 0.0004, mse: 0.003741, wmse: 0.031121, mae: 0.045717, val nll: -1.5198, val mse 0.0030, lr 0.000072900\n",
      "test nll: -1.4118, test mse: 0.0039\n",
      "5151,5152,5153,5154,5155,5156,5157,5158,5159,5160,\tIter: 5160, train loss: -1.3565, avg nll: -1.3772, avg wnll: 32.4921, avg kl: 0.0012, mse: 0.003922, wmse: 0.032761, mae: 0.047927, val nll: -1.2407, val mse 0.0053, lr 0.000072900\n",
      "test nll: -1.3711, test mse: 0.0041\n",
      "5161,5162,5163,5164,5165,5166,5167,5168,5169,5170,\tIter: 5170, train loss: -1.3200, avg nll: -1.3426, avg wnll: 40.6734, avg kl: 0.0012, mse: 0.004292, wmse: 0.035807, mae: 0.049751, val nll: -1.3256, val mse 0.0045, lr 0.000072900\n",
      "test nll: -1.3854, test mse: 0.0041\n",
      "5171,5172,5173,5174,5175,5176,5177,5178,5179,5180,\tIter: 5180, train loss: -1.4253, avg nll: -1.4441, avg wnll: 32.8151, avg kl: 0.0005, mse: 0.003643, wmse: 0.030845, mae: 0.046903, val nll: -1.4790, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.4281, test mse: 0.0038\n",
      "5181,5182,5183,5184,5185,5186,5187,5188,5189,5190,\tIter: 5190, train loss: -1.4057, avg nll: -1.4257, avg wnll: 38.0549, avg kl: 0.0003, mse: 0.003942, wmse: 0.033030, mae: 0.045751, val nll: -1.4929, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.4364, test mse: 0.0041\n",
      "5191,5192,5193,5194,5195,5196,5197,5198,5199,5200,\tIter: 5200, train loss: -1.4865, avg nll: -1.5038, avg wnll: 31.6986, avg kl: 0.0002, mse: 0.003401, wmse: 0.028681, mae: 0.043774, val nll: -1.4619, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.4530, test mse: 0.0036\n",
      "saving.................\n",
      "done\n",
      "5201,5202,5203,5204,5205,5206,5207,5208,5209,5210,\tIter: 5210, train loss: -1.4635, avg nll: -1.4809, avg wnll: 34.1367, avg kl: 0.0002, mse: 0.003451, wmse: 0.028934, mae: 0.043544, val nll: -1.4201, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4053, test mse: 0.0040\n",
      "5211,5212,5213,5214,5215,5216,5217,5218,5219,5220,\tIter: 5220, train loss: -1.3950, avg nll: -1.4148, avg wnll: 36.7549, avg kl: 0.0004, mse: 0.003876, wmse: 0.033102, mae: 0.047299, val nll: -1.4872, val mse 0.0030, lr 0.000072900\n",
      "test nll: -1.4258, test mse: 0.0038\n",
      "5221,5222,5223,5224,5225,5226,5227,5228,5229,5230,\tIter: 5230, train loss: -1.4563, avg nll: -1.4745, avg wnll: 32.0916, avg kl: 0.0005, mse: 0.003564, wmse: 0.029881, mae: 0.043971, val nll: -1.4196, val mse 0.0040, lr 0.000072900\n",
      "test nll: -1.4243, test mse: 0.0038\n",
      "5231,5232,5233,5234,5235,5236,5237,5238,5239,5240,\tIter: 5240, train loss: -1.3939, avg nll: -1.4142, avg wnll: 38.5687, avg kl: 0.0004, mse: 0.003988, wmse: 0.033591, mae: 0.046787, val nll: -1.4812, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.3813, test mse: 0.0046\n",
      "5241,5242,5243,5244,5245,5246,5247,5248,5249,5250,\tIter: 5250, train loss: -1.3979, avg nll: -1.4179, avg wnll: 36.6255, avg kl: 0.0003, mse: 0.003946, wmse: 0.033206, mae: 0.046662, val nll: -1.3899, val mse 0.0040, lr 0.000072900\n",
      "test nll: -1.3738, test mse: 0.0045\n",
      "5251,5252,5253,5254,5255,5256,5257,5258,5259,5260,\tIter: 5260, train loss: -1.4584, avg nll: -1.4763, avg wnll: 30.5040, avg kl: 0.0003, mse: 0.003529, wmse: 0.029593, mae: 0.044202, val nll: -1.2848, val mse 0.0047, lr 0.000072900\n",
      "test nll: -1.2688, test mse: 0.0049\n",
      "5261,5262,5263,5264,5265,5266,5267,5268,5269,5270,\tIter: 5270, train loss: -1.4652, avg nll: -1.4837, avg wnll: 31.9728, avg kl: 0.0006, mse: 0.003589, wmse: 0.029923, mae: 0.043648, val nll: -1.4968, val mse 0.0031, lr 0.000072900\n",
      "test nll: -1.3934, test mse: 0.0039\n",
      "5271,5272,5273,5274,5275,5276,5277,5278,5279,5280,\tIter: 5280, train loss: -1.4346, avg nll: -1.4535, avg wnll: 35.2904, avg kl: 0.0003, mse: 0.003709, wmse: 0.031580, mae: 0.045264, val nll: -1.3877, val mse 0.0039, lr 0.000072900\n",
      "test nll: -1.4734, test mse: 0.0036\n",
      "5281,5282,5283,5284,5285,5286,5287,5288,5289,5290,\tIter: 5290, train loss: -1.4535, avg nll: -1.4718, avg wnll: 31.9288, avg kl: 0.0004, mse: 0.003571, wmse: 0.030094, mae: 0.043864, val nll: -1.3610, val mse 0.0039, lr 0.000072900\n",
      "test nll: -1.4013, test mse: 0.0038\n",
      "5291,5292,5293,5294,5295,5296,5297,5298,5299,5300,\tIter: 5300, train loss: -1.4142, avg nll: -1.4342, avg wnll: 37.0248, avg kl: 0.0002, mse: 0.003938, wmse: 0.033341, mae: 0.046640, val nll: -1.4592, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.3998, test mse: 0.0043\n",
      "5301,5302,5303,5304,5305,5306,5307,5308,5309,5310,\tIter: 5310, train loss: -1.4108, avg nll: -1.4301, avg wnll: 35.4221, avg kl: 0.0002, mse: 0.003808, wmse: 0.031849, mae: 0.045643, val nll: -1.4332, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4512, test mse: 0.0038\n",
      "5311,5312,5313,5314,5315,5316,5317,5318,5319,5320,\tIter: 5320, train loss: -1.3639, avg nll: -1.3844, avg wnll: 38.4273, avg kl: 0.0007, mse: 0.003958, wmse: 0.032554, mae: 0.046586, val nll: -1.3466, val mse 0.0039, lr 0.000072900\n",
      "test nll: -1.3822, test mse: 0.0042\n",
      "5321,5322,5323,5324,5325,5326,5327,5328,5329,5330,\tIter: 5330, train loss: -1.4235, avg nll: -1.4420, avg wnll: 32.6208, avg kl: 0.0002, mse: 0.003668, wmse: 0.031051, mae: 0.045826, val nll: -1.3873, val mse 0.0039, lr 0.000072900\n",
      "test nll: -1.4264, test mse: 0.0040\n",
      "5331,5332,5333,5334,5335,5336,5337,5338,5339,5340,\tIter: 5340, train loss: -1.3870, avg nll: -1.4074, avg wnll: 38.8190, avg kl: 0.0004, mse: 0.003994, wmse: 0.034128, mae: 0.046995, val nll: -1.4223, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4212, test mse: 0.0039\n",
      "5341,5342,5343,5344,5345,5346,5347,5348,5349,5350,\tIter: 5350, train loss: -1.4078, avg nll: -1.4276, avg wnll: 36.2972, avg kl: 0.0002, mse: 0.003902, wmse: 0.032928, mae: 0.046679, val nll: -1.4946, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.4252, test mse: 0.0039\n",
      "5351,5352,5353,5354,5355,5356,5357,5358,5359,5360,\tIter: 5360, train loss: -1.5138, avg nll: -1.5302, avg wnll: 31.2451, avg kl: 0.0002, mse: 0.003224, wmse: 0.027044, mae: 0.041295, val nll: -1.4912, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4387, test mse: 0.0036\n",
      "5361,5362,5363,5364,5365,5366,5367,5368,5369,5370,\tIter: 5370, train loss: -1.4445, avg nll: -1.4633, avg wnll: 31.2202, avg kl: 0.0004, mse: 0.003682, wmse: 0.030769, mae: 0.044872, val nll: -1.5110, val mse 0.0031, lr 0.000072900\n",
      "test nll: -1.4241, test mse: 0.0035\n",
      "5371,5372,5373,5374,5375,5376,5377,5378,5379,5380,\tIter: 5380, train loss: -1.4663, avg nll: -1.4836, avg wnll: 34.2545, avg kl: 0.0002, mse: 0.003420, wmse: 0.028552, mae: 0.043524, val nll: -1.3986, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.3953, test mse: 0.0045\n",
      "5381,5382,5383,5384,5385,5386,5387,5388,5389,5390,\tIter: 5390, train loss: -1.4592, avg nll: -1.4781, avg wnll: 32.6915, avg kl: 0.0007, mse: 0.003651, wmse: 0.030525, mae: 0.043949, val nll: -1.4076, val mse 0.0038, lr 0.000072900\n",
      "test nll: -1.4090, test mse: 0.0039\n",
      "5391,5392,5393,5394,5395,5396,5397,5398,5399,5400,\tIter: 5400, train loss: -1.3963, avg nll: -1.4162, avg wnll: 30.9763, avg kl: 0.0005, mse: 0.003873, wmse: 0.032554, mae: 0.045805, val nll: -1.3701, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.4142, test mse: 0.0035\n",
      "saving.................\n",
      "done\n",
      "5401,5402,5403,5404,5405,5406,5407,5408,5409,5410,\tIter: 5410, train loss: -1.3952, avg nll: -1.4150, avg wnll: 37.8311, avg kl: 0.0004, mse: 0.003892, wmse: 0.033176, mae: 0.047485, val nll: -1.3555, val mse 0.0043, lr 0.000072900\n",
      "test nll: -1.3980, test mse: 0.0042\n",
      "5411,5412,5413,5414,5415,5416,5417,5418,5419,5420,\tIter: 5420, train loss: -1.4520, avg nll: -1.4699, avg wnll: 34.9595, avg kl: 0.0003, mse: 0.003534, wmse: 0.029705, mae: 0.044038, val nll: -1.3858, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.4768, test mse: 0.0034\n",
      "5421,5422,5423,5424,5425,5426,5427,5428,5429,5430,\tIter: 5430, train loss: -1.4096, avg nll: -1.4277, avg wnll: 37.1702, avg kl: 0.0004, mse: 0.003529, wmse: 0.029819, mae: 0.044592, val nll: -1.4146, val mse 0.0041, lr 0.000072900\n",
      "test nll: -1.4546, test mse: 0.0035\n",
      "5431,5432,5433,5434,5435,5436,5437,5438,5439,5440,\tIter: 5440, train loss: -1.4218, avg nll: -1.4408, avg wnll: 35.9673, avg kl: 0.0003, mse: 0.003729, wmse: 0.031405, mae: 0.045446, val nll: -1.4273, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4430, test mse: 0.0039\n",
      "5441,5442,5443,5444,5445,5446,5447,5448,5449,5450,\tIter: 5450, train loss: -1.3306, avg nll: -1.3525, avg wnll: 40.2188, avg kl: 0.0004, mse: 0.004294, wmse: 0.036159, mae: 0.048796, val nll: -1.4256, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.4484, test mse: 0.0036\n",
      "5451,5452,5453,5454,5455,5456,5457,5458,5459,5460,\tIter: 5460, train loss: -1.4078, avg nll: -1.4282, avg wnll: 34.6917, avg kl: 0.0004, mse: 0.004020, wmse: 0.034154, mae: 0.046600, val nll: -1.5491, val mse 0.0029, lr 0.000072900\n",
      "test nll: -1.4143, test mse: 0.0040\n",
      "5461,5462,5463,5464,5465,5466,5467,5468,5469,5470,\tIter: 5470, train loss: -1.4042, avg nll: -1.4240, avg wnll: 37.0018, avg kl: 0.0003, mse: 0.003893, wmse: 0.032394, mae: 0.046306, val nll: -1.4962, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.5183, test mse: 0.0032\n",
      "5471,5472,5473,5474,5475,5476,5477,5478,5479,5480,\tIter: 5480, train loss: -1.3224, avg nll: -1.3452, avg wnll: 38.9492, avg kl: 0.0004, mse: 0.004489, wmse: 0.037210, mae: 0.049349, val nll: -1.3416, val mse 0.0046, lr 0.000072900\n",
      "test nll: -1.4366, test mse: 0.0037\n",
      "5481,5482,5483,5484,5485,5486,5487,5488,5489,5490,\tIter: 5490, train loss: -1.3455, avg nll: -1.3672, avg wnll: 37.7941, avg kl: 0.0005, mse: 0.004234, wmse: 0.034856, mae: 0.047907, val nll: -1.4162, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.4432, test mse: 0.0038\n",
      "5491,5492,5493,5494,5495,5496,5497,5498,5499,5500,\tIter: 5500, train loss: -1.4686, avg nll: -1.4868, avg wnll: 33.0503, avg kl: 0.0005, mse: 0.003545, wmse: 0.029828, mae: 0.044201, val nll: -1.4760, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4342, test mse: 0.0040\n",
      "5501,5502,5503,5504,5505,5506,5507,5508,5509,5510,\tIter: 5510, train loss: -1.4911, avg nll: -1.5076, avg wnll: 30.9961, avg kl: 0.0003, mse: 0.003234, wmse: 0.027554, mae: 0.043280, val nll: -1.4862, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.3546, test mse: 0.0048\n",
      "5511,5512,5513,5514,5515,5516,5517,5518,5519,5520,\tIter: 5520, train loss: -1.5015, avg nll: -1.5176, avg wnll: 33.0845, avg kl: 0.0002, mse: 0.003184, wmse: 0.026850, mae: 0.042310, val nll: -1.5217, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.4818, test mse: 0.0037\n",
      "5521,5522,5523,5524,5525,5526,5527,5528,5529,5530,\tIter: 5530, train loss: -1.3985, avg nll: -1.4186, avg wnll: 36.9195, avg kl: 0.0003, mse: 0.003963, wmse: 0.033438, mae: 0.046183, val nll: -1.5341, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.4611, test mse: 0.0035\n",
      "5531,5532,5533,5534,5535,5536,5537,5538,5539,5540,\tIter: 5540, train loss: -1.4506, avg nll: -1.4681, avg wnll: 31.3267, avg kl: 0.0004, mse: 0.003424, wmse: 0.028977, mae: 0.043725, val nll: -1.4582, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4468, test mse: 0.0036\n",
      "5541,5542,5543,5544,5545,5546,5547,5548,5549,5550,\tIter: 5550, train loss: -1.3792, avg nll: -1.3994, avg wnll: 38.1351, avg kl: 0.0004, mse: 0.003958, wmse: 0.033109, mae: 0.047519, val nll: -1.2440, val mse 0.0050, lr 0.000072900\n",
      "test nll: -1.3598, test mse: 0.0038\n",
      "5551,5552,5553,5554,5555,5556,5557,5558,5559,5560,\tIter: 5560, train loss: -1.4315, avg nll: -1.4509, avg wnll: 32.2537, avg kl: 0.0006, mse: 0.003780, wmse: 0.031885, mae: 0.046118, val nll: -1.4736, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.3645, test mse: 0.0043\n",
      "5561,5562,5563,5564,5565,5566,5567,5568,5569,5570,\tIter: 5570, train loss: -1.4059, avg nll: -1.4264, avg wnll: 34.0055, avg kl: 0.0009, mse: 0.003921, wmse: 0.033247, mae: 0.046493, val nll: -1.3399, val mse 0.0046, lr 0.000072900\n",
      "test nll: -1.2805, test mse: 0.0052\n",
      "5571,5572,5573,5574,5575,5576,5577,5578,5579,5580,\tIter: 5580, train loss: -1.4355, avg nll: -1.4542, avg wnll: 35.4450, avg kl: 0.0002, mse: 0.003706, wmse: 0.031227, mae: 0.044719, val nll: -1.4001, val mse 0.0041, lr 0.000072900\n",
      "test nll: -1.4705, test mse: 0.0034\n",
      "5581,5582,5583,5584,5585,5586,5587,5588,5589,5590,\tIter: 5590, train loss: -1.3664, avg nll: -1.3863, avg wnll: 37.0409, avg kl: 0.0003, mse: 0.003921, wmse: 0.032953, mae: 0.047273, val nll: -1.3162, val mse 0.0043, lr 0.000072900\n",
      "test nll: -1.3765, test mse: 0.0043\n",
      "5591,5592,5593,5594,5595,5596,5597,5598,5599,5600,\tIter: 5600, train loss: -1.4022, avg nll: -1.4230, avg wnll: 36.2462, avg kl: 0.0004, mse: 0.004083, wmse: 0.033479, mae: 0.047212, val nll: -1.3969, val mse 0.0040, lr 0.000072900\n",
      "test nll: -1.4953, test mse: 0.0031\n",
      "saving.................\n",
      "done\n",
      "5601,5602,5603,5604,5605,5606,5607,5608,5609,5610,\tIter: 5610, train loss: -1.4315, avg nll: -1.4502, avg wnll: 34.4934, avg kl: 0.0004, mse: 0.003674, wmse: 0.031237, mae: 0.045790, val nll: -1.4078, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.4693, test mse: 0.0038\n",
      "5611,5612,5613,5614,5615,5616,5617,5618,5619,5620,\tIter: 5620, train loss: -1.4993, avg nll: -1.5159, avg wnll: 31.0238, avg kl: 0.0004, mse: 0.003243, wmse: 0.027315, mae: 0.042742, val nll: -1.4530, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4042, test mse: 0.0039\n",
      "5621,5622,5623,5624,5625,5626,5627,5628,5629,5630,\tIter: 5630, train loss: -1.4240, avg nll: -1.4433, avg wnll: 35.7147, avg kl: 0.0003, mse: 0.003816, wmse: 0.032431, mae: 0.045485, val nll: -1.4216, val mse 0.0038, lr 0.000072900\n",
      "test nll: -1.4894, test mse: 0.0033\n",
      "5631,5632,5633,5634,5635,5636,5637,5638,5639,5640,\tIter: 5640, train loss: -1.3994, avg nll: -1.4193, avg wnll: 38.3728, avg kl: 0.0003, mse: 0.003931, wmse: 0.033079, mae: 0.047182, val nll: -1.4530, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4757, test mse: 0.0034\n",
      "5641,5642,5643,5644,5645,5646,5647,5648,5649,5650,\tIter: 5650, train loss: -1.3855, avg nll: -1.4054, avg wnll: 35.6784, avg kl: 0.0005, mse: 0.003888, wmse: 0.032335, mae: 0.046231, val nll: -1.5016, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4338, test mse: 0.0033\n",
      "5651,5652,5653,5654,5655,5656,5657,5658,5659,5660,\tIter: 5660, train loss: -1.3777, avg nll: -1.3982, avg wnll: 38.0428, avg kl: 0.0004, mse: 0.004023, wmse: 0.034370, mae: 0.048878, val nll: -1.4274, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4293, test mse: 0.0038\n",
      "5661,5662,5663,5664,5665,5666,5667,5668,5669,5670,\tIter: 5670, train loss: -1.4339, avg nll: -1.4529, avg wnll: 34.9931, avg kl: 0.0004, mse: 0.003717, wmse: 0.031373, mae: 0.044899, val nll: -1.4873, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.4460, test mse: 0.0041\n",
      "5671,5672,5673,5674,5675,5676,5677,5678,5679,5680,\tIter: 5680, train loss: -1.3763, avg nll: -1.3965, avg wnll: 34.3007, avg kl: 0.0005, mse: 0.003942, wmse: 0.032916, mae: 0.047291, val nll: -1.4189, val mse 0.0038, lr 0.000072900\n",
      "test nll: -1.3678, test mse: 0.0044\n",
      "5681,5682,5683,5684,5685,5686,5687,5688,5689,5690,\tIter: 5690, train loss: -1.4093, avg nll: -1.4282, avg wnll: 33.0926, avg kl: 0.0005, mse: 0.003690, wmse: 0.031161, mae: 0.046717, val nll: -1.4156, val mse 0.0040, lr 0.000072900\n",
      "test nll: -1.2631, test mse: 0.0049\n",
      "5691,5692,5693,5694,5695,5696,5697,5698,5699,5700,\tIter: 5700, train loss: -1.4568, avg nll: -1.4754, avg wnll: 34.0750, avg kl: 0.0003, mse: 0.003665, wmse: 0.030483, mae: 0.043724, val nll: -1.4506, val mse 0.0037, lr 0.000072900\n",
      "test nll: -1.4759, test mse: 0.0033\n",
      "5701,5702,5703,5704,5705,5706,5707,5708,5709,5710,\tIter: 5710, train loss: -1.3396, avg nll: -1.3622, avg wnll: 37.7395, avg kl: 0.0007, mse: 0.004383, wmse: 0.036868, mae: 0.048874, val nll: -1.4015, val mse 0.0039, lr 0.000072900\n",
      "test nll: -1.4989, test mse: 0.0036\n",
      "5711,5712,5713,5714,5715,5716,5717,5718,5719,5720,\tIter: 5720, train loss: -1.3270, avg nll: -1.3491, avg wnll: 38.5914, avg kl: 0.0011, mse: 0.004186, wmse: 0.034800, mae: 0.048692, val nll: -1.3936, val mse 0.0038, lr 0.000072900\n",
      "test nll: -1.3186, test mse: 0.0044\n",
      "5721,5722,5723,5724,5725,5726,5727,5728,5729,5730,\tIter: 5730, train loss: -1.4395, avg nll: -1.4582, avg wnll: 32.9536, avg kl: 0.0007, mse: 0.003612, wmse: 0.030344, mae: 0.044649, val nll: -1.4756, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.4381, test mse: 0.0037\n",
      "5731,5732,5733,5734,5735,5736,5737,5738,5739,5740,\tIter: 5740, train loss: -1.4884, avg nll: -1.5050, avg wnll: 34.2534, avg kl: 0.0003, mse: 0.003270, wmse: 0.027464, mae: 0.042432, val nll: -1.4601, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4953, test mse: 0.0030\n",
      "5741,5742,5743,5744,5745,5746,5747,5748,5749,5750,\tIter: 5750, train loss: -1.4615, avg nll: -1.4802, avg wnll: 31.0932, avg kl: 0.0004, mse: 0.003669, wmse: 0.030834, mae: 0.043818, val nll: -1.5122, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4134, test mse: 0.0042\n",
      "5751,5752,5753,5754,5755,5756,5757,5758,5759,5760,\tIter: 5760, train loss: -1.4485, avg nll: -1.4669, avg wnll: 35.2292, avg kl: 0.0003, mse: 0.003634, wmse: 0.030889, mae: 0.044507, val nll: -1.4459, val mse 0.0040, lr 0.000072900\n",
      "test nll: -1.4183, test mse: 0.0041\n",
      "5761,5762,5763,5764,5765,5766,5767,5768,5769,5770,\tIter: 5770, train loss: -1.4645, avg nll: -1.4822, avg wnll: 32.8628, avg kl: 0.0003, mse: 0.003469, wmse: 0.029598, mae: 0.044030, val nll: -1.3119, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.3442, test mse: 0.0045\n",
      "5771,5772,5773,5774,5775,5776,5777,5778,5779,5780,\tIter: 5780, train loss: -1.4084, avg nll: -1.4286, avg wnll: 35.6853, avg kl: 0.0003, mse: 0.003965, wmse: 0.033175, mae: 0.046665, val nll: -1.5051, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.3812, test mse: 0.0041\n",
      "5781,5782,5783,5784,5785,5786,5787,5788,5789,5790,\tIter: 5790, train loss: -1.4383, avg nll: -1.4564, avg wnll: 36.3758, avg kl: 0.0004, mse: 0.003550, wmse: 0.030237, mae: 0.045003, val nll: -1.4841, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.3934, test mse: 0.0041\n",
      "5791,5792,5793,5794,5795,5796,5797,5798,5799,5800,\tIter: 5800, train loss: -1.4423, avg nll: -1.4616, avg wnll: 34.0677, avg kl: 0.0003, mse: 0.003803, wmse: 0.032791, mae: 0.045160, val nll: -1.4827, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.3984, test mse: 0.0041\n",
      "saving.................\n",
      "done\n",
      "5801,5802,5803,5804,5805,5806,5807,5808,5809,5810,\tIter: 5810, train loss: -1.4339, avg nll: -1.4528, avg wnll: 32.3442, avg kl: 0.0003, mse: 0.003733, wmse: 0.031078, mae: 0.045672, val nll: -1.4757, val mse 0.0031, lr 0.000072900\n",
      "test nll: -1.4120, test mse: 0.0038\n",
      "5811,5812,5813,5814,5815,5816,5817,5818,5819,5820,\tIter: 5820, train loss: -1.4845, avg nll: -1.5014, avg wnll: 30.6377, avg kl: 0.0004, mse: 0.003307, wmse: 0.027925, mae: 0.043377, val nll: -1.5039, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.3822, test mse: 0.0044\n",
      "5821,5822,5823,5824,5825,5826,5827,5828,5829,5830,\tIter: 5830, train loss: -1.4659, avg nll: -1.4840, avg wnll: 32.1863, avg kl: 0.0002, mse: 0.003587, wmse: 0.029865, mae: 0.043414, val nll: -1.4885, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4246, test mse: 0.0043\n",
      "5831,5832,5833,5834,5835,5836,5837,5838,5839,5840,\tIter: 5840, train loss: -1.3945, avg nll: -1.4151, avg wnll: 35.6507, avg kl: 0.0003, mse: 0.004068, wmse: 0.034557, mae: 0.046845, val nll: -1.4616, val mse 0.0038, lr 0.000072900\n",
      "test nll: -1.3961, test mse: 0.0039\n",
      "5841,5842,5843,5844,5845,5846,5847,5848,5849,5850,\tIter: 5850, train loss: -1.4508, avg nll: -1.4686, avg wnll: 36.3064, avg kl: 0.0003, mse: 0.003500, wmse: 0.029899, mae: 0.045245, val nll: -1.5648, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.5096, test mse: 0.0031\n",
      "5851,5852,5853,5854,5855,5856,5857,5858,5859,5860,\tIter: 5860, train loss: -1.4599, avg nll: -1.4785, avg wnll: 34.0135, avg kl: 0.0002, mse: 0.003673, wmse: 0.031027, mae: 0.043955, val nll: -1.4648, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.4543, test mse: 0.0037\n",
      "5861,5862,5863,5864,5865,5866,5867,5868,5869,5870,\tIter: 5870, train loss: -1.4561, avg nll: -1.4742, avg wnll: 34.1552, avg kl: 0.0003, mse: 0.003551, wmse: 0.030091, mae: 0.044741, val nll: -1.5060, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.4341, test mse: 0.0039\n",
      "5871,5872,5873,5874,5875,5876,5877,5878,5879,5880,\tIter: 5880, train loss: -1.4666, avg nll: -1.4844, avg wnll: 32.9414, avg kl: 0.0002, mse: 0.003519, wmse: 0.029570, mae: 0.044280, val nll: -1.5178, val mse 0.0034, lr 0.000072900\n",
      "test nll: -1.5167, test mse: 0.0032\n",
      "5881,5882,5883,5884,5885,5886,5887,5888,5889,5890,\tIter: 5890, train loss: -1.4106, avg nll: -1.4308, avg wnll: 34.9790, avg kl: 0.0003, mse: 0.003968, wmse: 0.033468, mae: 0.046900, val nll: -1.5083, val mse 0.0033, lr 0.000072900\n",
      "test nll: -1.4198, test mse: 0.0039\n",
      "5891,5892,5893,5894,5895,5896,5897,5898,5899,5900,\tIter: 5900, train loss: -1.3841, avg nll: -1.4053, avg wnll: 37.2038, avg kl: 0.0003, mse: 0.004179, wmse: 0.034721, mae: 0.047645, val nll: -1.5100, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.3554, test mse: 0.0042\n",
      "5901,5902,5903,5904,5905,5906,5907,5908,5909,5910,\tIter: 5910, train loss: -1.4037, avg nll: -1.4224, avg wnll: 36.8611, avg kl: 0.0003, mse: 0.003698, wmse: 0.031127, mae: 0.045387, val nll: -1.5531, val mse 0.0025, lr 0.000072900\n",
      "test nll: -1.4931, test mse: 0.0032\n",
      "5911,5912,5913,5914,5915,5916,5917,5918,5919,5920,\tIter: 5920, train loss: -1.4315, avg nll: -1.4503, avg wnll: 33.9194, avg kl: 0.0005, mse: 0.003661, wmse: 0.030528, mae: 0.043539, val nll: -1.4945, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.5276, test mse: 0.0031\n",
      "5921,5922,5923,5924,5925,5926,5927,5928,5929,5930,\tIter: 5930, train loss: -1.4019, avg nll: -1.4215, avg wnll: 38.4828, avg kl: 0.0002, mse: 0.003886, wmse: 0.032668, mae: 0.045824, val nll: -1.5285, val mse 0.0029, lr 0.000072900\n",
      "test nll: -1.4880, test mse: 0.0033\n",
      "5931,5932,5933,5934,5935,5936,5937,5938,5939,5940,\tIter: 5940, train loss: -1.4329, avg nll: -1.4513, avg wnll: 32.2885, avg kl: 0.0005, mse: 0.003591, wmse: 0.030186, mae: 0.045171, val nll: -1.2935, val mse 0.0046, lr 0.000072900\n",
      "test nll: -1.3088, test mse: 0.0049\n",
      "5941,5942,5943,5944,5945,5946,5947,5948,5949,5950,\tIter: 5950, train loss: -1.4431, avg nll: -1.4615, avg wnll: 34.5725, avg kl: 0.0002, mse: 0.003620, wmse: 0.030495, mae: 0.043920, val nll: -1.4475, val mse 0.0032, lr 0.000072900\n",
      "test nll: -1.4096, test mse: 0.0039\n",
      "5951,5952,5953,5954,5955,5956,5957,5958,5959,5960,\tIter: 5960, train loss: -1.4268, avg nll: -1.4460, avg wnll: 35.5465, avg kl: 0.0002, mse: 0.003810, wmse: 0.032079, mae: 0.046005, val nll: -1.4002, val mse 0.0036, lr 0.000072900\n",
      "test nll: -1.4132, test mse: 0.0037\n",
      "5961,5962,5963,5964,5965,5966,5967,5968,5969,5970,\tIter: 5970, train loss: -1.4479, avg nll: -1.4666, avg wnll: 31.6278, avg kl: 0.0005, mse: 0.003644, wmse: 0.030604, mae: 0.044795, val nll: -1.4575, val mse 0.0035, lr 0.000072900\n",
      "test nll: -1.4684, test mse: 0.0036\n",
      "5971,5972,5973,5974,5975,5976,5977,5978,5979,5980,\tIter: 5980, train loss: -1.3925, avg nll: -1.4132, avg wnll: 39.2140, avg kl: 0.0004, mse: 0.004069, wmse: 0.035072, mae: 0.047489, val nll: -1.4126, val mse 0.0040, lr 0.000072900\n",
      "test nll: -1.4288, test mse: 0.0038\n",
      "5981,5982,5983,5984,5985,5986,5987,5988,5989,5990,\tIter: 5990, train loss: -1.4342, avg nll: -1.4533, avg wnll: 36.8933, avg kl: 0.0002, mse: 0.003767, wmse: 0.031436, mae: 0.045258, val nll: -1.4031, val mse 0.0043, lr 0.000072900\n",
      "test nll: -1.4732, test mse: 0.0035\n",
      "5991,5992,5993,5994,5995,5996,5997,5998,5999,6000,\tIter: 6000, train loss: -1.3883, avg nll: -1.4093, avg wnll: 36.5960, avg kl: 0.0004, mse: 0.004123, wmse: 0.034332, mae: 0.047796, val nll: -1.4040, val mse 0.0042, lr 0.000072900\n",
      "test nll: -1.4444, test mse: 0.0037\n",
      "saving.................\n",
      "done\n",
      "6001,6002,6003,6004,6005,6006,6007,6008,6009,6010,\tIter: 6010, train loss: -1.4840, avg nll: -1.5007, avg wnll: 32.0991, avg kl: 0.0007, mse: 0.003203, wmse: 0.027101, mae: 0.043015, val nll: -1.4340, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.2932, test mse: 0.0046\n",
      "6011,6012,6013,6014,6015,6016,6017,6018,6019,6020,\tIter: 6020, train loss: -1.4422, avg nll: -1.4611, avg wnll: 33.9274, avg kl: 0.0004, mse: 0.003712, wmse: 0.031355, mae: 0.044526, val nll: -1.5776, val mse 0.0026, lr 0.000065610\n",
      "test nll: -1.3933, test mse: 0.0042\n",
      "6021,6022,6023,6024,6025,6026,6027,6028,6029,6030,\tIter: 6030, train loss: -1.4872, avg nll: -1.5050, avg wnll: 32.9697, avg kl: 0.0002, mse: 0.003521, wmse: 0.029526, mae: 0.043352, val nll: -1.4415, val mse 0.0039, lr 0.000065610\n",
      "test nll: -1.4818, test mse: 0.0034\n",
      "6031,6032,6033,6034,6035,6036,6037,6038,6039,6040,\tIter: 6040, train loss: -1.4454, avg nll: -1.4631, avg wnll: 33.0573, avg kl: 0.0002, mse: 0.003502, wmse: 0.029480, mae: 0.044740, val nll: -1.4850, val mse 0.0034, lr 0.000065610\n",
      "test nll: -1.4207, test mse: 0.0039\n",
      "6041,6042,6043,6044,6045,6046,6047,6048,6049,6050,\tIter: 6050, train loss: -1.4224, avg nll: -1.4406, avg wnll: 34.6417, avg kl: 0.0002, mse: 0.003601, wmse: 0.029777, mae: 0.043924, val nll: -1.5597, val mse 0.0027, lr 0.000065610\n",
      "test nll: -1.3606, test mse: 0.0048\n",
      "6051,6052,6053,6054,6055,6056,6057,6058,6059,6060,\tIter: 6060, train loss: -1.4626, avg nll: -1.4795, avg wnll: 33.9969, avg kl: 0.0003, mse: 0.003319, wmse: 0.028262, mae: 0.043357, val nll: -1.3817, val mse 0.0037, lr 0.000065610\n",
      "test nll: -1.4260, test mse: 0.0037\n",
      "6061,6062,6063,6064,6065,6066,6067,6068,6069,6070,\tIter: 6070, train loss: -1.4777, avg nll: -1.4959, avg wnll: 34.1128, avg kl: 0.0002, mse: 0.003593, wmse: 0.030305, mae: 0.043883, val nll: -1.4801, val mse 0.0039, lr 0.000065610\n",
      "test nll: -1.3858, test mse: 0.0043\n",
      "6071,6072,6073,6074,6075,6076,6077,6078,6079,6080,\tIter: 6080, train loss: -1.4480, avg nll: -1.4654, avg wnll: 36.7459, avg kl: 0.0003, mse: 0.003429, wmse: 0.028626, mae: 0.043604, val nll: -1.4054, val mse 0.0042, lr 0.000065610\n",
      "test nll: -1.5376, test mse: 0.0030\n",
      "6081,6082,6083,6084,6085,6086,6087,6088,6089,6090,\tIter: 6090, train loss: -1.4402, avg nll: -1.4594, avg wnll: 35.4874, avg kl: 0.0002, mse: 0.003785, wmse: 0.032618, mae: 0.045328, val nll: -1.5015, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.4725, test mse: 0.0034\n",
      "6091,6092,6093,6094,6095,6096,6097,6098,6099,6100,\tIter: 6100, train loss: -1.4008, avg nll: -1.4204, avg wnll: 37.4573, avg kl: 0.0003, mse: 0.003861, wmse: 0.032428, mae: 0.046393, val nll: -1.4380, val mse 0.0039, lr 0.000065610\n",
      "test nll: -1.4403, test mse: 0.0037\n",
      "6101,6102,6103,6104,6105,6106,6107,6108,6109,6110,\tIter: 6110, train loss: -1.4341, avg nll: -1.4528, avg wnll: 37.5877, avg kl: 0.0002, mse: 0.003687, wmse: 0.031512, mae: 0.045221, val nll: -1.5100, val mse 0.0032, lr 0.000065610\n",
      "test nll: -1.4287, test mse: 0.0039\n",
      "6111,6112,6113,6114,6115,6116,6117,6118,6119,6120,\tIter: 6120, train loss: -1.4505, avg nll: -1.4682, avg wnll: 33.7536, avg kl: 0.0003, mse: 0.003466, wmse: 0.028950, mae: 0.044062, val nll: -1.4412, val mse 0.0037, lr 0.000065610\n",
      "test nll: -1.4823, test mse: 0.0038\n",
      "6121,6122,6123,6124,6125,6126,6127,6128,6129,6130,\tIter: 6130, train loss: -1.4396, avg nll: -1.4577, avg wnll: 36.4506, avg kl: 0.0003, mse: 0.003572, wmse: 0.030343, mae: 0.044535, val nll: -1.4152, val mse 0.0042, lr 0.000065610\n",
      "test nll: -1.3711, test mse: 0.0048\n",
      "6131,6132,6133,6134,6135,6136,6137,6138,6139,6140,\tIter: 6140, train loss: -1.4341, avg nll: -1.4529, avg wnll: 35.2661, avg kl: 0.0002, mse: 0.003714, wmse: 0.030928, mae: 0.044386, val nll: -1.5048, val mse 0.0032, lr 0.000065610\n",
      "test nll: -1.4523, test mse: 0.0037\n",
      "6141,6142,6143,6144,6145,6146,6147,6148,6149,6150,\tIter: 6150, train loss: -1.4722, avg nll: -1.4896, avg wnll: 35.3218, avg kl: 0.0001, mse: 0.003457, wmse: 0.029160, mae: 0.043417, val nll: -1.4812, val mse 0.0030, lr 0.000065610\n",
      "test nll: -1.5417, test mse: 0.0030\n",
      "6151,6152,6153,6154,6155,6156,6157,6158,6159,6160,\tIter: 6160, train loss: -1.4177, avg nll: -1.4370, avg wnll: 36.8599, avg kl: 0.0002, mse: 0.003819, wmse: 0.031719, mae: 0.046077, val nll: -1.5208, val mse 0.0034, lr 0.000065610\n",
      "test nll: -1.4329, test mse: 0.0036\n",
      "6161,6162,6163,6164,6165,6166,6167,6168,6169,6170,\tIter: 6170, train loss: -1.4278, avg nll: -1.4472, avg wnll: 38.3769, avg kl: 0.0002, mse: 0.003851, wmse: 0.032318, mae: 0.045590, val nll: -1.4968, val mse 0.0032, lr 0.000065610\n",
      "test nll: -1.4719, test mse: 0.0038\n",
      "6171,6172,6173,6174,6175,6176,6177,6178,6179,6180,\tIter: 6180, train loss: -1.4614, avg nll: -1.4799, avg wnll: 35.9670, avg kl: 0.0002, mse: 0.003666, wmse: 0.030890, mae: 0.044416, val nll: -1.5124, val mse 0.0031, lr 0.000065610\n",
      "test nll: -1.4854, test mse: 0.0033\n",
      "6181,6182,6183,6184,6185,6186,6187,6188,6189,6190,\tIter: 6190, train loss: -1.4337, avg nll: -1.4523, avg wnll: 37.1185, avg kl: 0.0002, mse: 0.003684, wmse: 0.030896, mae: 0.045188, val nll: -1.5089, val mse 0.0031, lr 0.000065610\n",
      "test nll: -1.4995, test mse: 0.0036\n",
      "6191,6192,6193,6194,6195,6196,6197,6198,6199,6200,\tIter: 6200, train loss: -1.4403, avg nll: -1.4593, avg wnll: 35.3862, avg kl: 0.0003, mse: 0.003746, wmse: 0.031161, mae: 0.044941, val nll: -1.4921, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.5133, test mse: 0.0034\n",
      "saving.................\n",
      "done\n",
      "6201,6202,6203,6204,6205,6206,6207,6208,6209,6210,\tIter: 6210, train loss: -1.4588, avg nll: -1.4773, avg wnll: 35.1074, avg kl: 0.0003, mse: 0.003642, wmse: 0.030756, mae: 0.044478, val nll: -1.5633, val mse 0.0028, lr 0.000065610\n",
      "test nll: -1.4278, test mse: 0.0044\n",
      "6211,6212,6213,6214,6215,6216,6217,6218,6219,6220,\tIter: 6220, train loss: -1.4745, avg nll: -1.4920, avg wnll: 30.7092, avg kl: 0.0005, mse: 0.003413, wmse: 0.028704, mae: 0.043616, val nll: -1.2714, val mse 0.0049, lr 0.000065610\n",
      "test nll: -1.3019, test mse: 0.0047\n",
      "6221,6222,6223,6224,6225,6226,6227,6228,6229,6230,\tIter: 6230, train loss: -1.4760, avg nll: -1.4945, avg wnll: 32.7293, avg kl: 0.0007, mse: 0.003556, wmse: 0.030062, mae: 0.043040, val nll: -1.4988, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.3328, test mse: 0.0044\n",
      "6231,6232,6233,6234,6235,6236,6237,6238,6239,6240,\tIter: 6240, train loss: -1.4846, avg nll: -1.5016, avg wnll: 32.6171, avg kl: 0.0002, mse: 0.003360, wmse: 0.028268, mae: 0.042124, val nll: -1.5330, val mse 0.0033, lr 0.000065610\n",
      "test nll: -1.4744, test mse: 0.0035\n",
      "6241,6242,6243,6244,6245,6246,6247,6248,6249,6250,\tIter: 6250, train loss: -1.3385, avg nll: -1.3599, avg wnll: 40.3660, avg kl: 0.0005, mse: 0.004182, wmse: 0.035385, mae: 0.049980, val nll: -1.3498, val mse 0.0040, lr 0.000065610\n",
      "test nll: -1.1974, test mse: 0.0053\n",
      "6251,6252,6253,6254,6255,6256,6257,6258,6259,6260,\tIter: 6260, train loss: -1.4341, avg nll: -1.4538, avg wnll: 32.7251, avg kl: 0.0008, mse: 0.003776, wmse: 0.031501, mae: 0.045118, val nll: -1.4747, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.4643, test mse: 0.0033\n",
      "6261,6262,6263,6264,6265,6266,6267,6268,6269,6270,\tIter: 6270, train loss: -1.3945, avg nll: -1.4155, avg wnll: 38.2939, avg kl: 0.0006, mse: 0.004089, wmse: 0.034707, mae: 0.047002, val nll: -1.5427, val mse 0.0030, lr 0.000065610\n",
      "test nll: -1.4152, test mse: 0.0040\n",
      "6271,6272,6273,6274,6275,6276,6277,6278,6279,6280,\tIter: 6280, train loss: -1.4410, avg nll: -1.4600, avg wnll: 33.7580, avg kl: 0.0005, mse: 0.003680, wmse: 0.030715, mae: 0.044217, val nll: -1.4401, val mse 0.0039, lr 0.000065610\n",
      "test nll: -1.4304, test mse: 0.0039\n",
      "6281,6282,6283,6284,6285,6286,6287,6288,6289,6290,\tIter: 6290, train loss: -1.4155, avg nll: -1.4358, avg wnll: 37.2606, avg kl: 0.0002, mse: 0.004020, wmse: 0.034146, mae: 0.046758, val nll: -1.4974, val mse 0.0032, lr 0.000065610\n",
      "test nll: -1.3064, test mse: 0.0048\n",
      "6291,6292,6293,6294,6295,6296,6297,6298,6299,6300,\tIter: 6300, train loss: -1.4352, avg nll: -1.4550, avg wnll: 35.8716, avg kl: 0.0003, mse: 0.003901, wmse: 0.032534, mae: 0.045128, val nll: -1.5065, val mse 0.0034, lr 0.000065610\n",
      "test nll: -1.4173, test mse: 0.0044\n",
      "6301,6302,6303,6304,6305,6306,6307,6308,6309,6310,\tIter: 6310, train loss: -1.4154, avg nll: -1.4346, avg wnll: 34.9822, avg kl: 0.0003, mse: 0.003764, wmse: 0.031543, mae: 0.046230, val nll: -1.4623, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.4369, test mse: 0.0042\n",
      "6311,6312,6313,6314,6315,6316,6317,6318,6319,6320,\tIter: 6320, train loss: -1.4499, avg nll: -1.4687, avg wnll: 34.3908, avg kl: 0.0003, mse: 0.003693, wmse: 0.030833, mae: 0.044443, val nll: -1.3940, val mse 0.0043, lr 0.000065610\n",
      "test nll: -1.4473, test mse: 0.0036\n",
      "6321,6322,6323,6324,6325,6326,6327,6328,6329,6330,\tIter: 6330, train loss: -1.4631, avg nll: -1.4814, avg wnll: 37.3765, avg kl: 0.0002, mse: 0.003607, wmse: 0.030796, mae: 0.043585, val nll: -1.3725, val mse 0.0044, lr 0.000065610\n",
      "test nll: -1.4090, test mse: 0.0044\n",
      "6331,6332,6333,6334,6335,6336,6337,6338,6339,6340,\tIter: 6340, train loss: -1.4362, avg nll: -1.4554, avg wnll: 34.9853, avg kl: 0.0004, mse: 0.003761, wmse: 0.030841, mae: 0.044231, val nll: -1.4829, val mse 0.0038, lr 0.000065610\n",
      "test nll: -1.4831, test mse: 0.0035\n",
      "6341,6342,6343,6344,6345,6346,6347,6348,6349,6350,\tIter: 6350, train loss: -1.4891, avg nll: -1.5062, avg wnll: 34.7965, avg kl: 0.0003, mse: 0.003378, wmse: 0.029024, mae: 0.043550, val nll: -1.5099, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.4801, test mse: 0.0033\n",
      "6351,6352,6353,6354,6355,6356,6357,6358,6359,6360,\tIter: 6360, train loss: -1.4599, avg nll: -1.4769, avg wnll: 35.4870, avg kl: 0.0002, mse: 0.003362, wmse: 0.028422, mae: 0.043459, val nll: -1.4613, val mse 0.0039, lr 0.000065610\n",
      "test nll: -1.4267, test mse: 0.0037\n",
      "6361,6362,6363,6364,6365,6366,6367,6368,6369,6370,\tIter: 6370, train loss: -1.4609, avg nll: -1.4789, avg wnll: 34.6592, avg kl: 0.0002, mse: 0.003561, wmse: 0.030068, mae: 0.044727, val nll: -1.3437, val mse 0.0046, lr 0.000065610\n",
      "test nll: -1.4556, test mse: 0.0038\n",
      "6371,6372,6373,6374,6375,6376,6377,6378,6379,6380,\tIter: 6380, train loss: -1.4467, avg nll: -1.4659, avg wnll: 33.9521, avg kl: 0.0002, mse: 0.003809, wmse: 0.032068, mae: 0.044455, val nll: -1.4467, val mse 0.0038, lr 0.000065610\n",
      "test nll: -1.4264, test mse: 0.0040\n",
      "6381,6382,6383,6384,6385,6386,6387,6388,6389,6390,\tIter: 6390, train loss: -1.4356, avg nll: -1.4546, avg wnll: 36.7331, avg kl: 0.0002, mse: 0.003755, wmse: 0.031390, mae: 0.044912, val nll: -1.5047, val mse 0.0033, lr 0.000065610\n",
      "test nll: -1.4291, test mse: 0.0035\n",
      "6391,6392,6393,6394,6395,6396,6397,6398,6399,6400,\tIter: 6400, train loss: -1.4526, avg nll: -1.4701, avg wnll: 35.8542, avg kl: 0.0002, mse: 0.003456, wmse: 0.029090, mae: 0.044691, val nll: -1.5345, val mse 0.0033, lr 0.000065610\n",
      "test nll: -1.4583, test mse: 0.0036\n",
      "saving.................\n",
      "done\n",
      "6401,6402,6403,6404,6405,6406,6407,6408,6409,6410,\tIter: 6410, train loss: -1.4462, avg nll: -1.4645, avg wnll: 36.5819, avg kl: 0.0002, mse: 0.003622, wmse: 0.031120, mae: 0.044725, val nll: -1.4976, val mse 0.0036, lr 0.000065610\n",
      "test nll: -1.4651, test mse: 0.0037\n",
      "6411,6412,6413,6414,6415,6416,6417,6418,6419,6420,\tIter: 6420, train loss: -1.3577, avg nll: -1.3793, avg wnll: 36.0690, avg kl: 0.0006, mse: 0.004195, wmse: 0.035292, mae: 0.049495, val nll: -1.5170, val mse 0.0033, lr 0.000065610\n",
      "test nll: -1.3692, test mse: 0.0042\n",
      "6421,6422,6423,6424,6425,6426,6427,6428,6429,6430,\tIter: 6430, train loss: -1.4395, avg nll: -1.4584, avg wnll: 32.5496, avg kl: 0.0005, mse: 0.003686, wmse: 0.030698, mae: 0.045006, val nll: -1.5340, val mse 0.0029, lr 0.000065610\n",
      "test nll: -1.4199, test mse: 0.0036\n",
      "6431,6432,6433,6434,6435,6436,6437,6438,6439,6440,\tIter: 6440, train loss: -1.3669, avg nll: -1.3868, avg wnll: 39.3671, avg kl: 0.0003, mse: 0.003913, wmse: 0.032859, mae: 0.048012, val nll: -1.3124, val mse 0.0041, lr 0.000065610\n",
      "test nll: -1.3977, test mse: 0.0039\n",
      "6441,6442,6443,6444,6445,6446,6447,6448,6449,6450,\tIter: 6450, train loss: -1.4163, avg nll: -1.4351, avg wnll: 35.3650, avg kl: 0.0003, mse: 0.003706, wmse: 0.030638, mae: 0.044411, val nll: -1.5235, val mse 0.0033, lr 0.000065610\n",
      "test nll: -1.4657, test mse: 0.0037\n",
      "6451,6452,6453,6454,6455,6456,6457,6458,6459,6460,\tIter: 6460, train loss: -1.4282, avg nll: -1.4468, avg wnll: 33.7912, avg kl: 0.0004, mse: 0.003642, wmse: 0.030612, mae: 0.044985, val nll: -1.5013, val mse 0.0032, lr 0.000065610\n",
      "test nll: -1.4284, test mse: 0.0039\n",
      "6461,6462,6463,6464,6465,6466,6467,6468,6469,6470,\tIter: 6470, train loss: -1.4787, avg nll: -1.4963, avg wnll: 34.6936, avg kl: 0.0002, mse: 0.003501, wmse: 0.030003, mae: 0.044042, val nll: -1.4050, val mse 0.0041, lr 0.000065610\n",
      "test nll: -1.4147, test mse: 0.0037\n",
      "6471,6472,6473,6474,6475,6476,6477,6478,6479,6480,\tIter: 6480, train loss: -1.4393, avg nll: -1.4579, avg wnll: 35.2662, avg kl: 0.0002, mse: 0.003670, wmse: 0.030538, mae: 0.045810, val nll: -1.4791, val mse 0.0035, lr 0.000065610\n",
      "test nll: -1.4922, test mse: 0.0034\n",
      "6481,6482,6483,6484,6485,6486,6487,6488,6489,6490,\tIter: 6490, train loss: -1.4304, avg nll: -1.4493, avg wnll: 36.4917, avg kl: 0.0002, mse: 0.003738, wmse: 0.031347, mae: 0.046104, val nll: -1.4347, val mse 0.0036, lr 0.000065610\n",
      "test nll: -1.3158, test mse: 0.0047\n",
      "6491,6492,6493,6494,6495,6496,6497,6498,6499,6500,\tIter: 6500, train loss: -1.4575, avg nll: -1.4755, avg wnll: 30.7280, avg kl: 0.0004, mse: 0.003534, wmse: 0.029979, mae: 0.044116, val nll: -1.4342, val mse 0.0039, lr 0.000065610\n",
      "test nll: -1.4547, test mse: 0.0035\n",
      "6501,6502,6503,6504,6505,6506,6507,6508,6509,6510,\tIter: 6510, train loss: -1.4725, avg nll: -1.4903, avg wnll: 34.4499, avg kl: 0.0003, mse: 0.003517, wmse: 0.029776, mae: 0.042911, val nll: -1.4335, val mse 0.0035, lr 0.000059049\n",
      "test nll: -1.4484, test mse: 0.0037\n",
      "6511,6512,6513,6514,6515,6516,6517,6518,6519,6520,\tIter: 6520, train loss: -1.4913, avg nll: -1.5096, avg wnll: 32.6227, avg kl: 0.0003, mse: 0.003617, wmse: 0.030518, mae: 0.042788, val nll: -1.5153, val mse 0.0031, lr 0.000059049\n",
      "test nll: -1.4638, test mse: 0.0038\n",
      "6521,6522,6523,6524,6525,6526,6527,6528,6529,6530,\tIter: 6530, train loss: -1.4883, avg nll: -1.5058, avg wnll: 32.7040, avg kl: 0.0003, mse: 0.003442, wmse: 0.028378, mae: 0.042390, val nll: -1.5700, val mse 0.0028, lr 0.000059049\n",
      "test nll: -1.4495, test mse: 0.0037\n",
      "6531,6532,6533,6534,6535,6536,6537,6538,6539,6540,\tIter: 6540, train loss: -1.4877, avg nll: -1.5045, avg wnll: 33.9565, avg kl: 0.0002, mse: 0.003313, wmse: 0.027910, mae: 0.043179, val nll: -1.4795, val mse 0.0033, lr 0.000059049\n",
      "test nll: -1.5321, test mse: 0.0029\n",
      "6541,6542,6543,6544,6545,6546,6547,6548,6549,6550,\tIter: 6550, train loss: -1.5082, avg nll: -1.5241, avg wnll: 32.6355, avg kl: 0.0001, mse: 0.003168, wmse: 0.026569, mae: 0.041694, val nll: -1.4879, val mse 0.0032, lr 0.000059049\n",
      "test nll: -1.4790, test mse: 0.0038\n",
      "6551,6552,6553,6554,6555,6556,6557,6558,6559,6560,\tIter: 6560, train loss: -1.4794, avg nll: -1.4968, avg wnll: 34.5254, avg kl: 0.0001, mse: 0.003455, wmse: 0.029014, mae: 0.042958, val nll: -1.4666, val mse 0.0036, lr 0.000059049\n",
      "test nll: -1.4078, test mse: 0.0043\n",
      "6561,6562,6563,6564,6565,6566,6567,6568,6569,6570,\tIter: 6570, train loss: -1.4681, avg nll: -1.4855, avg wnll: 34.7996, avg kl: 0.0002, mse: 0.003440, wmse: 0.029033, mae: 0.043995, val nll: -1.5258, val mse 0.0030, lr 0.000059049\n",
      "test nll: -1.5057, test mse: 0.0030\n",
      "6571,6572,6573,6574,6575,6576,6577,6578,6579,6580,\tIter: 6580, train loss: -1.4712, avg nll: -1.4891, avg wnll: 33.8319, avg kl: 0.0002, mse: 0.003540, wmse: 0.029928, mae: 0.043852, val nll: -1.4450, val mse 0.0040, lr 0.000059049\n",
      "test nll: -1.5020, test mse: 0.0037\n",
      "6581,6582,6583,6584,6585,6586,6587,6588,6589,6590,\tIter: 6590, train loss: -1.3922, avg nll: -1.4123, avg wnll: 38.6591, avg kl: 0.0002, mse: 0.003998, wmse: 0.033729, mae: 0.046394, val nll: -1.4641, val mse 0.0033, lr 0.000059049\n",
      "test nll: -1.4465, test mse: 0.0037\n",
      "6591,6592,6593,6594,6595,6596,6597,6598,6599,6600,\tIter: 6600, train loss: -1.5077, avg nll: -1.5242, avg wnll: 33.8517, avg kl: 0.0001, mse: 0.003270, wmse: 0.027321, mae: 0.041385, val nll: -1.4341, val mse 0.0037, lr 0.000059049\n",
      "test nll: -1.4845, test mse: 0.0033\n",
      "saving.................\n",
      "done\n",
      "6601,6602,6603,6604,6605,6606,6607,6608,6609,6610,\tIter: 6610, train loss: -1.4131, avg nll: -1.4323, avg wnll: 36.1141, avg kl: 0.0002, mse: 0.003785, wmse: 0.031989, mae: 0.046937, val nll: -1.4563, val mse 0.0038, lr 0.000059049\n",
      "test nll: -1.3571, test mse: 0.0043\n",
      "6611,6612,6613,6614,6615,6616,6617,6618,6619,6620,\tIter: 6620, train loss: -1.4871, avg nll: -1.5041, avg wnll: 32.3912, avg kl: 0.0002, mse: 0.003366, wmse: 0.028200, mae: 0.043074, val nll: -1.5081, val mse 0.0034, lr 0.000059049\n",
      "test nll: -1.4833, test mse: 0.0035\n",
      "6621,6622,6623,6624,6625,6626,6627,6628,6629,6630,\tIter: 6630, train loss: -1.4377, avg nll: -1.4570, avg wnll: 34.9108, avg kl: 0.0002, mse: 0.003815, wmse: 0.032192, mae: 0.046092, val nll: -1.5152, val mse 0.0032, lr 0.000059049\n",
      "test nll: -1.4488, test mse: 0.0036\n",
      "6631,6632,6633,6634,6635,6636,6637,6638,6639,6640,\tIter: 6640, train loss: -1.4033, avg nll: -1.4224, avg wnll: 40.0210, avg kl: 0.0002, mse: 0.003774, wmse: 0.032285, mae: 0.045839, val nll: -1.3424, val mse 0.0042, lr 0.000059049\n",
      "test nll: -1.3721, test mse: 0.0042\n",
      "6641,6642,6643,6644,6645,6646,6647,6648,6649,6650,\tIter: 6650, train loss: -1.5062, avg nll: -1.5229, avg wnll: 33.7733, avg kl: 0.0002, mse: 0.003285, wmse: 0.027647, mae: 0.042816, val nll: -1.5294, val mse 0.0029, lr 0.000059049\n",
      "test nll: -1.4354, test mse: 0.0041\n",
      "6651,6652,6653,6654,6655,6656,6657,6658,6659,6660,\tIter: 6660, train loss: -1.4458, avg nll: -1.4643, avg wnll: 37.1716, avg kl: 0.0002, mse: 0.003670, wmse: 0.030640, mae: 0.045131, val nll: -1.4870, val mse 0.0035, lr 0.000059049\n",
      "test nll: -1.4730, test mse: 0.0038\n",
      "6661,6662,6663,6664,6665,6666,6667,6668,6669,6670,\tIter: 6670, train loss: -1.4804, avg nll: -1.4973, avg wnll: 33.8192, avg kl: 0.0002, mse: 0.003338, wmse: 0.028116, mae: 0.042986, val nll: -1.4665, val mse 0.0038, lr 0.000059049\n",
      "test nll: -1.5189, test mse: 0.0036\n",
      "6671,6672,6673,6674,6675,6676,6677,6678,6679,6680,\tIter: 6680, train loss: -1.4238, avg nll: -1.4426, avg wnll: 35.7209, avg kl: 0.0004, mse: 0.003684, wmse: 0.030754, mae: 0.046070, val nll: -1.5127, val mse 0.0036, lr 0.000059049\n",
      "test nll: -1.4438, test mse: 0.0035\n",
      "6681,6682,6683,6684,6685,6686,6687,6688,6689,6690,\tIter: 6690, train loss: -1.4356, avg nll: -1.4538, avg wnll: 36.0406, avg kl: 0.0003, mse: 0.003574, wmse: 0.030014, mae: 0.044556, val nll: -1.4993, val mse 0.0035, lr 0.000059049\n",
      "test nll: -1.4524, test mse: 0.0034\n",
      "6691,6692,6693,6694,6695,6696,6697,6698,6699,6700,\tIter: 6700, train loss: -1.5051, avg nll: -1.5216, avg wnll: 30.5229, avg kl: 0.0003, mse: 0.003242, wmse: 0.027453, mae: 0.041806, val nll: -1.4699, val mse 0.0036, lr 0.000059049\n",
      "test nll: -1.3800, test mse: 0.0041\n",
      "6701,6702,6703,6704,6705,6706,6707,6708,6709,6710,\tIter: 6710, train loss: -1.5414, avg nll: -1.5573, avg wnll: 31.5854, avg kl: 0.0002, mse: 0.003131, wmse: 0.026077, mae: 0.040739, val nll: -1.5236, val mse 0.0033, lr 0.000059049\n",
      "test nll: -1.4487, test mse: 0.0042\n",
      "6711,6712,6713,6714,6715,6716,6717,6718,6719,6720,\tIter: 6720, train loss: -1.4690, avg nll: -1.4863, avg wnll: 34.8036, avg kl: 0.0001, mse: 0.003421, wmse: 0.028607, mae: 0.044228, val nll: -1.3970, val mse 0.0041, lr 0.000059049\n",
      "test nll: -1.4870, test mse: 0.0036\n",
      "6721,6722,6723,6724,6725,6726,6727,6728,6729,6730,\tIter: 6730, train loss: -1.4390, avg nll: -1.4576, avg wnll: 37.9608, avg kl: 0.0001, mse: 0.003694, wmse: 0.030878, mae: 0.045262, val nll: -1.5426, val mse 0.0030, lr 0.000059049\n",
      "test nll: -1.5431, test mse: 0.0030\n",
      "6731,6732,6733,6734,6735,6736,6737,6738,6739,6740,\tIter: 6740, train loss: -1.5144, avg nll: -1.5309, avg wnll: 33.1106, avg kl: 0.0002, mse: 0.003261, wmse: 0.027528, mae: 0.041860, val nll: -1.5453, val mse 0.0032, lr 0.000059049\n",
      "test nll: -1.5097, test mse: 0.0034\n",
      "6741,6742,6743,6744,6745,6746,6747,6748,6749,6750,\tIter: 6750, train loss: -1.4361, avg nll: -1.4554, avg wnll: 38.2425, avg kl: 0.0002, mse: 0.003831, wmse: 0.032439, mae: 0.045794, val nll: -1.4433, val mse 0.0037, lr 0.000059049\n",
      "test nll: -1.3577, test mse: 0.0044\n",
      "6751,6752,6753,6754,6755,6756,6757,6758,6759,6760,\tIter: 6760, train loss: -1.5051, avg nll: -1.5217, avg wnll: 31.7518, avg kl: 0.0003, mse: 0.003258, wmse: 0.027612, mae: 0.042987, val nll: -1.5000, val mse 0.0035, lr 0.000059049\n",
      "test nll: -1.4864, test mse: 0.0031\n",
      "6761,6762,6763,6764,6765,6766,6767,6768,6769,6770,\tIter: 6770, train loss: -1.4318, avg nll: -1.4514, avg wnll: 34.7335, avg kl: 0.0003, mse: 0.003860, wmse: 0.032555, mae: 0.046633, val nll: -1.5023, val mse 0.0031, lr 0.000059049\n",
      "test nll: -1.4814, test mse: 0.0036\n",
      "6771,6772,6773,6774,6775,6776,6777,6778,6779,6780,\tIter: 6780, train loss: -1.3804, avg nll: -1.4009, avg wnll: 38.7661, avg kl: 0.0003, mse: 0.004031, wmse: 0.034067, mae: 0.047578, val nll: -1.4546, val mse 0.0037, lr 0.000059049\n",
      "test nll: -1.4770, test mse: 0.0037\n",
      "6781,6782,6783,6784,6785,6786,6787,6788,6789,6790,\tIter: 6790, train loss: -1.4322, avg nll: -1.4513, avg wnll: 35.2890, avg kl: 0.0004, mse: 0.003745, wmse: 0.031603, mae: 0.046124, val nll: -1.4627, val mse 0.0034, lr 0.000059049\n",
      "test nll: -1.4554, test mse: 0.0040\n",
      "6791,6792,6793,6794,6795,6796,6797,6798,6799,6800,\tIter: 6800, train loss: -1.4857, avg nll: -1.5033, avg wnll: 35.1588, avg kl: 0.0002, mse: 0.003483, wmse: 0.029541, mae: 0.043589, val nll: -1.5548, val mse 0.0030, lr 0.000059049\n",
      "test nll: -1.4488, test mse: 0.0038\n",
      "saving.................\n",
      "done\n",
      "6801,6802,6803,6804,6805,6806,6807,6808,6809,6810,\tIter: 6810, train loss: -1.4090, avg nll: -1.4297, avg wnll: 35.9795, avg kl: 0.0002, mse: 0.004103, wmse: 0.034172, mae: 0.046497, val nll: -1.4528, val mse 0.0037, lr 0.000059049\n",
      "test nll: -1.4586, test mse: 0.0041\n",
      "6811,6812,6813,6814,6815,6816,6817,6818,6819,6820,\tIter: 6820, train loss: -1.4272, avg nll: -1.4465, avg wnll: 35.9219, avg kl: 0.0002, mse: 0.003814, wmse: 0.031970, mae: 0.044672, val nll: -1.4780, val mse 0.0035, lr 0.000059049\n",
      "test nll: -1.4886, test mse: 0.0036\n",
      "6821,6822,6823,6824,6825,6826,6827,6828,6829,6830,\tIter: 6830, train loss: -1.4799, avg nll: -1.4983, avg wnll: 32.3500, avg kl: 0.0001, mse: 0.003656, wmse: 0.031087, mae: 0.044485, val nll: -1.5425, val mse 0.0028, lr 0.000059049\n",
      "test nll: -1.4388, test mse: 0.0040\n",
      "6831,6832,6833,6834,6835,6836,6837,6838,6839,6840,\tIter: 6840, train loss: -1.4585, avg nll: -1.4758, avg wnll: 33.7726, avg kl: 0.0003, mse: 0.003402, wmse: 0.028227, mae: 0.043957, val nll: -1.5216, val mse 0.0033, lr 0.000059049\n",
      "test nll: -1.3885, test mse: 0.0044\n",
      "6841,6842,6843,6844,6845,6846,6847,6848,6849,6850,\tIter: 6850, train loss: -1.4727, avg nll: -1.4910, avg wnll: 33.4608, avg kl: 0.0002, mse: 0.003621, wmse: 0.030776, mae: 0.043383, val nll: -1.4317, val mse 0.0039, lr 0.000059049\n",
      "test nll: -1.4262, test mse: 0.0042\n",
      "6851,6852,6853,6854,6855,6856,6857,6858,6859,6860,\tIter: 6860, train loss: -1.5083, avg nll: -1.5246, avg wnll: 32.1915, avg kl: 0.0001, mse: 0.003230, wmse: 0.027101, mae: 0.041176, val nll: -1.4981, val mse 0.0034, lr 0.000059049\n",
      "test nll: -1.5027, test mse: 0.0036\n",
      "6861,6862,6863,6864,6865,6866,6867,6868,6869,6870,\tIter: 6870, train loss: -1.4702, avg nll: -1.4883, avg wnll: 36.0161, avg kl: 0.0001, mse: 0.003592, wmse: 0.030149, mae: 0.043214, val nll: -1.3724, val mse 0.0043, lr 0.000059049\n",
      "test nll: -1.4624, test mse: 0.0039\n",
      "6871,6872,6873,6874,6875,6876,6877,6878,6879,6880,\tIter: 6880, train loss: -1.5169, avg nll: -1.5331, avg wnll: 33.6224, avg kl: 0.0001, mse: 0.003200, wmse: 0.027051, mae: 0.042325, val nll: -1.5470, val mse 0.0032, lr 0.000059049\n",
      "test nll: -1.4504, test mse: 0.0040\n",
      "6881,6882,6883,6884,6885,6886,6887,6888,6889,6890,\tIter: 6890, train loss: -1.4179, avg nll: -1.4360, avg wnll: 36.9817, avg kl: 0.0005, mse: 0.003514, wmse: 0.029342, mae: 0.044887, val nll: -1.4744, val mse 0.0038, lr 0.000059049\n",
      "test nll: -1.4721, test mse: 0.0035\n",
      "6891,6892,6893,6894,6895,6896,6897,6898,6899,6900,\tIter: 6900, train loss: -1.4709, avg nll: -1.4872, avg wnll: 32.6520, avg kl: 0.0004, mse: 0.003181, wmse: 0.026551, mae: 0.042146, val nll: -1.4744, val mse 0.0035, lr 0.000059049\n",
      "test nll: -1.4683, test mse: 0.0036\n",
      "6901,6902,6903,6904,6905,6906,6907,6908,6909,6910,\tIter: 6910, train loss: -1.4996, avg nll: -1.5170, avg wnll: 33.3300, avg kl: 0.0002, mse: 0.003450, wmse: 0.028696, mae: 0.042613, val nll: -1.4933, val mse 0.0036, lr 0.000059049\n",
      "test nll: -1.5618, test mse: 0.0030\n",
      "6911,6912,6913,6914,6915,6916,6917,6918,6919,6920,\tIter: 6920, train loss: -1.4553, avg nll: -1.4735, avg wnll: 33.7697, avg kl: 0.0002, mse: 0.003583, wmse: 0.029972, mae: 0.044279, val nll: -1.5373, val mse 0.0029, lr 0.000059049\n",
      "test nll: -1.4537, test mse: 0.0039\n",
      "6921,6922,6923,6924,6925,6926,6927,6928,6929,6930,\tIter: 6930, train loss: -1.5087, avg nll: -1.5249, avg wnll: 33.6221, avg kl: 0.0002, mse: 0.003203, wmse: 0.026627, mae: 0.040971, val nll: -1.5123, val mse 0.0029, lr 0.000059049\n",
      "test nll: -1.4541, test mse: 0.0039\n",
      "6931,6932,6933,6934,6935,6936,6937,6938,6939,6940,\tIter: 6940, train loss: -1.5162, avg nll: -1.5319, avg wnll: 30.3642, avg kl: 0.0002, mse: 0.003100, wmse: 0.025921, mae: 0.042047, val nll: -1.5078, val mse 0.0032, lr 0.000059049\n",
      "test nll: -1.5031, test mse: 0.0032\n",
      "6941,6942,6943,6944,6945,6946,6947,6948,6949,6950,\tIter: 6950, train loss: -1.4808, avg nll: -1.4975, avg wnll: 33.2818, avg kl: 0.0003, mse: 0.003289, wmse: 0.027855, mae: 0.042844, val nll: -1.4147, val mse 0.0040, lr 0.000059049\n",
      "test nll: -1.4610, test mse: 0.0039\n",
      "6951,6952,6953,6954,6955,6956,6957,6958,6959,6960,\tIter: 6960, train loss: -1.5061, avg nll: -1.5232, avg wnll: 33.0565, avg kl: 0.0002, mse: 0.003383, wmse: 0.028349, mae: 0.042263, val nll: -1.5002, val mse 0.0037, lr 0.000059049\n",
      "test nll: -1.3939, test mse: 0.0044\n",
      "6961,6962,6963,6964,6965,6966,6967,6968,6969,6970,\tIter: 6970, train loss: -1.5003, avg nll: -1.5166, avg wnll: 32.7063, avg kl: 0.0002, mse: 0.003242, wmse: 0.027121, mae: 0.041705, val nll: -1.4086, val mse 0.0039, lr 0.000059049\n",
      "test nll: -1.6012, test mse: 0.0027\n",
      "6971,6972,6973,6974,6975,6976,6977,6978,6979,6980,\tIter: 6980, train loss: -1.5029, avg nll: -1.5202, avg wnll: 32.1397, avg kl: 0.0003, mse: 0.003409, wmse: 0.028270, mae: 0.042122, val nll: -1.4303, val mse 0.0039, lr 0.000059049\n",
      "test nll: -1.4809, test mse: 0.0037\n",
      "6981,6982,6983,6984,6985,6986,6987,6988,6989,6990,\tIter: 6990, train loss: -1.4948, avg nll: -1.5114, avg wnll: 31.7483, avg kl: 0.0002, mse: 0.003269, wmse: 0.027136, mae: 0.041551, val nll: -1.4836, val mse 0.0036, lr 0.000059049\n",
      "test nll: -1.4754, test mse: 0.0036\n",
      "6991,6992,6993,6994,6995,6996,6997,6998,6999,7000,\tIter: 7000, train loss: -1.4369, avg nll: -1.4567, avg wnll: 37.7365, avg kl: 0.0003, mse: 0.003885, wmse: 0.032535, mae: 0.046028, val nll: -1.5123, val mse 0.0034, lr 0.000059049\n",
      "test nll: -1.3796, test mse: 0.0045\n",
      "saving.................\n",
      "done\n",
      "7001,7002,7003,7004,7005,7006,7007,7008,7009,7010,\tIter: 7010, train loss: -1.5122, avg nll: -1.5284, avg wnll: 29.6484, avg kl: 0.0003, mse: 0.003173, wmse: 0.026581, mae: 0.041603, val nll: -1.5007, val mse 0.0034, lr 0.000053144\n",
      "test nll: -1.4309, test mse: 0.0038\n",
      "7011,7012,7013,7014,7015,7016,7017,7018,7019,7020,\tIter: 7020, train loss: -1.4768, avg nll: -1.4945, avg wnll: 34.4030, avg kl: 0.0003, mse: 0.003476, wmse: 0.029162, mae: 0.043070, val nll: -1.5750, val mse 0.0030, lr 0.000053144\n",
      "test nll: -1.4641, test mse: 0.0036\n",
      "7021,7022,7023,7024,7025,7026,7027,7028,7029,7030,\tIter: 7030, train loss: -1.4461, avg nll: -1.4646, avg wnll: 35.0351, avg kl: 0.0001, mse: 0.003681, wmse: 0.030970, mae: 0.044701, val nll: -1.4312, val mse 0.0039, lr 0.000053144\n",
      "test nll: -1.4339, test mse: 0.0040\n",
      "7031,7032,7033,7034,7035,7036,7037,7038,7039,7040,\tIter: 7040, train loss: -1.5143, avg nll: -1.5304, avg wnll: 35.7224, avg kl: 0.0001, mse: 0.003204, wmse: 0.027080, mae: 0.041710, val nll: -1.5661, val mse 0.0030, lr 0.000053144\n",
      "test nll: -1.5321, test mse: 0.0028\n",
      "7041,7042,7043,7044,7045,7046,7047,7048,7049,7050,\tIter: 7050, train loss: -1.5108, avg nll: -1.5268, avg wnll: 33.8714, avg kl: 0.0002, mse: 0.003164, wmse: 0.026213, mae: 0.042078, val nll: -1.3669, val mse 0.0040, lr 0.000053144\n",
      "test nll: -1.3913, test mse: 0.0042\n",
      "7051,7052,7053,7054,7055,7056,7057,7058,7059,7060,\tIter: 7060, train loss: -1.5191, avg nll: -1.5352, avg wnll: 31.1671, avg kl: 0.0002, mse: 0.003185, wmse: 0.026902, mae: 0.042171, val nll: -1.4489, val mse 0.0037, lr 0.000053144\n",
      "test nll: -1.4849, test mse: 0.0034\n",
      "7061,7062,7063,7064,7065,7066,7067,7068,7069,7070,\tIter: 7070, train loss: -1.4414, avg nll: -1.4610, avg wnll: 34.3497, avg kl: 0.0002, mse: 0.003873, wmse: 0.032163, mae: 0.045030, val nll: -1.5933, val mse 0.0029, lr 0.000053144\n",
      "test nll: -1.3792, test mse: 0.0040\n",
      "7071,7072,7073,7074,7075,7076,7077,7078,7079,7080,\tIter: 7080, train loss: -1.4862, avg nll: -1.5039, avg wnll: 33.4959, avg kl: 0.0002, mse: 0.003501, wmse: 0.029180, mae: 0.042205, val nll: -1.5605, val mse 0.0031, lr 0.000053144\n",
      "test nll: -1.4668, test mse: 0.0040\n",
      "7081,7082,7083,7084,7085,7086,7087,7088,7089,7090,\tIter: 7090, train loss: -1.4595, avg nll: -1.4776, avg wnll: 35.9608, avg kl: 0.0001, mse: 0.003605, wmse: 0.030388, mae: 0.043610, val nll: -1.5043, val mse 0.0032, lr 0.000053144\n",
      "test nll: -1.4643, test mse: 0.0039\n",
      "7091,7092,7093,7094,7095,7096,7097,7098,7099,7100,\tIter: 7100, train loss: -1.4953, avg nll: -1.5127, avg wnll: 31.7076, avg kl: 0.0003, mse: 0.003418, wmse: 0.028497, mae: 0.042577, val nll: -1.5194, val mse 0.0030, lr 0.000053144\n",
      "test nll: -1.3988, test mse: 0.0041\n",
      "7101,7102,7103,7104,7105,7106,7107,7108,7109,7110,\tIter: 7110, train loss: -1.4982, avg nll: -1.5154, avg wnll: 32.7308, avg kl: 0.0002, mse: 0.003406, wmse: 0.028243, mae: 0.042829, val nll: -1.6231, val mse 0.0027, lr 0.000053144\n",
      "test nll: -1.4643, test mse: 0.0041\n",
      "7111,7112,7113,7114,7115,7116,7117,7118,7119,7120,\tIter: 7120, train loss: -1.4841, avg nll: -1.5012, avg wnll: 33.2121, avg kl: 0.0002, mse: 0.003391, wmse: 0.028471, mae: 0.043389, val nll: -1.4606, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4558, test mse: 0.0035\n",
      "7121,7122,7123,7124,7125,7126,7127,7128,7129,7130,\tIter: 7130, train loss: -1.4144, avg nll: -1.4337, avg wnll: 30.4399, avg kl: 0.0006, mse: 0.003718, wmse: 0.031334, mae: 0.045991, val nll: -1.3779, val mse 0.0043, lr 0.000053144\n",
      "test nll: -1.2641, test mse: 0.0053\n",
      "7131,7132,7133,7134,7135,7136,7137,7138,7139,7140,\tIter: 7140, train loss: -1.4133, avg nll: -1.4329, avg wnll: 36.8841, avg kl: 0.0003, mse: 0.003861, wmse: 0.032393, mae: 0.046051, val nll: -1.3987, val mse 0.0039, lr 0.000053144\n",
      "test nll: -1.3514, test mse: 0.0044\n",
      "7141,7142,7143,7144,7145,7146,7147,7148,7149,7150,\tIter: 7150, train loss: -1.4687, avg nll: -1.4863, avg wnll: 33.4909, avg kl: 0.0002, mse: 0.003490, wmse: 0.029221, mae: 0.044082, val nll: -1.4589, val mse 0.0037, lr 0.000053144\n",
      "test nll: -1.4932, test mse: 0.0035\n",
      "7151,7152,7153,7154,7155,7156,7157,7158,7159,7160,\tIter: 7160, train loss: -1.4290, avg nll: -1.4473, avg wnll: 35.9920, avg kl: 0.0002, mse: 0.003633, wmse: 0.030052, mae: 0.044800, val nll: -1.4898, val mse 0.0037, lr 0.000053144\n",
      "test nll: -1.4857, test mse: 0.0036\n",
      "7161,7162,7163,7164,7165,7166,7167,7168,7169,7170,\tIter: 7170, train loss: -1.4775, avg nll: -1.4946, avg wnll: 33.9897, avg kl: 0.0001, mse: 0.003399, wmse: 0.028501, mae: 0.042043, val nll: -1.5159, val mse 0.0031, lr 0.000053144\n",
      "test nll: -1.4727, test mse: 0.0037\n",
      "7171,7172,7173,7174,7175,7176,7177,7178,7179,7180,\tIter: 7180, train loss: -1.4792, avg nll: -1.4973, avg wnll: 33.6971, avg kl: 0.0002, mse: 0.003586, wmse: 0.030279, mae: 0.043729, val nll: -1.5004, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4757, test mse: 0.0039\n",
      "7181,7182,7183,7184,7185,7186,7187,7188,7189,7190,\tIter: 7190, train loss: -1.4804, avg nll: -1.4972, avg wnll: 33.8034, avg kl: 0.0002, mse: 0.003330, wmse: 0.028020, mae: 0.043118, val nll: -1.4211, val mse 0.0038, lr 0.000053144\n",
      "test nll: -1.4117, test mse: 0.0042\n",
      "7191,7192,7193,7194,7195,7196,7197,7198,7199,7200,\tIter: 7200, train loss: -1.4848, avg nll: -1.5022, avg wnll: 32.3637, avg kl: 0.0002, mse: 0.003433, wmse: 0.028333, mae: 0.042732, val nll: -1.6012, val mse 0.0024, lr 0.000053144\n",
      "test nll: -1.4730, test mse: 0.0034\n",
      "saving.................\n",
      "done\n",
      "7201,7202,7203,7204,7205,7206,7207,7208,7209,7210,\tIter: 7210, train loss: -1.5063, avg nll: -1.5238, avg wnll: 34.0813, avg kl: 0.0002, mse: 0.003468, wmse: 0.029539, mae: 0.042354, val nll: -1.4985, val mse 0.0034, lr 0.000053144\n",
      "test nll: -1.5066, test mse: 0.0032\n",
      "7211,7212,7213,7214,7215,7216,7217,7218,7219,7220,\tIter: 7220, train loss: -1.4849, avg nll: -1.5017, avg wnll: 33.7577, avg kl: 0.0002, mse: 0.003340, wmse: 0.028372, mae: 0.043615, val nll: -1.5787, val mse 0.0026, lr 0.000053144\n",
      "test nll: -1.4749, test mse: 0.0035\n",
      "7221,7222,7223,7224,7225,7226,7227,7228,7229,7230,\tIter: 7230, train loss: -1.4734, avg nll: -1.4906, avg wnll: 34.9900, avg kl: 0.0003, mse: 0.003380, wmse: 0.028822, mae: 0.043772, val nll: -1.4256, val mse 0.0037, lr 0.000053144\n",
      "test nll: -1.4435, test mse: 0.0036\n",
      "7231,7232,7233,7234,7235,7236,7237,7238,7239,7240,\tIter: 7240, train loss: -1.5049, avg nll: -1.5214, avg wnll: 29.8770, avg kl: 0.0003, mse: 0.003227, wmse: 0.026758, mae: 0.041750, val nll: -1.4788, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.5064, test mse: 0.0033\n",
      "7241,7242,7243,7244,7245,7246,7247,7248,7249,7250,\tIter: 7250, train loss: -1.4775, avg nll: -1.4945, avg wnll: 32.9212, avg kl: 0.0002, mse: 0.003362, wmse: 0.028121, mae: 0.042750, val nll: -1.5092, val mse 0.0032, lr 0.000053144\n",
      "test nll: -1.4335, test mse: 0.0037\n",
      "7251,7252,7253,7254,7255,7256,7257,7258,7259,7260,\tIter: 7260, train loss: -1.4125, avg nll: -1.4313, avg wnll: 38.8307, avg kl: 0.0002, mse: 0.003730, wmse: 0.031153, mae: 0.044936, val nll: -1.4386, val mse 0.0038, lr 0.000053144\n",
      "test nll: -1.2868, test mse: 0.0051\n",
      "7261,7262,7263,7264,7265,7266,7267,7268,7269,7270,\tIter: 7270, train loss: -1.4930, avg nll: -1.5103, avg wnll: 31.5760, avg kl: 0.0002, mse: 0.003412, wmse: 0.028604, mae: 0.042676, val nll: -1.3902, val mse 0.0039, lr 0.000053144\n",
      "test nll: -1.4750, test mse: 0.0031\n",
      "7271,7272,7273,7274,7275,7276,7277,7278,7279,7280,\tIter: 7280, train loss: -1.5193, avg nll: -1.5357, avg wnll: 32.3722, avg kl: 0.0002, mse: 0.003230, wmse: 0.026919, mae: 0.041621, val nll: -1.5439, val mse 0.0028, lr 0.000053144\n",
      "test nll: -1.4512, test mse: 0.0043\n",
      "7281,7282,7283,7284,7285,7286,7287,7288,7289,7290,\tIter: 7290, train loss: -1.4643, avg nll: -1.4818, avg wnll: 35.4537, avg kl: 0.0002, mse: 0.003449, wmse: 0.029019, mae: 0.044019, val nll: -1.5179, val mse 0.0028, lr 0.000053144\n",
      "test nll: -1.4771, test mse: 0.0038\n",
      "7291,7292,7293,7294,7295,7296,7297,7298,7299,7300,\tIter: 7300, train loss: -1.4919, avg nll: -1.5084, avg wnll: 32.9270, avg kl: 0.0002, mse: 0.003248, wmse: 0.027070, mae: 0.043267, val nll: -1.4019, val mse 0.0038, lr 0.000053144\n",
      "test nll: -1.4651, test mse: 0.0037\n",
      "7301,7302,7303,7304,7305,7306,7307,7308,7309,7310,\tIter: 7310, train loss: -1.4818, avg nll: -1.4987, avg wnll: 33.8068, avg kl: 0.0001, mse: 0.003364, wmse: 0.028203, mae: 0.043431, val nll: -1.4447, val mse 0.0041, lr 0.000053144\n",
      "test nll: -1.3752, test mse: 0.0041\n",
      "7311,7312,7313,7314,7315,7316,7317,7318,7319,7320,\tIter: 7320, train loss: -1.4834, avg nll: -1.5008, avg wnll: 34.1902, avg kl: 0.0001, mse: 0.003442, wmse: 0.029062, mae: 0.043045, val nll: -1.4164, val mse 0.0036, lr 0.000053144\n",
      "test nll: -1.4094, test mse: 0.0044\n",
      "7321,7322,7323,7324,7325,7326,7327,7328,7329,7330,\tIter: 7330, train loss: -1.4614, avg nll: -1.4794, avg wnll: 35.1883, avg kl: 0.0003, mse: 0.003544, wmse: 0.029848, mae: 0.044404, val nll: -1.4263, val mse 0.0039, lr 0.000053144\n",
      "test nll: -1.3854, test mse: 0.0039\n",
      "7331,7332,7333,7334,7335,7336,7337,7338,7339,7340,\tIter: 7340, train loss: -1.4709, avg nll: -1.4886, avg wnll: 35.7595, avg kl: 0.0005, mse: 0.003455, wmse: 0.029450, mae: 0.043089, val nll: -1.3401, val mse 0.0043, lr 0.000053144\n",
      "test nll: -1.4842, test mse: 0.0033\n",
      "7341,7342,7343,7344,7345,7346,7347,7348,7349,7350,\tIter: 7350, train loss: -1.5097, avg nll: -1.5260, avg wnll: 32.9181, avg kl: 0.0002, mse: 0.003233, wmse: 0.027565, mae: 0.042311, val nll: -1.4978, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.5073, test mse: 0.0034\n",
      "7351,7352,7353,7354,7355,7356,7357,7358,7359,7360,\tIter: 7360, train loss: -1.4899, avg nll: -1.5073, avg wnll: 34.9254, avg kl: 0.0001, mse: 0.003437, wmse: 0.028901, mae: 0.042908, val nll: -1.5402, val mse 0.0028, lr 0.000053144\n",
      "test nll: -1.4900, test mse: 0.0041\n",
      "7361,7362,7363,7364,7365,7366,7367,7368,7369,7370,\tIter: 7370, train loss: -1.4863, avg nll: -1.5036, avg wnll: 34.2890, avg kl: 0.0001, mse: 0.003437, wmse: 0.028876, mae: 0.043200, val nll: -1.4775, val mse 0.0034, lr 0.000053144\n",
      "test nll: -1.5165, test mse: 0.0034\n",
      "7371,7372,7373,7374,7375,7376,7377,7378,7379,7380,\tIter: 7380, train loss: -1.4645, avg nll: -1.4824, avg wnll: 37.4492, avg kl: 0.0001, mse: 0.003560, wmse: 0.029733, mae: 0.043970, val nll: -1.5610, val mse 0.0028, lr 0.000053144\n",
      "test nll: -1.4753, test mse: 0.0037\n",
      "7381,7382,7383,7384,7385,7386,7387,7388,7389,7390,\tIter: 7390, train loss: -1.4903, avg nll: -1.5076, avg wnll: 35.2755, avg kl: 0.0002, mse: 0.003421, wmse: 0.028666, mae: 0.042767, val nll: -1.4580, val mse 0.0033, lr 0.000053144\n",
      "test nll: -1.4532, test mse: 0.0038\n",
      "7391,7392,7393,7394,7395,7396,7397,7398,7399,7400,\tIter: 7400, train loss: -1.4949, avg nll: -1.5122, avg wnll: 34.2788, avg kl: 0.0002, mse: 0.003417, wmse: 0.028732, mae: 0.042026, val nll: -1.5220, val mse 0.0031, lr 0.000053144\n",
      "test nll: -1.4325, test mse: 0.0041\n",
      "saving.................\n",
      "done\n",
      "7401,7402,7403,7404,7405,7406,7407,7408,7409,7410,\tIter: 7410, train loss: -1.5244, avg nll: -1.5392, avg wnll: 32.5711, avg kl: 0.0002, mse: 0.002935, wmse: 0.025158, mae: 0.040679, val nll: -1.5032, val mse 0.0033, lr 0.000053144\n",
      "test nll: -1.4496, test mse: 0.0041\n",
      "7411,7412,7413,7414,7415,7416,7417,7418,7419,7420,\tIter: 7420, train loss: -1.4754, avg nll: -1.4926, avg wnll: 33.9517, avg kl: 0.0002, mse: 0.003417, wmse: 0.028598, mae: 0.042894, val nll: -1.3816, val mse 0.0044, lr 0.000053144\n",
      "test nll: -1.4218, test mse: 0.0042\n",
      "7421,7422,7423,7424,7425,7426,7427,7428,7429,7430,\tIter: 7430, train loss: -1.4873, avg nll: -1.5047, avg wnll: 32.2908, avg kl: 0.0004, mse: 0.003411, wmse: 0.028471, mae: 0.042512, val nll: -1.4984, val mse 0.0033, lr 0.000053144\n",
      "test nll: -1.4408, test mse: 0.0039\n",
      "7431,7432,7433,7434,7435,7436,7437,7438,7439,7440,\tIter: 7440, train loss: -1.4531, avg nll: -1.4706, avg wnll: 37.3027, avg kl: 0.0002, mse: 0.003462, wmse: 0.029126, mae: 0.044454, val nll: -1.5638, val mse 0.0029, lr 0.000053144\n",
      "test nll: -1.4605, test mse: 0.0033\n",
      "7441,7442,7443,7444,7445,7446,7447,7448,7449,7450,\tIter: 7450, train loss: -1.4467, avg nll: -1.4650, avg wnll: 37.0760, avg kl: 0.0002, mse: 0.003628, wmse: 0.030437, mae: 0.044802, val nll: -1.5658, val mse 0.0025, lr 0.000053144\n",
      "test nll: -1.4083, test mse: 0.0039\n",
      "7451,7452,7453,7454,7455,7456,7457,7458,7459,7460,\tIter: 7460, train loss: -1.4611, avg nll: -1.4799, avg wnll: 33.9950, avg kl: 0.0003, mse: 0.003698, wmse: 0.031090, mae: 0.044795, val nll: -1.5008, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4890, test mse: 0.0034\n",
      "7461,7462,7463,7464,7465,7466,7467,7468,7469,7470,\tIter: 7470, train loss: -1.4287, avg nll: -1.4479, avg wnll: 38.4210, avg kl: 0.0002, mse: 0.003802, wmse: 0.031756, mae: 0.045488, val nll: -1.4940, val mse 0.0034, lr 0.000053144\n",
      "test nll: -1.4136, test mse: 0.0041\n",
      "7471,7472,7473,7474,7475,7476,7477,7478,7479,7480,\tIter: 7480, train loss: -1.5049, avg nll: -1.5215, avg wnll: 34.4072, avg kl: 0.0002, mse: 0.003297, wmse: 0.028022, mae: 0.042977, val nll: -1.4575, val mse 0.0036, lr 0.000053144\n",
      "test nll: -1.4710, test mse: 0.0036\n",
      "7481,7482,7483,7484,7485,7486,7487,7488,7489,7490,\tIter: 7490, train loss: -1.4301, avg nll: -1.4493, avg wnll: 38.2742, avg kl: 0.0002, mse: 0.003816, wmse: 0.031787, mae: 0.044975, val nll: -1.4817, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4848, test mse: 0.0032\n",
      "7491,7492,7493,7494,7495,7496,7497,7498,7499,7500,\tIter: 7500, train loss: -1.4603, avg nll: -1.4779, avg wnll: 35.9930, avg kl: 0.0002, mse: 0.003473, wmse: 0.029350, mae: 0.044134, val nll: -1.3312, val mse 0.0043, lr 0.000053144\n",
      "test nll: -1.4112, test mse: 0.0044\n",
      "7501,7502,7503,7504,7505,7506,7507,7508,7509,7510,\tIter: 7510, train loss: -1.4744, avg nll: -1.4928, avg wnll: 33.6089, avg kl: 0.0004, mse: 0.003591, wmse: 0.029813, mae: 0.043156, val nll: -1.5295, val mse 0.0030, lr 0.000053144\n",
      "test nll: -1.4691, test mse: 0.0037\n",
      "7511,7512,7513,7514,7515,7516,7517,7518,7519,7520,\tIter: 7520, train loss: -1.4903, avg nll: -1.5079, avg wnll: 34.1144, avg kl: 0.0003, mse: 0.003451, wmse: 0.028944, mae: 0.043094, val nll: -1.5175, val mse 0.0036, lr 0.000053144\n",
      "test nll: -1.3965, test mse: 0.0040\n",
      "7521,7522,7523,7524,7525,7526,7527,7528,7529,7530,\tIter: 7530, train loss: -1.4676, avg nll: -1.4853, avg wnll: 33.3617, avg kl: 0.0003, mse: 0.003472, wmse: 0.029193, mae: 0.043655, val nll: -1.5580, val mse 0.0026, lr 0.000053144\n",
      "test nll: -1.3947, test mse: 0.0043\n",
      "7531,7532,7533,7534,7535,7536,7537,7538,7539,7540,\tIter: 7540, train loss: -1.4607, avg nll: -1.4787, avg wnll: 36.2373, avg kl: 0.0002, mse: 0.003547, wmse: 0.029551, mae: 0.043986, val nll: -1.4466, val mse 0.0038, lr 0.000053144\n",
      "test nll: -1.4440, test mse: 0.0036\n",
      "7541,7542,7543,7544,7545,7546,7547,7548,7549,7550,\tIter: 7550, train loss: -1.4615, avg nll: -1.4788, avg wnll: 34.9702, avg kl: 0.0002, mse: 0.003438, wmse: 0.028665, mae: 0.043733, val nll: -1.4254, val mse 0.0034, lr 0.000053144\n",
      "test nll: -1.4296, test mse: 0.0038\n",
      "7551,7552,7553,7554,7555,7556,7557,7558,7559,7560,\tIter: 7560, train loss: -1.4720, avg nll: -1.4898, avg wnll: 35.7019, avg kl: 0.0002, mse: 0.003523, wmse: 0.029755, mae: 0.043936, val nll: -1.4353, val mse 0.0038, lr 0.000053144\n",
      "test nll: -1.4572, test mse: 0.0037\n",
      "7561,7562,7563,7564,7565,7566,7567,7568,7569,7570,\tIter: 7570, train loss: -1.4844, avg nll: -1.5020, avg wnll: 34.4605, avg kl: 0.0002, mse: 0.003490, wmse: 0.029470, mae: 0.043782, val nll: -1.5117, val mse 0.0031, lr 0.000053144\n",
      "test nll: -1.5216, test mse: 0.0033\n",
      "7571,7572,7573,7574,7575,7576,7577,7578,7579,7580,\tIter: 7580, train loss: -1.4956, avg nll: -1.5133, avg wnll: 34.7656, avg kl: 0.0001, mse: 0.003514, wmse: 0.029773, mae: 0.043567, val nll: -1.5409, val mse 0.0032, lr 0.000053144\n",
      "test nll: -1.4705, test mse: 0.0039\n",
      "7581,7582,7583,7584,7585,7586,7587,7588,7589,7590,\tIter: 7590, train loss: -1.4596, avg nll: -1.4779, avg wnll: 35.8038, avg kl: 0.0001, mse: 0.003625, wmse: 0.030335, mae: 0.044205, val nll: -1.5461, val mse 0.0031, lr 0.000053144\n",
      "test nll: -1.4546, test mse: 0.0039\n",
      "7591,7592,7593,7594,7595,7596,7597,7598,7599,7600,\tIter: 7600, train loss: -1.4657, avg nll: -1.4842, avg wnll: 34.1441, avg kl: 0.0002, mse: 0.003668, wmse: 0.030526, mae: 0.044532, val nll: -1.5113, val mse 0.0037, lr 0.000053144\n",
      "test nll: -1.5273, test mse: 0.0030\n",
      "saving.................\n",
      "done\n",
      "7601,7602,7603,7604,7605,7606,7607,7608,7609,7610,\tIter: 7610, train loss: -1.4892, avg nll: -1.5060, avg wnll: 34.1610, avg kl: 0.0002, mse: 0.003314, wmse: 0.027956, mae: 0.042978, val nll: -1.4851, val mse 0.0034, lr 0.000053144\n",
      "test nll: -1.3981, test mse: 0.0046\n",
      "7611,7612,7613,7614,7615,7616,7617,7618,7619,7620,\tIter: 7620, train loss: -1.4803, avg nll: -1.4981, avg wnll: 33.5875, avg kl: 0.0002, mse: 0.003504, wmse: 0.029330, mae: 0.042703, val nll: -1.4782, val mse 0.0039, lr 0.000053144\n",
      "test nll: -1.5078, test mse: 0.0036\n",
      "7621,7622,7623,7624,7625,7626,7627,7628,7629,7630,\tIter: 7630, train loss: -1.4518, avg nll: -1.4702, avg wnll: 35.1299, avg kl: 0.0002, mse: 0.003648, wmse: 0.030610, mae: 0.044729, val nll: -1.4785, val mse 0.0033, lr 0.000053144\n",
      "test nll: -1.4488, test mse: 0.0035\n",
      "7631,7632,7633,7634,7635,7636,7637,7638,7639,7640,\tIter: 7640, train loss: -1.4492, avg nll: -1.4679, avg wnll: 34.4563, avg kl: 0.0003, mse: 0.003678, wmse: 0.031142, mae: 0.045251, val nll: -1.4695, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4836, test mse: 0.0033\n",
      "7641,7642,7643,7644,7645,7646,7647,7648,7649,7650,\tIter: 7650, train loss: -1.4171, avg nll: -1.4364, avg wnll: 36.2287, avg kl: 0.0003, mse: 0.003809, wmse: 0.032177, mae: 0.045707, val nll: -1.4829, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4196, test mse: 0.0045\n",
      "7651,7652,7653,7654,7655,7656,7657,7658,7659,7660,\tIter: 7660, train loss: -1.4682, avg nll: -1.4861, avg wnll: 32.5861, avg kl: 0.0003, mse: 0.003528, wmse: 0.029510, mae: 0.044256, val nll: -1.4779, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.3869, test mse: 0.0039\n",
      "7661,7662,7663,7664,7665,7666,7667,7668,7669,7670,\tIter: 7670, train loss: -1.4715, avg nll: -1.4889, avg wnll: 35.2229, avg kl: 0.0003, mse: 0.003434, wmse: 0.029220, mae: 0.044241, val nll: -1.4490, val mse 0.0036, lr 0.000053144\n",
      "test nll: -1.4894, test mse: 0.0036\n",
      "7671,7672,7673,7674,7675,7676,7677,7678,7679,7680,\tIter: 7680, train loss: -1.4368, avg nll: -1.4554, avg wnll: 37.0778, avg kl: 0.0002, mse: 0.003704, wmse: 0.031575, mae: 0.045544, val nll: -1.4320, val mse 0.0040, lr 0.000053144\n",
      "test nll: -1.4703, test mse: 0.0037\n",
      "7681,7682,7683,7684,7685,7686,7687,7688,7689,7690,\tIter: 7690, train loss: -1.4328, avg nll: -1.4511, avg wnll: 35.6689, avg kl: 0.0002, mse: 0.003629, wmse: 0.030208, mae: 0.044673, val nll: -1.4019, val mse 0.0039, lr 0.000053144\n",
      "test nll: -1.3993, test mse: 0.0037\n",
      "7691,7692,7693,7694,7695,7696,7697,7698,7699,7700,\tIter: 7700, train loss: -1.4559, avg nll: -1.4734, avg wnll: 35.0660, avg kl: 0.0002, mse: 0.003445, wmse: 0.029144, mae: 0.043952, val nll: -1.4936, val mse 0.0034, lr 0.000053144\n",
      "test nll: -1.4306, test mse: 0.0043\n",
      "7701,7702,7703,7704,7705,7706,7707,7708,7709,7710,\tIter: 7710, train loss: -1.4478, avg nll: -1.4662, avg wnll: 36.0501, avg kl: 0.0002, mse: 0.003653, wmse: 0.030378, mae: 0.044609, val nll: -1.5194, val mse 0.0033, lr 0.000053144\n",
      "test nll: -1.5117, test mse: 0.0030\n",
      "7711,7712,7713,7714,7715,7716,7717,7718,7719,7720,\tIter: 7720, train loss: -1.4509, avg nll: -1.4697, avg wnll: 36.8262, avg kl: 0.0001, mse: 0.003738, wmse: 0.031254, mae: 0.044985, val nll: -1.5277, val mse 0.0032, lr 0.000053144\n",
      "test nll: -1.4778, test mse: 0.0037\n",
      "7721,7722,7723,7724,7725,7726,7727,7728,7729,7730,\tIter: 7730, train loss: -1.4089, avg nll: -1.4287, avg wnll: 39.1279, avg kl: 0.0003, mse: 0.003898, wmse: 0.032572, mae: 0.045919, val nll: -1.3742, val mse 0.0040, lr 0.000053144\n",
      "test nll: -1.4467, test mse: 0.0037\n",
      "7731,7732,7733,7734,7735,7736,7737,7738,7739,7740,\tIter: 7740, train loss: -1.4654, avg nll: -1.4837, avg wnll: 32.6705, avg kl: 0.0002, mse: 0.003612, wmse: 0.030277, mae: 0.043957, val nll: -1.3613, val mse 0.0040, lr 0.000053144\n",
      "test nll: -1.5499, test mse: 0.0030\n",
      "7741,7742,7743,7744,7745,7746,7747,7748,7749,7750,\tIter: 7750, train loss: -1.4722, avg nll: -1.4896, avg wnll: 32.3204, avg kl: 0.0004, mse: 0.003407, wmse: 0.028911, mae: 0.043589, val nll: -1.5333, val mse 0.0031, lr 0.000053144\n",
      "test nll: -1.4690, test mse: 0.0034\n",
      "7751,7752,7753,7754,7755,7756,7757,7758,7759,7760,\tIter: 7760, train loss: -1.4908, avg nll: -1.5075, avg wnll: 33.3580, avg kl: 0.0003, mse: 0.003298, wmse: 0.027908, mae: 0.042539, val nll: -1.5060, val mse 0.0033, lr 0.000053144\n",
      "test nll: -1.3917, test mse: 0.0046\n",
      "7761,7762,7763,7764,7765,7766,7767,7768,7769,7770,\tIter: 7770, train loss: -1.4616, avg nll: -1.4789, avg wnll: 32.0516, avg kl: 0.0003, mse: 0.003399, wmse: 0.028814, mae: 0.044195, val nll: -1.4332, val mse 0.0036, lr 0.000053144\n",
      "test nll: -1.3829, test mse: 0.0042\n",
      "7771,7772,7773,7774,7775,7776,7777,7778,7779,7780,\tIter: 7780, train loss: -1.4445, avg nll: -1.4636, avg wnll: 34.3708, avg kl: 0.0002, mse: 0.003779, wmse: 0.031515, mae: 0.045239, val nll: -1.4607, val mse 0.0036, lr 0.000053144\n",
      "test nll: -1.4702, test mse: 0.0038\n",
      "7781,7782,7783,7784,7785,7786,7787,7788,7789,7790,\tIter: 7790, train loss: -1.4926, avg nll: -1.5094, avg wnll: 34.5123, avg kl: 0.0003, mse: 0.003311, wmse: 0.027532, mae: 0.042769, val nll: -1.5238, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.5190, test mse: 0.0032\n",
      "7791,7792,7793,7794,7795,7796,7797,7798,7799,7800,\tIter: 7800, train loss: -1.4452, avg nll: -1.4639, avg wnll: 36.8860, avg kl: 0.0002, mse: 0.003718, wmse: 0.031729, mae: 0.044955, val nll: -1.5211, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4936, test mse: 0.0035\n",
      "saving.................\n",
      "done\n",
      "7801,7802,7803,7804,7805,7806,7807,7808,7809,7810,\tIter: 7810, train loss: -1.4975, avg nll: -1.5144, avg wnll: 33.2387, avg kl: 0.0001, mse: 0.003366, wmse: 0.028256, mae: 0.043118, val nll: -1.5436, val mse 0.0029, lr 0.000053144\n",
      "test nll: -1.5335, test mse: 0.0031\n",
      "7811,7812,7813,7814,7815,7816,7817,7818,7819,7820,\tIter: 7820, train loss: -1.4726, avg nll: -1.4896, avg wnll: 34.9927, avg kl: 0.0002, mse: 0.003378, wmse: 0.028054, mae: 0.042764, val nll: -1.5353, val mse 0.0030, lr 0.000053144\n",
      "test nll: -1.4766, test mse: 0.0035\n",
      "7821,7822,7823,7824,7825,7826,7827,7828,7829,7830,\tIter: 7830, train loss: -1.4853, avg nll: -1.5021, avg wnll: 31.9646, avg kl: 0.0003, mse: 0.003304, wmse: 0.027571, mae: 0.042308, val nll: -1.4587, val mse 0.0032, lr 0.000053144\n",
      "test nll: -1.3419, test mse: 0.0045\n",
      "7831,7832,7833,7834,7835,7836,7837,7838,7839,7840,\tIter: 7840, train loss: -1.4726, avg nll: -1.4904, avg wnll: 34.7622, avg kl: 0.0002, mse: 0.003533, wmse: 0.030139, mae: 0.044933, val nll: -1.4825, val mse 0.0035, lr 0.000053144\n",
      "test nll: -1.4366, test mse: 0.0038\n",
      "7841,7842,7843,7844,7845,7846,7847,7848,7849,7850,\tIter: 7850, train loss: -1.4648, avg nll: -1.4828, avg wnll: 36.6973, avg kl: 0.0001, mse: 0.003591, wmse: 0.030141, mae: 0.043913, val nll: -1.4146, val mse 0.0043, lr 0.000053144\n",
      "test nll: -1.6036, test mse: 0.0025\n",
      "7851,7852,7853,7854,7855,7856,7857,7858,7859,7860,\tIter: 7860, train loss: -1.4765, avg nll: -1.4940, avg wnll: 34.1450, avg kl: 0.0001, mse: 0.003483, wmse: 0.029408, mae: 0.044341, val nll: -1.4746, val mse 0.0037, lr 0.000053144\n",
      "test nll: -1.4763, test mse: 0.0032\n",
      "7861,7862,7863,7864,7865,7866,7867,7868,7869,7870,\tIter: 7870, train loss: -1.5190, avg nll: -1.5349, avg wnll: 33.5253, avg kl: 0.0001, mse: 0.003144, wmse: 0.026354, mae: 0.041318, val nll: -1.5779, val mse 0.0026, lr 0.000047830\n",
      "test nll: -1.4343, test mse: 0.0042\n",
      "7871,7872,7873,7874,7875,7876,7877,7878,7879,7880,\tIter: 7880, train loss: -1.4948, avg nll: -1.5114, avg wnll: 34.8917, avg kl: 0.0001, mse: 0.003295, wmse: 0.027936, mae: 0.042872, val nll: -1.4584, val mse 0.0037, lr 0.000047830\n",
      "test nll: -1.4719, test mse: 0.0041\n",
      "7881,7882,7883,7884,7885,7886,7887,7888,7889,7890,\tIter: 7890, train loss: -1.5121, avg nll: -1.5289, avg wnll: 34.7791, avg kl: 0.0001, mse: 0.003341, wmse: 0.027893, mae: 0.042437, val nll: -1.5507, val mse 0.0027, lr 0.000047830\n",
      "test nll: -1.4803, test mse: 0.0035\n",
      "7891,7892,7893,7894,7895,7896,7897,7898,7899,7900,\tIter: 7900, train loss: -1.5344, avg nll: -1.5507, avg wnll: 33.4721, avg kl: 0.0001, mse: 0.003235, wmse: 0.027256, mae: 0.041753, val nll: -1.5145, val mse 0.0031, lr 0.000047830\n",
      "test nll: -1.4719, test mse: 0.0038\n",
      "7901,7902,7903,7904,7905,7906,7907,7908,7909,7910,\tIter: 7910, train loss: -1.4648, avg nll: -1.4830, avg wnll: 36.4639, avg kl: 0.0001, mse: 0.003607, wmse: 0.030152, mae: 0.043925, val nll: -1.5515, val mse 0.0031, lr 0.000047830\n",
      "test nll: -1.4780, test mse: 0.0033\n",
      "7911,7912,7913,7914,7915,7916,7917,7918,7919,7920,\tIter: 7920, train loss: -1.5237, avg nll: -1.5400, avg wnll: 33.2937, avg kl: 0.0001, mse: 0.003241, wmse: 0.027452, mae: 0.041862, val nll: -1.5145, val mse 0.0033, lr 0.000047830\n",
      "test nll: -1.4989, test mse: 0.0035\n",
      "7921,7922,7923,7924,7925,7926,7927,7928,7929,7930,\tIter: 7930, train loss: -1.5387, avg nll: -1.5552, avg wnll: 32.6677, avg kl: 0.0001, mse: 0.003284, wmse: 0.027544, mae: 0.041322, val nll: -1.5181, val mse 0.0033, lr 0.000047830\n",
      "test nll: -1.4488, test mse: 0.0038\n",
      "7931,7932,7933,7934,7935,7936,7937,7938,7939,7940,\tIter: 7940, train loss: -1.4863, avg nll: -1.5041, avg wnll: 34.7602, avg kl: 0.0002, mse: 0.003530, wmse: 0.029952, mae: 0.044001, val nll: -1.5103, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.4086, test mse: 0.0040\n",
      "7941,7942,7943,7944,7945,7946,7947,7948,7949,7950,\tIter: 7950, train loss: -1.4810, avg nll: -1.4994, avg wnll: 33.8532, avg kl: 0.0002, mse: 0.003631, wmse: 0.030301, mae: 0.043938, val nll: -1.4672, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.4403, test mse: 0.0043\n",
      "7951,7952,7953,7954,7955,7956,7957,7958,7959,7960,\tIter: 7960, train loss: -1.4501, avg nll: -1.4679, avg wnll: 37.4807, avg kl: 0.0002, mse: 0.003515, wmse: 0.029486, mae: 0.043902, val nll: -1.4897, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.5036, test mse: 0.0031\n",
      "7961,7962,7963,7964,7965,7966,7967,7968,7969,7970,\tIter: 7970, train loss: -1.5175, avg nll: -1.5346, avg wnll: 34.3599, avg kl: 0.0001, mse: 0.003399, wmse: 0.028543, mae: 0.042575, val nll: -1.5112, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.3989, test mse: 0.0040\n",
      "7971,7972,7973,7974,7975,7976,7977,7978,7979,7980,\tIter: 7980, train loss: -1.5008, avg nll: -1.5186, avg wnll: 35.3691, avg kl: 0.0002, mse: 0.003532, wmse: 0.030156, mae: 0.044152, val nll: -1.4283, val mse 0.0042, lr 0.000047830\n",
      "test nll: -1.4324, test mse: 0.0040\n",
      "7981,7982,7983,7984,7985,7986,7987,7988,7989,7990,\tIter: 7990, train loss: -1.5138, avg nll: -1.5310, avg wnll: 35.3979, avg kl: 0.0001, mse: 0.003428, wmse: 0.028952, mae: 0.042441, val nll: -1.5389, val mse 0.0031, lr 0.000047830\n",
      "test nll: -1.4380, test mse: 0.0042\n",
      "7991,7992,7993,7994,7995,7996,7997,7998,7999,8000,\tIter: 8000, train loss: -1.4635, avg nll: -1.4816, avg wnll: 35.6828, avg kl: 0.0001, mse: 0.003589, wmse: 0.029709, mae: 0.044039, val nll: -1.5405, val mse 0.0031, lr 0.000047830\n",
      "test nll: -1.4967, test mse: 0.0033\n",
      "saving.................\n",
      "done\n",
      "8001,8002,8003,8004,8005,8006,8007,8008,8009,8010,\tIter: 8010, train loss: -1.4852, avg nll: -1.5024, avg wnll: 33.3717, avg kl: 0.0001, mse: 0.003408, wmse: 0.028855, mae: 0.043617, val nll: -1.5045, val mse 0.0033, lr 0.000047830\n",
      "test nll: -1.3993, test mse: 0.0046\n",
      "8011,8012,8013,8014,8015,8016,8017,8018,8019,8020,\tIter: 8020, train loss: -1.5427, avg nll: -1.5569, avg wnll: 31.8820, avg kl: 0.0001, mse: 0.002809, wmse: 0.023565, mae: 0.040063, val nll: -1.4978, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4505, test mse: 0.0040\n",
      "8021,8022,8023,8024,8025,8026,8027,8028,8029,8030,\tIter: 8030, train loss: -1.5105, avg nll: -1.5268, avg wnll: 33.5940, avg kl: 0.0001, mse: 0.003231, wmse: 0.027083, mae: 0.042149, val nll: -1.4959, val mse 0.0031, lr 0.000047830\n",
      "test nll: -1.4879, test mse: 0.0037\n",
      "8031,8032,8033,8034,8035,8036,8037,8038,8039,8040,\tIter: 8040, train loss: -1.5215, avg nll: -1.5384, avg wnll: 32.2197, avg kl: 0.0001, mse: 0.003354, wmse: 0.028087, mae: 0.041656, val nll: -1.5447, val mse 0.0032, lr 0.000047830\n",
      "test nll: -1.5130, test mse: 0.0031\n",
      "8041,8042,8043,8044,8045,8046,8047,8048,8049,8050,\tIter: 8050, train loss: -1.4691, avg nll: -1.4870, avg wnll: 33.9530, avg kl: 0.0001, mse: 0.003569, wmse: 0.030172, mae: 0.044690, val nll: -1.4953, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.3873, test mse: 0.0040\n",
      "8051,8052,8053,8054,8055,8056,8057,8058,8059,8060,\tIter: 8060, train loss: -1.4700, avg nll: -1.4870, avg wnll: 37.6426, avg kl: 0.0002, mse: 0.003356, wmse: 0.028206, mae: 0.044064, val nll: -1.5393, val mse 0.0028, lr 0.000047830\n",
      "test nll: -1.4634, test mse: 0.0033\n",
      "8061,8062,8063,8064,8065,8066,8067,8068,8069,8070,\tIter: 8070, train loss: -1.5093, avg nll: -1.5263, avg wnll: 37.0938, avg kl: 0.0001, mse: 0.003375, wmse: 0.028645, mae: 0.041810, val nll: -1.5151, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4762, test mse: 0.0029\n",
      "8071,8072,8073,8074,8075,8076,8077,8078,8079,8080,\tIter: 8080, train loss: -1.5105, avg nll: -1.5275, avg wnll: 34.2771, avg kl: 0.0001, mse: 0.003377, wmse: 0.028522, mae: 0.042283, val nll: -1.6189, val mse 0.0026, lr 0.000047830\n",
      "test nll: -1.4836, test mse: 0.0037\n",
      "8081,8082,8083,8084,8085,8086,8087,8088,8089,8090,\tIter: 8090, train loss: -1.4766, avg nll: -1.4937, avg wnll: 36.4743, avg kl: 0.0002, mse: 0.003387, wmse: 0.028492, mae: 0.043291, val nll: -1.4703, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4845, test mse: 0.0038\n",
      "8091,8092,8093,8094,8095,8096,8097,8098,8099,8100,\tIter: 8100, train loss: -1.4638, avg nll: -1.4813, avg wnll: 36.0919, avg kl: 0.0002, mse: 0.003471, wmse: 0.028805, mae: 0.043724, val nll: -1.5202, val mse 0.0032, lr 0.000047830\n",
      "test nll: -1.4164, test mse: 0.0039\n",
      "8101,8102,8103,8104,8105,8106,8107,8108,8109,8110,\tIter: 8110, train loss: -1.4544, avg nll: -1.4738, avg wnll: 36.7151, avg kl: 0.0002, mse: 0.003843, wmse: 0.032570, mae: 0.044744, val nll: -1.4443, val mse 0.0038, lr 0.000047830\n",
      "test nll: -1.4791, test mse: 0.0039\n",
      "8111,8112,8113,8114,8115,8116,8117,8118,8119,8120,\tIter: 8120, train loss: -1.5304, avg nll: -1.5455, avg wnll: 32.3490, avg kl: 0.0002, mse: 0.002985, wmse: 0.025200, mae: 0.041336, val nll: -1.5180, val mse 0.0033, lr 0.000047830\n",
      "test nll: -1.5587, test mse: 0.0029\n",
      "8121,8122,8123,8124,8125,8126,8127,8128,8129,8130,\tIter: 8130, train loss: -1.3829, avg nll: -1.4045, avg wnll: 39.3502, avg kl: 0.0004, mse: 0.004234, wmse: 0.035420, mae: 0.047452, val nll: -1.4575, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.4805, test mse: 0.0037\n",
      "8131,8132,8133,8134,8135,8136,8137,8138,8139,8140,\tIter: 8140, train loss: -1.5258, avg nll: -1.5422, avg wnll: 31.9064, avg kl: 0.0002, mse: 0.003241, wmse: 0.027325, mae: 0.041793, val nll: -1.4936, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.5308, test mse: 0.0034\n",
      "8141,8142,8143,8144,8145,8146,8147,8148,8149,8150,\tIter: 8150, train loss: -1.5102, avg nll: -1.5276, avg wnll: 32.7152, avg kl: 0.0002, mse: 0.003447, wmse: 0.028741, mae: 0.042775, val nll: -1.4769, val mse 0.0039, lr 0.000047830\n",
      "test nll: -1.4338, test mse: 0.0040\n",
      "8151,8152,8153,8154,8155,8156,8157,8158,8159,8160,\tIter: 8160, train loss: -1.5195, avg nll: -1.5362, avg wnll: 31.9158, avg kl: 0.0001, mse: 0.003299, wmse: 0.027885, mae: 0.042098, val nll: -1.5117, val mse 0.0038, lr 0.000047830\n",
      "test nll: -1.5242, test mse: 0.0036\n",
      "8161,8162,8163,8164,8165,8166,8167,8168,8169,8170,\tIter: 8170, train loss: -1.4902, avg nll: -1.5071, avg wnll: 34.7141, avg kl: 0.0002, mse: 0.003332, wmse: 0.028468, mae: 0.042772, val nll: -1.5307, val mse 0.0032, lr 0.000047830\n",
      "test nll: -1.4442, test mse: 0.0036\n",
      "8171,8172,8173,8174,8175,8176,8177,8178,8179,8180,\tIter: 8180, train loss: -1.4691, avg nll: -1.4872, avg wnll: 35.9989, avg kl: 0.0001, mse: 0.003591, wmse: 0.029692, mae: 0.043645, val nll: -1.4643, val mse 0.0039, lr 0.000047830\n",
      "test nll: -1.4268, test mse: 0.0043\n",
      "8181,8182,8183,8184,8185,8186,8187,8188,8189,8190,\tIter: 8190, train loss: -1.4542, avg nll: -1.4736, avg wnll: 35.9967, avg kl: 0.0002, mse: 0.003835, wmse: 0.032286, mae: 0.045217, val nll: -1.5699, val mse 0.0030, lr 0.000047830\n",
      "test nll: -1.4806, test mse: 0.0038\n",
      "8191,8192,8193,8194,8195,8196,8197,8198,8199,8200,\tIter: 8200, train loss: -1.5210, avg nll: -1.5380, avg wnll: 32.8389, avg kl: 0.0002, mse: 0.003368, wmse: 0.028433, mae: 0.041921, val nll: -1.4710, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4611, test mse: 0.0038\n",
      "saving.................\n",
      "done\n",
      "8201,8202,8203,8204,8205,8206,8207,8208,8209,8210,\tIter: 8210, train loss: -1.4570, avg nll: -1.4743, avg wnll: 36.3888, avg kl: 0.0002, mse: 0.003414, wmse: 0.028847, mae: 0.043929, val nll: -1.5013, val mse 0.0030, lr 0.000047830\n",
      "test nll: -1.4670, test mse: 0.0035\n",
      "8211,8212,8213,8214,8215,8216,8217,8218,8219,8220,\tIter: 8220, train loss: -1.4972, avg nll: -1.5129, avg wnll: 34.5485, avg kl: 0.0002, mse: 0.003086, wmse: 0.025980, mae: 0.042259, val nll: -1.5300, val mse 0.0029, lr 0.000047830\n",
      "test nll: -1.4732, test mse: 0.0037\n",
      "8221,8222,8223,8224,8225,8226,8227,8228,8229,8230,\tIter: 8230, train loss: -1.4470, avg nll: -1.4663, avg wnll: 35.5715, avg kl: 0.0002, mse: 0.003815, wmse: 0.031879, mae: 0.045208, val nll: -1.4475, val mse 0.0038, lr 0.000047830\n",
      "test nll: -1.5066, test mse: 0.0034\n",
      "8231,8232,8233,8234,8235,8236,8237,8238,8239,8240,\tIter: 8240, train loss: -1.5153, avg nll: -1.5318, avg wnll: 34.0671, avg kl: 0.0002, mse: 0.003260, wmse: 0.027401, mae: 0.042196, val nll: -1.5759, val mse 0.0032, lr 0.000047830\n",
      "test nll: -1.5031, test mse: 0.0035\n",
      "8241,8242,8243,8244,8245,8246,8247,8248,8249,8250,\tIter: 8250, train loss: -1.5115, avg nll: -1.5282, avg wnll: 33.7093, avg kl: 0.0001, mse: 0.003307, wmse: 0.027775, mae: 0.042060, val nll: -1.5222, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.4513, test mse: 0.0039\n",
      "8251,8252,8253,8254,8255,8256,8257,8258,8259,8260,\tIter: 8260, train loss: -1.4897, avg nll: -1.5072, avg wnll: 32.9288, avg kl: 0.0002, mse: 0.003471, wmse: 0.029095, mae: 0.043937, val nll: -1.4087, val mse 0.0040, lr 0.000047830\n",
      "test nll: -1.4991, test mse: 0.0034\n",
      "8261,8262,8263,8264,8265,8266,8267,8268,8269,8270,\tIter: 8270, train loss: -1.4750, avg nll: -1.4925, avg wnll: 35.7326, avg kl: 0.0003, mse: 0.003436, wmse: 0.028948, mae: 0.043568, val nll: -1.4892, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.4741, test mse: 0.0042\n",
      "8271,8272,8273,8274,8275,8276,8277,8278,8279,8280,\tIter: 8280, train loss: -1.4899, avg nll: -1.5062, avg wnll: 33.6648, avg kl: 0.0001, mse: 0.003241, wmse: 0.027246, mae: 0.041929, val nll: -1.4706, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4212, test mse: 0.0044\n",
      "8281,8282,8283,8284,8285,8286,8287,8288,8289,8290,\tIter: 8290, train loss: -1.4434, avg nll: -1.4621, avg wnll: 36.2631, avg kl: 0.0002, mse: 0.003692, wmse: 0.031493, mae: 0.044670, val nll: -1.4763, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.4423, test mse: 0.0039\n",
      "8291,8292,8293,8294,8295,8296,8297,8298,8299,8300,\tIter: 8300, train loss: -1.5354, avg nll: -1.5507, avg wnll: 33.0032, avg kl: 0.0002, mse: 0.003032, wmse: 0.025379, mae: 0.041035, val nll: -1.5430, val mse 0.0030, lr 0.000047830\n",
      "test nll: -1.5584, test mse: 0.0028\n",
      "8301,8302,8303,8304,8305,8306,8307,8308,8309,8310,\tIter: 8310, train loss: -1.4702, avg nll: -1.4891, avg wnll: 34.5363, avg kl: 0.0002, mse: 0.003735, wmse: 0.031064, mae: 0.043581, val nll: -1.4702, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.4850, test mse: 0.0038\n",
      "8311,8312,8313,8314,8315,8316,8317,8318,8319,8320,\tIter: 8320, train loss: -1.4559, avg nll: -1.4741, avg wnll: 35.4218, avg kl: 0.0001, mse: 0.003613, wmse: 0.030279, mae: 0.043391, val nll: -1.4281, val mse 0.0039, lr 0.000047830\n",
      "test nll: -1.4750, test mse: 0.0038\n",
      "8321,8322,8323,8324,8325,8326,8327,8328,8329,8330,\tIter: 8330, train loss: -1.5077, avg nll: -1.5238, avg wnll: 33.6864, avg kl: 0.0001, mse: 0.003192, wmse: 0.026836, mae: 0.042123, val nll: -1.4882, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.4457, test mse: 0.0039\n",
      "8331,8332,8333,8334,8335,8336,8337,8338,8339,8340,\tIter: 8340, train loss: -1.4854, avg nll: -1.5027, avg wnll: 35.5918, avg kl: 0.0001, mse: 0.003430, wmse: 0.028724, mae: 0.042865, val nll: -1.4735, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4578, test mse: 0.0038\n",
      "8341,8342,8343,8344,8345,8346,8347,8348,8349,8350,\tIter: 8350, train loss: -1.4755, avg nll: -1.4927, avg wnll: 37.0650, avg kl: 0.0001, mse: 0.003411, wmse: 0.028720, mae: 0.043798, val nll: -1.5368, val mse 0.0031, lr 0.000047830\n",
      "test nll: -1.4264, test mse: 0.0042\n",
      "8351,8352,8353,8354,8355,8356,8357,8358,8359,8360,\tIter: 8360, train loss: -1.5241, avg nll: -1.5401, avg wnll: 33.0614, avg kl: 0.0001, mse: 0.003182, wmse: 0.026448, mae: 0.041953, val nll: -1.4448, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4854, test mse: 0.0036\n",
      "8361,8362,8363,8364,8365,8366,8367,8368,8369,8370,\tIter: 8370, train loss: -1.5109, avg nll: -1.5269, avg wnll: 32.9490, avg kl: 0.0002, mse: 0.003163, wmse: 0.026404, mae: 0.041501, val nll: -1.4413, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.4451, test mse: 0.0040\n",
      "8371,8372,8373,8374,8375,8376,8377,8378,8379,8380,\tIter: 8380, train loss: -1.4287, avg nll: -1.4479, avg wnll: 37.6833, avg kl: 0.0002, mse: 0.003794, wmse: 0.031884, mae: 0.045022, val nll: -1.4951, val mse 0.0032, lr 0.000047830\n",
      "test nll: -1.4644, test mse: 0.0043\n",
      "8381,8382,8383,8384,8385,8386,8387,8388,8389,8390,\tIter: 8390, train loss: -1.5277, avg nll: -1.5449, avg wnll: 33.1612, avg kl: 0.0002, mse: 0.003401, wmse: 0.028694, mae: 0.042022, val nll: -1.4896, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.5104, test mse: 0.0031\n",
      "8391,8392,8393,8394,8395,8396,8397,8398,8399,8400,\tIter: 8400, train loss: -1.5138, avg nll: -1.5302, avg wnll: 33.0607, avg kl: 0.0001, mse: 0.003237, wmse: 0.027213, mae: 0.041930, val nll: -1.5732, val mse 0.0028, lr 0.000047830\n",
      "test nll: -1.4771, test mse: 0.0038\n",
      "saving.................\n",
      "done\n",
      "8401,8402,8403,8404,8405,8406,8407,8408,8409,8410,\tIter: 8410, train loss: -1.5127, avg nll: -1.5285, avg wnll: 31.5974, avg kl: 0.0003, mse: 0.003099, wmse: 0.026229, mae: 0.042175, val nll: -1.4867, val mse 0.0038, lr 0.000047830\n",
      "test nll: -1.4909, test mse: 0.0034\n",
      "8411,8412,8413,8414,8415,8416,8417,8418,8419,8420,\tIter: 8420, train loss: -1.4656, avg nll: -1.4832, avg wnll: 33.8643, avg kl: 0.0003, mse: 0.003457, wmse: 0.029177, mae: 0.043639, val nll: -1.4623, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.5598, test mse: 0.0029\n",
      "8421,8422,8423,8424,8425,8426,8427,8428,8429,8430,\tIter: 8430, train loss: -1.4879, avg nll: -1.5053, avg wnll: 31.6136, avg kl: 0.0002, mse: 0.003445, wmse: 0.028537, mae: 0.043504, val nll: -1.5779, val mse 0.0025, lr 0.000047830\n",
      "test nll: -1.5148, test mse: 0.0031\n",
      "8431,8432,8433,8434,8435,8436,8437,8438,8439,8440,\tIter: 8440, train loss: -1.5238, avg nll: -1.5401, avg wnll: 32.7445, avg kl: 0.0001, mse: 0.003228, wmse: 0.027162, mae: 0.041620, val nll: -1.4741, val mse 0.0037, lr 0.000047830\n",
      "test nll: -1.4696, test mse: 0.0040\n",
      "8441,8442,8443,8444,8445,8446,8447,8448,8449,8450,\tIter: 8450, train loss: -1.5121, avg nll: -1.5286, avg wnll: 28.6941, avg kl: 0.0003, mse: 0.003236, wmse: 0.027339, mae: 0.041522, val nll: -1.4481, val mse 0.0039, lr 0.000047830\n",
      "test nll: -1.4674, test mse: 0.0033\n",
      "8451,8452,8453,8454,8455,8456,8457,8458,8459,8460,\tIter: 8460, train loss: -1.4430, avg nll: -1.4616, avg wnll: 36.1553, avg kl: 0.0002, mse: 0.003669, wmse: 0.030640, mae: 0.044766, val nll: -1.4561, val mse 0.0036, lr 0.000047830\n",
      "test nll: -1.3973, test mse: 0.0045\n",
      "8461,8462,8463,8464,8465,8466,8467,8468,8469,8470,\tIter: 8470, train loss: -1.3893, avg nll: -1.4098, avg wnll: 39.2032, avg kl: 0.0002, mse: 0.004054, wmse: 0.034167, mae: 0.047973, val nll: -1.5106, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.4547, test mse: 0.0035\n",
      "8471,8472,8473,8474,8475,8476,8477,8478,8479,8480,\tIter: 8480, train loss: -1.4956, avg nll: -1.5127, avg wnll: 34.3361, avg kl: 0.0001, mse: 0.003385, wmse: 0.028205, mae: 0.042081, val nll: -1.5494, val mse 0.0032, lr 0.000047830\n",
      "test nll: -1.5214, test mse: 0.0033\n",
      "8481,8482,8483,8484,8485,8486,8487,8488,8489,8490,\tIter: 8490, train loss: -1.4994, avg nll: -1.5170, avg wnll: 33.4125, avg kl: 0.0001, mse: 0.003502, wmse: 0.029443, mae: 0.042355, val nll: -1.4609, val mse 0.0038, lr 0.000047830\n",
      "test nll: -1.4306, test mse: 0.0037\n",
      "8491,8492,8493,8494,8495,8496,8497,8498,8499,8500,\tIter: 8500, train loss: -1.5011, avg nll: -1.5191, avg wnll: 35.7103, avg kl: 0.0001, mse: 0.003580, wmse: 0.030422, mae: 0.043322, val nll: -1.4319, val mse 0.0037, lr 0.000047830\n",
      "test nll: -1.4528, test mse: 0.0037\n",
      "8501,8502,8503,8504,8505,8506,8507,8508,8509,8510,\tIter: 8510, train loss: -1.4467, avg nll: -1.4654, avg wnll: 37.6382, avg kl: 0.0001, mse: 0.003721, wmse: 0.031492, mae: 0.044558, val nll: -1.5660, val mse 0.0028, lr 0.000047830\n",
      "test nll: -1.5108, test mse: 0.0034\n",
      "8511,8512,8513,8514,8515,8516,8517,8518,8519,8520,\tIter: 8520, train loss: -1.5135, avg nll: -1.5302, avg wnll: 32.6713, avg kl: 0.0003, mse: 0.003287, wmse: 0.027931, mae: 0.042013, val nll: -1.5670, val mse 0.0029, lr 0.000047830\n",
      "test nll: -1.4739, test mse: 0.0040\n",
      "8521,8522,8523,8524,8525,8526,8527,8528,8529,8530,\tIter: 8530, train loss: -1.5328, avg nll: -1.5489, avg wnll: 32.3469, avg kl: 0.0002, mse: 0.003188, wmse: 0.026242, mae: 0.040774, val nll: -1.4882, val mse 0.0033, lr 0.000047830\n",
      "test nll: -1.4248, test mse: 0.0040\n",
      "8531,8532,8533,8534,8535,8536,8537,8538,8539,8540,\tIter: 8540, train loss: -1.5083, avg nll: -1.5237, avg wnll: 30.2367, avg kl: 0.0003, mse: 0.003009, wmse: 0.025374, mae: 0.041302, val nll: -1.4221, val mse 0.0034, lr 0.000047830\n",
      "test nll: -1.4016, test mse: 0.0042\n",
      "8541,8542,8543,8544,8545,8546,8547,8548,8549,8550,\tIter: 8550, train loss: -1.4901, avg nll: -1.5074, avg wnll: 35.1338, avg kl: 0.0002, mse: 0.003419, wmse: 0.028399, mae: 0.042518, val nll: -1.5019, val mse 0.0032, lr 0.000047830\n",
      "test nll: -1.4796, test mse: 0.0034\n",
      "8551,8552,8553,8554,8555,8556,8557,8558,8559,8560,\tIter: 8560, train loss: -1.5292, avg nll: -1.5447, avg wnll: 31.2919, avg kl: 0.0002, mse: 0.003064, wmse: 0.025685, mae: 0.040912, val nll: -1.5434, val mse 0.0029, lr 0.000047830\n",
      "test nll: -1.3757, test mse: 0.0045\n",
      "8561,8562,8563,8564,8565,8566,8567,8568,8569,8570,\tIter: 8570, train loss: -1.5014, avg nll: -1.5189, avg wnll: 31.8118, avg kl: 0.0002, mse: 0.003463, wmse: 0.028946, mae: 0.042999, val nll: -1.5508, val mse 0.0028, lr 0.000047830\n",
      "test nll: -1.5126, test mse: 0.0033\n",
      "8571,8572,8573,8574,8575,8576,8577,8578,8579,8580,\tIter: 8580, train loss: -1.5131, avg nll: -1.5285, avg wnll: 32.7875, avg kl: 0.0001, mse: 0.003063, wmse: 0.025659, mae: 0.041167, val nll: -1.4797, val mse 0.0037, lr 0.000047830\n",
      "test nll: -1.4362, test mse: 0.0038\n",
      "8581,8582,8583,8584,8585,8586,8587,8588,8589,8590,\tIter: 8590, train loss: -1.4996, avg nll: -1.5170, avg wnll: 34.6203, avg kl: 0.0001, mse: 0.003465, wmse: 0.028713, mae: 0.042610, val nll: -1.4736, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.4965, test mse: 0.0034\n",
      "8591,8592,8593,8594,8595,8596,8597,8598,8599,8600,\tIter: 8600, train loss: -1.5107, avg nll: -1.5274, avg wnll: 32.2291, avg kl: 0.0001, mse: 0.003317, wmse: 0.028111, mae: 0.042509, val nll: -1.5059, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.5008, test mse: 0.0039\n",
      "saving.................\n",
      "done\n",
      "8601,8602,8603,8604,8605,8606,8607,8608,8609,8610,\tIter: 8610, train loss: -1.5189, avg nll: -1.5356, avg wnll: 33.2818, avg kl: 0.0001, mse: 0.003311, wmse: 0.027744, mae: 0.041936, val nll: -1.4314, val mse 0.0042, lr 0.000047830\n",
      "test nll: -1.5288, test mse: 0.0033\n",
      "8611,8612,8613,8614,8615,8616,8617,8618,8619,8620,\tIter: 8620, train loss: -1.4602, avg nll: -1.4783, avg wnll: 35.7594, avg kl: 0.0001, mse: 0.003601, wmse: 0.030048, mae: 0.044283, val nll: -1.5372, val mse 0.0035, lr 0.000047830\n",
      "test nll: -1.5091, test mse: 0.0033\n",
      "8621,8622,8623,8624,8625,8626,8627,8628,8629,8630,\tIter: 8630, train loss: -1.4666, avg nll: -1.4845, avg wnll: 34.8862, avg kl: 0.0002, mse: 0.003537, wmse: 0.029782, mae: 0.044407, val nll: -1.4314, val mse 0.0039, lr 0.000047830\n",
      "test nll: -1.3768, test mse: 0.0042\n",
      "8631,8632,8633,8634,8635,8636,8637,8638,8639,8640,\tIter: 8640, train loss: -1.4989, avg nll: -1.5151, avg wnll: 30.4927, avg kl: 0.0002, mse: 0.003190, wmse: 0.026734, mae: 0.042087, val nll: -1.5098, val mse 0.0031, lr 0.000047830\n",
      "test nll: -1.4785, test mse: 0.0035\n",
      "8641,8642,8643,8644,8645,8646,8647,8648,8649,8650,\tIter: 8650, train loss: -1.4881, avg nll: -1.5053, avg wnll: 31.9285, avg kl: 0.0002, mse: 0.003386, wmse: 0.028177, mae: 0.041848, val nll: -1.5215, val mse 0.0033, lr 0.000043047\n",
      "test nll: -1.4368, test mse: 0.0042\n",
      "8651,8652,8653,8654,8655,8656,8657,8658,8659,8660,\tIter: 8660, train loss: -1.4817, avg nll: -1.4987, avg wnll: 34.0461, avg kl: 0.0001, mse: 0.003353, wmse: 0.027903, mae: 0.042900, val nll: -1.4074, val mse 0.0043, lr 0.000043047\n",
      "test nll: -1.4362, test mse: 0.0036\n",
      "8661,8662,8663,8664,8665,8666,8667,8668,8669,8670,\tIter: 8670, train loss: -1.4754, avg nll: -1.4933, avg wnll: 36.4181, avg kl: 0.0001, mse: 0.003544, wmse: 0.029836, mae: 0.043972, val nll: -1.6218, val mse 0.0023, lr 0.000043047\n",
      "test nll: -1.4422, test mse: 0.0039\n",
      "8671,8672,8673,8674,8675,8676,8677,8678,8679,8680,\tIter: 8680, train loss: -1.5428, avg nll: -1.5579, avg wnll: 31.5711, avg kl: 0.0001, mse: 0.002987, wmse: 0.025219, mae: 0.040163, val nll: -1.5297, val mse 0.0032, lr 0.000043047\n",
      "test nll: -1.5266, test mse: 0.0034\n",
      "8681,8682,8683,8684,8685,8686,8687,8688,8689,8690,\tIter: 8690, train loss: -1.4968, avg nll: -1.5142, avg wnll: 35.4553, avg kl: 0.0001, mse: 0.003433, wmse: 0.028979, mae: 0.042972, val nll: -1.5152, val mse 0.0032, lr 0.000043047\n",
      "test nll: -1.4314, test mse: 0.0040\n",
      "8691,8692,8693,8694,8695,8696,8697,8698,8699,8700,\tIter: 8700, train loss: -1.5215, avg nll: -1.5372, avg wnll: 33.8471, avg kl: 0.0001, mse: 0.003121, wmse: 0.026254, mae: 0.041858, val nll: -1.5333, val mse 0.0030, lr 0.000043047\n",
      "test nll: -1.5500, test mse: 0.0034\n",
      "8701,8702,8703,8704,8705,8706,8707,8708,8709,8710,\tIter: 8710, train loss: -1.5158, avg nll: -1.5327, avg wnll: 32.7568, avg kl: 0.0001, mse: 0.003365, wmse: 0.028406, mae: 0.041884, val nll: -1.4196, val mse 0.0040, lr 0.000043047\n",
      "test nll: -1.4442, test mse: 0.0037\n",
      "8711,8712,8713,8714,8715,8716,8717,8718,8719,8720,\tIter: 8720, train loss: -1.5476, avg nll: -1.5639, avg wnll: 33.0858, avg kl: 0.0001, mse: 0.003257, wmse: 0.027575, mae: 0.041380, val nll: -1.5257, val mse 0.0031, lr 0.000043047\n",
      "test nll: -1.4778, test mse: 0.0037\n",
      "8721,8722,8723,8724,8725,8726,8727,8728,8729,8730,\tIter: 8730, train loss: -1.4984, avg nll: -1.5158, avg wnll: 34.4754, avg kl: 0.0001, mse: 0.003475, wmse: 0.029157, mae: 0.042865, val nll: -1.5673, val mse 0.0029, lr 0.000043047\n",
      "test nll: -1.4904, test mse: 0.0033\n",
      "8731,8732,8733,8734,8735,8736,8737,8738,8739,8740,\tIter: 8740, train loss: -1.4926, avg nll: -1.5105, avg wnll: 35.2198, avg kl: 0.0001, mse: 0.003565, wmse: 0.029740, mae: 0.043493, val nll: -1.5616, val mse 0.0029, lr 0.000043047\n",
      "test nll: -1.4104, test mse: 0.0040\n",
      "8741,8742,8743,8744,8745,8746,8747,8748,8749,8750,\tIter: 8750, train loss: -1.4970, avg nll: -1.5133, avg wnll: 34.1164, avg kl: 0.0001, mse: 0.003240, wmse: 0.026998, mae: 0.042875, val nll: -1.5352, val mse 0.0032, lr 0.000043047\n",
      "test nll: -1.4044, test mse: 0.0043\n",
      "8751,8752,8753,8754,8755,8756,8757,8758,8759,8760,\tIter: 8760, train loss: -1.5420, avg nll: -1.5572, avg wnll: 32.5765, avg kl: 0.0001, mse: 0.003018, wmse: 0.025629, mae: 0.041782, val nll: -1.5457, val mse 0.0031, lr 0.000043047\n",
      "test nll: -1.5109, test mse: 0.0032\n",
      "8761,8762,8763,8764,8765,8766,8767,8768,8769,8770,\tIter: 8770, train loss: -1.5324, avg nll: -1.5482, avg wnll: 32.1479, avg kl: 0.0002, mse: 0.003134, wmse: 0.026825, mae: 0.042279, val nll: -1.4370, val mse 0.0042, lr 0.000043047\n",
      "test nll: -1.5192, test mse: 0.0031\n",
      "8771,8772,8773,8774,8775,8776,8777,8778,8779,8780,\tIter: 8780, train loss: -1.5191, avg nll: -1.5354, avg wnll: 33.3294, avg kl: 0.0001, mse: 0.003256, wmse: 0.027965, mae: 0.042011, val nll: -1.5036, val mse 0.0036, lr 0.000043047\n",
      "test nll: -1.5395, test mse: 0.0034\n",
      "8781,8782,8783,8784,8785,8786,8787,8788,8789,8790,\tIter: 8790, train loss: -1.5215, avg nll: -1.5376, avg wnll: 33.0409, avg kl: 0.0002, mse: 0.003188, wmse: 0.027011, mae: 0.041791, val nll: -1.5076, val mse 0.0032, lr 0.000043047\n",
      "test nll: -1.5292, test mse: 0.0030\n",
      "8791,8792,8793,8794,8795,8796,8797,8798,8799,8800,\tIter: 8800, train loss: -1.5132, avg nll: -1.5293, avg wnll: 31.8102, avg kl: 0.0001, mse: 0.003200, wmse: 0.026616, mae: 0.041923, val nll: -1.4744, val mse 0.0038, lr 0.000043047\n",
      "test nll: -1.4929, test mse: 0.0034\n",
      "saving.................\n",
      "done\n",
      "8801,8802,8803,8804,8805,8806,8807,8808,8809,8810,\tIter: 8810, train loss: -1.5485, avg nll: -1.5639, avg wnll: 31.1393, avg kl: 0.0001, mse: 0.003057, wmse: 0.025890, mae: 0.040787, val nll: -1.4922, val mse 0.0033, lr 0.000043047\n",
      "test nll: -1.4947, test mse: 0.0033\n",
      "8811,8812,8813,8814,8815,8816,8817,8818,8819,8820,\tIter: 8820, train loss: -1.5122, avg nll: -1.5292, avg wnll: 34.0519, avg kl: 0.0001, mse: 0.003377, wmse: 0.028401, mae: 0.042348, val nll: -1.5739, val mse 0.0029, lr 0.000043047\n",
      "test nll: -1.5471, test mse: 0.0029\n",
      "8821,8822,8823,8824,8825,8826,8827,8828,8829,8830,\tIter: 8830, train loss: -1.4928, avg nll: -1.5106, avg wnll: 35.9361, avg kl: 0.0001, mse: 0.003541, wmse: 0.029895, mae: 0.042402, val nll: -1.4147, val mse 0.0041, lr 0.000043047\n",
      "test nll: -1.5051, test mse: 0.0037\n",
      "8831,8832,8833,8834,8835,8836,8837,8838,8839,8840,\tIter: 8840, train loss: -1.4496, avg nll: -1.4680, avg wnll: 36.8655, avg kl: 0.0002, mse: 0.003649, wmse: 0.030717, mae: 0.044523, val nll: -1.4565, val mse 0.0036, lr 0.000043047\n",
      "test nll: -1.4369, test mse: 0.0042\n",
      "8841,8842,8843,8844,8845,8846,8847,8848,8849,8850,\tIter: 8850, train loss: -1.4900, avg nll: -1.5064, avg wnll: 35.3554, avg kl: 0.0002, mse: 0.003257, wmse: 0.027774, mae: 0.042865, val nll: -1.5779, val mse 0.0027, lr 0.000043047\n",
      "test nll: -1.4229, test mse: 0.0041\n",
      "8851,8852,8853,8854,8855,8856,8857,8858,8859,8860,\tIter: 8860, train loss: -1.5134, avg nll: -1.5296, avg wnll: 30.7583, avg kl: 0.0003, mse: 0.003187, wmse: 0.026790, mae: 0.042279, val nll: -1.5281, val mse 0.0035, lr 0.000043047\n",
      "test nll: -1.4450, test mse: 0.0038\n",
      "8861,8862,8863,8864,8865,8866,8867,8868,8869,8870,\tIter: 8870, train loss: -1.5003, avg nll: -1.5171, avg wnll: 33.3879, avg kl: 0.0001, mse: 0.003337, wmse: 0.027905, mae: 0.042476, val nll: -1.4203, val mse 0.0042, lr 0.000043047\n",
      "test nll: -1.3844, test mse: 0.0042\n",
      "8871,8872,8873,8874,8875,8876,8877,8878,8879,8880,\tIter: 8880, train loss: -1.5233, avg nll: -1.5393, avg wnll: 33.8615, avg kl: 0.0002, mse: 0.003172, wmse: 0.026586, mae: 0.041059, val nll: -1.4735, val mse 0.0034, lr 0.000043047\n",
      "test nll: -1.5310, test mse: 0.0034\n",
      "8881,8882,8883,8884,8885,8886,8887,8888,8889,8890,\tIter: 8890, train loss: -1.4493, avg nll: -1.4685, avg wnll: 37.7415, avg kl: 0.0001, mse: 0.003811, wmse: 0.032087, mae: 0.044694, val nll: -1.5783, val mse 0.0026, lr 0.000043047\n",
      "test nll: -1.5278, test mse: 0.0031\n",
      "8891,8892,8893,8894,8895,8896,8897,8898,8899,8900,\tIter: 8900, train loss: -1.4970, avg nll: -1.5146, avg wnll: 33.2850, avg kl: 0.0001, mse: 0.003494, wmse: 0.028915, mae: 0.042888, val nll: -1.5271, val mse 0.0031, lr 0.000043047\n",
      "test nll: -1.4792, test mse: 0.0036\n",
      "8901,8902,8903,8904,8905,8906,8907,8908,8909,8910,\tIter: 8910, train loss: -1.4446, avg nll: -1.4627, avg wnll: 37.6852, avg kl: 0.0002, mse: 0.003575, wmse: 0.029823, mae: 0.044014, val nll: -1.4810, val mse 0.0035, lr 0.000043047\n",
      "test nll: -1.4824, test mse: 0.0035\n",
      "8911,8912,8913,8914,8915,8916,8917,8918,8919,8920,\tIter: 8920, train loss: -1.5190, avg nll: -1.5348, avg wnll: 31.3416, avg kl: 0.0001, mse: 0.003127, wmse: 0.026483, mae: 0.042024, val nll: -1.4701, val mse 0.0035, lr 0.000043047\n",
      "test nll: -1.4577, test mse: 0.0038\n",
      "8921,8922,8923,8924,8925,8926,8927,8928,8929,8930,\tIter: 8930, train loss: -1.4858, avg nll: -1.5031, avg wnll: 34.8392, avg kl: 0.0003, mse: 0.003398, wmse: 0.028753, mae: 0.044050, val nll: -1.4927, val mse 0.0040, lr 0.000043047\n",
      "test nll: -1.4022, test mse: 0.0041\n",
      "8931,8932,8933,8934,8935,8936,8937,8938,8939,8940,\tIter: 8940, train loss: -1.4832, avg nll: -1.5012, avg wnll: 35.7117, avg kl: 0.0002, mse: 0.003579, wmse: 0.030032, mae: 0.043213, val nll: -1.4269, val mse 0.0038, lr 0.000043047\n",
      "test nll: -1.3629, test mse: 0.0039\n",
      "8941,8942,8943,8944,8945,8946,8947,8948,8949,8950,\tIter: 8950, train loss: -1.5045, avg nll: -1.5211, avg wnll: 33.8799, avg kl: 0.0002, mse: 0.003282, wmse: 0.027512, mae: 0.042164, val nll: -1.5083, val mse 0.0034, lr 0.000043047\n",
      "test nll: -1.4931, test mse: 0.0033\n",
      "8951,8952,8953,8954,8955,8956,8957,8958,8959,8960,\tIter: 8960, train loss: -1.5285, avg nll: -1.5452, avg wnll: 32.6615, avg kl: 0.0001, mse: 0.003333, wmse: 0.027950, mae: 0.042135, val nll: -1.5173, val mse 0.0031, lr 0.000043047\n",
      "test nll: -1.4459, test mse: 0.0039\n",
      "8961,8962,8963,8964,8965,8966,8967,8968,8969,8970,\tIter: 8970, train loss: -1.4953, avg nll: -1.5130, avg wnll: 33.1017, avg kl: 0.0002, mse: 0.003497, wmse: 0.029163, mae: 0.042340, val nll: -1.5006, val mse 0.0033, lr 0.000043047\n",
      "test nll: -1.5465, test mse: 0.0032\n",
      "8971,8972,8973,8974,8975,8976,8977,8978,8979,8980,\tIter: 8980, train loss: -1.5059, avg nll: -1.5237, avg wnll: 33.7083, avg kl: 0.0002, mse: 0.003540, wmse: 0.030063, mae: 0.042685, val nll: -1.5647, val mse 0.0033, lr 0.000043047\n",
      "test nll: -1.5374, test mse: 0.0032\n",
      "8981,8982,8983,8984,8985,8986,8987,8988,8989,8990,\tIter: 8990, train loss: -1.4742, avg nll: -1.4919, avg wnll: 36.1596, avg kl: 0.0001, mse: 0.003523, wmse: 0.029815, mae: 0.043375, val nll: -1.4725, val mse 0.0035, lr 0.000043047\n",
      "test nll: -1.4964, test mse: 0.0040\n",
      "8991,8992,8993,8994,8995,8996,8997,8998,8999,9000,\tIter: 9000, train loss: -1.5007, avg nll: -1.5174, avg wnll: 36.1178, avg kl: 0.0001, mse: 0.003314, wmse: 0.027938, mae: 0.043561, val nll: -1.4945, val mse 0.0033, lr 0.000043047\n",
      "test nll: -1.3748, test mse: 0.0044\n",
      "saving.................\n",
      "done\n",
      "9001,9002,9003,9004,9005,9006,9007,9008,9009,9010,\tIter: 9010, train loss: -1.5457, avg nll: -1.5616, avg wnll: 31.7886, avg kl: 0.0002, mse: 0.003153, wmse: 0.026459, mae: 0.040834, val nll: -1.4729, val mse 0.0033, lr 0.000043047\n",
      "test nll: -1.4530, test mse: 0.0040\n",
      "9011,9012,9013,9014,9015,9016,9017,9018,"
     ]
    }
   ],
   "source": [
    "! python3 ../../train.py data_folder=../../datasets/ZTF_MCG+08-11-011 \\\n",
    "                        device=mps \\\n",
    "                        model.size.num_heads=1\\\n",
    "                        training.optimizer.lr=0.0001 \\\n",
    "                        dataset.start_col=1 \\\n",
    "                        dataset.sep=comma \\\n",
    "                        dataset.shuffle=false \\\n",
    "                        training.scheduler.reset=true \\\n",
    "                        save_at=200 \\\n",
    "                        training.niters=100000 \\\n",
    "                        print_at=10 \\\n",
    "                        training.loss.kl_annealing=True \\\n",
    "                        filter.min_length=0 \\\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0134cee3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py:233: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_name='config', config_path='conf')\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Namespace(data_folder='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_MCG+08-11-011', checkpoint='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_MCG+08-11-011-0.9715341329574585.h5', seed=2, device='mps', shuffle=False, start_col=1, test_split=0.2, sep='comma', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=8, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=100000, patience=100000, batch_size=2, k_iwae=1, lr=1e-05, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, reset=True, factor=0.9, lr_patience=500, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=False, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=True, min_length=0, print_at=1, save_at=200, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=12, is_bounded=True) 7023\n",
      "found 1 for band='r'\n",
      "found 1 for band='i'\n",
      "found 1 for band='g'\n",
      "max time:  1480.9922\n",
      "created union_tp attribute of length 3500\n",
      "dataset created, lcs.dataset.shape=(13, 3, 415, 3)\n",
      "train size: 10, valid size: 2, test size: 3\n",
      "=> loading checkpoint '/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_MCG+08-11-011-0.9715341329574585.h5'\n",
      "Namespace(data_folder='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_MCG+08-11-011', checkpoint='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_MCG+08-11-011-0.11807934194803238.h5', seed=2, device='mps', shuffle=False, start_col=1, test_split=0.2, sep=',', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=8, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=100000, patience=100000, batch_size=2, k_iwae=1, lr=1e-05, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, reset=True, factor=0.9, lr_patience=500, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=False, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=True, min_length=0, print_at=1, save_at=200, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=12, is_bounded=True)\n",
      "reset scheduler to args.factor=0.9, args.threshold=0.01,args.lr_patience=500, args.lr=1e-05\n",
      "loaded checkpoint w/ loss=-0.9715341329574585\n",
      "model_size=388294\n",
      "2801,/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/layers.py:83: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
      "\tIter: 2801, train loss: -0.9407, avg nll: -1.0018, avg wnll: 40.7782, avg kl: 0.0208, mse: 0.008056, wmse: 0.072982, mae: 0.070291, val nll: -0.9480, val mse 0.0091, lr 0.000010000\n",
      "2802,\tIter: 2802, train loss: -0.9498, avg nll: -1.0104, avg wnll: 41.1374, avg kl: 0.0213, mse: 0.007848, wmse: 0.072127, mae: 0.069223, val nll: -1.0029, val mse 0.0090, lr 0.000010000\n",
      "2803,\tIter: 2803, train loss: -0.9320, avg nll: -0.9946, avg wnll: 42.8882, avg kl: 0.0207, mse: 0.008372, wmse: 0.076247, mae: 0.070810, val nll: -0.9599, val mse 0.0086, lr 0.000010000\n",
      "2804,\tIter: 2804, train loss: -0.8467, avg nll: -0.9138, avg wnll: 51.4895, avg kl: 0.0204, mse: 0.009357, wmse: 0.084302, mae: 0.074995, val nll: -0.9480, val mse 0.0084, lr 0.000010000\n",
      "2805,\tIter: 2805, train loss: -0.8569, avg nll: -0.9253, avg wnll: 47.5313, avg kl: 0.0194, mse: 0.009817, wmse: 0.088231, mae: 0.075615, val nll: -0.8892, val mse 0.0102, lr 0.000010000\n",
      "2806,\tIter: 2806, train loss: -0.8886, avg nll: -0.9560, avg wnll: 45.0431, avg kl: 0.0220, mse: 0.009078, wmse: 0.082721, mae: 0.073879, val nll: -0.8165, val mse 0.0114, lr 0.000010000\n",
      "2807,\tIter: 2807, train loss: -0.9227, avg nll: -0.9849, avg wnll: 40.5852, avg kl: 0.0200, mse: 0.008427, wmse: 0.076877, mae: 0.072075, val nll: -0.9166, val mse 0.0102, lr 0.000010000\n",
      "2808,\tIter: 2808, train loss: -0.9616, avg nll: -1.0212, avg wnll: 40.3464, avg kl: 0.0203, mse: 0.007843, wmse: 0.071479, mae: 0.069065, val nll: -0.9943, val mse 0.0081, lr 0.000010000\n",
      "2809,\tIter: 2809, train loss: -0.9087, avg nll: -0.9716, avg wnll: 39.6733, avg kl: 0.0189, mse: 0.008807, wmse: 0.080080, mae: 0.072848, val nll: -0.9379, val mse 0.0095, lr 0.000010000\n",
      "2810,\tIter: 2810, train loss: -0.9005, avg nll: -0.9646, avg wnll: 41.5711, avg kl: 0.0199, mse: 0.008841, wmse: 0.080223, mae: 0.072759, val nll: -1.0139, val mse 0.0082, lr 0.000010000\n",
      "test nll: -1.0150, test mse: 0.0077\n",
      "2811,\tIter: 2811, train loss: -0.8677, avg nll: -0.9344, avg wnll: 47.6447, avg kl: 0.0201, mse: 0.009318, wmse: 0.084447, mae: 0.075498, val nll: -1.0132, val mse 0.0083, lr 0.000010000\n",
      "2812,\tIter: 2812, train loss: -0.9324, avg nll: -0.9951, avg wnll: 41.4010, avg kl: 0.0204, mse: 0.008467, wmse: 0.078072, mae: 0.071380, val nll: -1.0403, val mse 0.0075, lr 0.000010000\n",
      "2813,\tIter: 2813, train loss: -0.6518, avg nll: -0.7375, avg wnll: 61.0321, avg kl: 0.0195, mse: 0.013239, wmse: 0.118893, mae: 0.083361, val nll: -0.9903, val mse 0.0083, lr 0.000010000\n",
      "2814,\tIter: 2814, train loss: -0.8832, avg nll: -0.9482, avg wnll: 42.8952, avg kl: 0.0202, mse: 0.008951, wmse: 0.081631, mae: 0.073453, val nll: -0.9860, val mse 0.0086, lr 0.000010000\n",
      "2815,\tIter: 2815, train loss: -0.9102, avg nll: -0.9738, avg wnll: 39.9383, avg kl: 0.0204, mse: 0.008637, wmse: 0.078817, mae: 0.072678, val nll: -0.9685, val mse 0.0089, lr 0.000010000\n",
      "2816,\tIter: 2816, train loss: -0.9463, avg nll: -1.0067, avg wnll: 38.0522, avg kl: 0.0198, mse: 0.008121, wmse: 0.073702, mae: 0.070661, val nll: -0.9961, val mse 0.0080, lr 0.000010000\n",
      "2817,\tIter: 2817, train loss: -0.9324, avg nll: -0.9934, avg wnll: 37.8229, avg kl: 0.0191, mse: 0.008382, wmse: 0.076613, mae: 0.071750, val nll: -1.0038, val mse 0.0078, lr 0.000010000\n",
      "2818,\tIter: 2818, train loss: -0.9988, avg nll: -1.0566, avg wnll: 35.6170, avg kl: 0.0199, mse: 0.007569, wmse: 0.069317, mae: 0.067370, val nll: -0.9657, val mse 0.0087, lr 0.000010000\n",
      "2819,\tIter: 2819, train loss: -0.9797, avg nll: -1.0365, avg wnll: 34.9131, avg kl: 0.0189, mse: 0.007585, wmse: 0.068928, mae: 0.068115, val nll: -0.9356, val mse 0.0100, lr 0.000010000\n",
      "2820,\tIter: 2820, train loss: -0.9244, avg nll: -0.9865, avg wnll: 40.8336, avg kl: 0.0197, mse: 0.008474, wmse: 0.076696, mae: 0.071309, val nll: -0.9000, val mse 0.0095, lr 0.000010000\n",
      "test nll: -0.9510, test mse: 0.0092\n",
      "2821,\tIter: 2821, train loss: -0.8849, avg nll: -0.9508, avg wnll: 41.8175, avg kl: 0.0195, mse: 0.009287, wmse: 0.083740, mae: 0.073891, val nll: -0.7547, val mse 0.0116, lr 0.000010000\n",
      "2822,\tIter: 2822, train loss: -0.9875, avg nll: -1.0426, avg wnll: 36.4334, avg kl: 0.0190, mse: 0.007233, wmse: 0.066381, mae: 0.067223, val nll: -1.0119, val mse 0.0070, lr 0.000010000\n",
      "2823,\tIter: 2823, train loss: -0.9716, avg nll: -1.0320, avg wnll: 36.7385, avg kl: 0.0187, mse: 0.008337, wmse: 0.075427, mae: 0.069488, val nll: -0.9714, val mse 0.0089, lr 0.000010000\n",
      "2824,\tIter: 2824, train loss: -0.9227, avg nll: -0.9841, avg wnll: 40.3701, avg kl: 0.0188, mse: 0.008535, wmse: 0.076941, mae: 0.072370, val nll: -0.9477, val mse 0.0096, lr 0.000010000\n",
      "2825,\tIter: 2825, train loss: -1.0087, avg nll: -1.0638, avg wnll: 35.1709, avg kl: 0.0194, mse: 0.007135, wmse: 0.065299, mae: 0.065607, val nll: -0.9178, val mse 0.0096, lr 0.000010000\n",
      "2826,\tIter: 2826, train loss: -0.9074, avg nll: -0.9708, avg wnll: 41.2988, avg kl: 0.0191, mse: 0.008871, wmse: 0.081040, mae: 0.073266, val nll: -0.8434, val mse 0.0111, lr 0.000010000\n",
      "2827,\tIter: 2827, train loss: -0.9736, avg nll: -1.0314, avg wnll: 38.2936, avg kl: 0.0197, mse: 0.007609, wmse: 0.069403, mae: 0.067239, val nll: -0.8633, val mse 0.0095, lr 0.000010000\n",
      "2828,\tIter: 2828, train loss: -0.9305, avg nll: -0.9900, avg wnll: 42.7182, avg kl: 0.0182, mse: 0.008264, wmse: 0.074715, mae: 0.069824, val nll: -1.0861, val mse 0.0070, lr 0.000010000\n",
      "2829,\tIter: 2829, train loss: -0.9273, avg nll: -0.9885, avg wnll: 43.5923, avg kl: 0.0191, mse: 0.008426, wmse: 0.076996, mae: 0.071289, val nll: -0.9474, val mse 0.0089, lr 0.000010000\n",
      "2830,\tIter: 2830, train loss: -0.9667, avg nll: -1.0258, avg wnll: 40.8185, avg kl: 0.0191, mse: 0.008017, wmse: 0.072750, mae: 0.069298, val nll: -0.8985, val mse 0.0105, lr 0.000010000\n",
      "test nll: -1.0932, test mse: 0.0066\n",
      "2831,\tIter: 2831, train loss: -0.9985, avg nll: -1.0544, avg wnll: 38.1812, avg kl: 0.0195, mse: 0.007291, wmse: 0.066606, mae: 0.066413, val nll: -0.9839, val mse 0.0084, lr 0.000010000\n",
      "2832,\tIter: 2832, train loss: -0.9087, avg nll: -0.9708, avg wnll: 43.9201, avg kl: 0.0188, mse: 0.008658, wmse: 0.079237, mae: 0.073707, val nll: -1.0381, val mse 0.0077, lr 0.000010000\n",
      "2833,\tIter: 2833, train loss: -0.9807, avg nll: -1.0372, avg wnll: 36.1900, avg kl: 0.0191, mse: 0.007478, wmse: 0.067960, mae: 0.066976, val nll: -0.9306, val mse 0.0087, lr 0.000010000\n",
      "2834,\tIter: 2834, train loss: -0.8823, avg nll: -0.9480, avg wnll: 47.4814, avg kl: 0.0198, mse: 0.009177, wmse: 0.083760, mae: 0.074586, val nll: -0.9538, val mse 0.0088, lr 0.000010000\n",
      "2835,\tIter: 2835, train loss: -0.9151, avg nll: -0.9758, avg wnll: 38.7211, avg kl: 0.0179, mse: 0.008552, wmse: 0.077816, mae: 0.072401, val nll: -0.9217, val mse 0.0095, lr 0.000010000\n",
      "2836,\tIter: 2836, train loss: -0.8752, avg nll: -0.9411, avg wnll: 49.2547, avg kl: 0.0199, mse: 0.009203, wmse: 0.084176, mae: 0.075093, val nll: -0.9921, val mse 0.0084, lr 0.000010000\n",
      "2837,\tIter: 2837, train loss: -0.8489, avg nll: -0.9166, avg wnll: 44.7981, avg kl: 0.0193, mse: 0.009687, wmse: 0.087265, mae: 0.075833, val nll: -0.9562, val mse 0.0091, lr 0.000010000\n",
      "2838,\tIter: 2838, train loss: -0.8287, avg nll: -0.8968, avg wnll: 52.2596, avg kl: 0.0213, mse: 0.009354, wmse: 0.085451, mae: 0.076006, val nll: -0.9790, val mse 0.0082, lr 0.000010000\n",
      "2839,\tIter: 2839, train loss: -0.8690, avg nll: -0.9347, avg wnll: 42.2923, avg kl: 0.0187, mse: 0.009399, wmse: 0.086154, mae: 0.074777, val nll: -0.9253, val mse 0.0094, lr 0.000010000\n",
      "2840,\tIter: 2840, train loss: -0.8895, avg nll: -0.9549, avg wnll: 42.5497, avg kl: 0.0203, mse: 0.009003, wmse: 0.081721, mae: 0.073232, val nll: -1.1069, val mse 0.0064, lr 0.000010000\n",
      "test nll: -0.8611, test mse: 0.0109\n",
      "2841,\tIter: 2841, train loss: -0.8692, avg nll: -0.9369, avg wnll: 40.7583, avg kl: 0.0196, mse: 0.009622, wmse: 0.087088, mae: 0.076052, val nll: -1.0588, val mse 0.0070, lr 0.000010000\n",
      "2842,\tIter: 2842, train loss: -0.9255, avg nll: -0.9887, avg wnll: 40.8189, avg kl: 0.0213, mse: 0.008393, wmse: 0.075571, mae: 0.070881, val nll: -0.9705, val mse 0.0091, lr 0.000010000\n",
      "2843,\tIter: 2843, train loss: -0.9628, avg nll: -1.0218, avg wnll: 35.2102, avg kl: 0.0200, mse: 0.007808, wmse: 0.070995, mae: 0.069505, val nll: -1.0233, val mse 0.0075, lr 0.000010000\n",
      "2844,\tIter: 2844, train loss: -0.9517, avg nll: -1.0103, avg wnll: 40.0791, avg kl: 0.0189, mse: 0.007930, wmse: 0.072616, mae: 0.070601, val nll: -0.9440, val mse 0.0094, lr 0.000010000\n",
      "2845,\tIter: 2845, train loss: -0.9650, avg nll: -1.0232, avg wnll: 38.3121, avg kl: 0.0196, mse: 0.007723, wmse: 0.070287, mae: 0.068274, val nll: -1.0124, val mse 0.0082, lr 0.000010000\n",
      "2846,\tIter: 2846, train loss: -1.0259, avg nll: -1.0790, avg wnll: 34.4123, avg kl: 0.0181, mse: 0.007028, wmse: 0.064014, mae: 0.065315, val nll: -0.9318, val mse 0.0100, lr 0.000010000\n",
      "2847,\tIter: 2847, train loss: -0.9860, avg nll: -1.0424, avg wnll: 36.2645, avg kl: 0.0188, mse: 0.007497, wmse: 0.068542, mae: 0.066948, val nll: -1.0622, val mse 0.0076, lr 0.000010000\n",
      "2848,\tIter: 2848, train loss: -1.0087, avg nll: -1.0638, avg wnll: 37.3252, avg kl: 0.0194, mse: 0.007145, wmse: 0.065173, mae: 0.065647, val nll: -0.9075, val mse 0.0102, lr 0.000010000\n",
      "2849,\tIter: 2849, train loss: -0.9362, avg nll: -0.9981, avg wnll: 39.9110, avg kl: 0.0194, mse: 0.008498, wmse: 0.077724, mae: 0.070985, val nll: -0.9202, val mse 0.0094, lr 0.000010000\n",
      "2850,\tIter: 2850, train loss: -0.9274, avg nll: -0.9904, avg wnll: 41.6341, avg kl: 0.0191, mse: 0.008791, wmse: 0.079760, mae: 0.071683, val nll: -0.9715, val mse 0.0082, lr 0.000010000\n",
      "test nll: -1.0085, test mse: 0.0080\n",
      "2851,\tIter: 2851, train loss: -0.9457, avg nll: -1.0068, avg wnll: 41.6082, avg kl: 0.0193, mse: 0.008371, wmse: 0.076178, mae: 0.071012, val nll: -0.8475, val mse 0.0113, lr 0.000010000\n",
      "2852,\tIter: 2852, train loss: -1.0043, avg nll: -1.0580, avg wnll: 35.8227, avg kl: 0.0181, mse: 0.007117, wmse: 0.064762, mae: 0.067040, val nll: -1.0203, val mse 0.0077, lr 0.000010000\n",
      "2853,\tIter: 2853, train loss: -0.9848, avg nll: -1.0416, avg wnll: 38.2558, avg kl: 0.0188, mse: 0.007616, wmse: 0.069023, mae: 0.068213, val nll: -0.9123, val mse 0.0092, lr 0.000010000\n",
      "2854,\tIter: 2854, train loss: -0.9971, avg nll: -1.0537, avg wnll: 36.2810, avg kl: 0.0196, mse: 0.007408, wmse: 0.067836, mae: 0.066420, val nll: -1.0977, val mse 0.0064, lr 0.000010000\n",
      "2855,\tIter: 2855, train loss: -0.8333, avg nll: -0.9037, avg wnll: 49.1692, avg kl: 0.0201, mse: 0.010059, wmse: 0.090946, mae: 0.076838, val nll: -0.9497, val mse 0.0086, lr 0.000010000\n",
      "2856,\tIter: 2856, train loss: -0.9128, avg nll: -0.9767, avg wnll: 46.3453, avg kl: 0.0205, mse: 0.008677, wmse: 0.079277, mae: 0.072037, val nll: -0.9419, val mse 0.0093, lr 0.000010000\n",
      "2857,\tIter: 2857, train loss: -0.9148, avg nll: -0.9787, avg wnll: 44.1394, avg kl: 0.0187, mse: 0.009053, wmse: 0.082113, mae: 0.073015, val nll: -0.9612, val mse 0.0085, lr 0.000010000\n",
      "2858,\tIter: 2858, train loss: -0.9526, avg nll: -1.0117, avg wnll: 42.5082, avg kl: 0.0198, mse: 0.007868, wmse: 0.072653, mae: 0.069238, val nll: -1.0946, val mse 0.0068, lr 0.000010000\n",
      "2859,\tIter: 2859, train loss: -0.9542, avg nll: -1.0122, avg wnll: 41.7341, avg kl: 0.0183, mse: 0.007937, wmse: 0.072681, mae: 0.069053, val nll: -0.9278, val mse 0.0099, lr 0.000010000\n",
      "2860,\tIter: 2860, train loss: -0.9703, avg nll: -1.0261, avg wnll: 36.4602, avg kl: 0.0175, mse: 0.007684, wmse: 0.069517, mae: 0.068434, val nll: -1.0743, val mse 0.0071, lr 0.000010000\n",
      "test nll: -1.0287, test mse: 0.0076\n",
      "2861,\tIter: 2861, train loss: -0.9497, avg nll: -1.0090, avg wnll: 42.3431, avg kl: 0.0193, mse: 0.007992, wmse: 0.072759, mae: 0.070174, val nll: -0.9958, val mse 0.0083, lr 0.000010000\n",
      "2862,\tIter: 2862, train loss: -0.9341, avg nll: -0.9946, avg wnll: 40.7896, avg kl: 0.0179, mse: 0.008527, wmse: 0.077441, mae: 0.072032, val nll: -0.9655, val mse 0.0088, lr 0.000010000\n",
      "2863,\tIter: 2863, train loss: -0.9276, avg nll: -0.9863, avg wnll: 42.8877, avg kl: 0.0174, mse: 0.008249, wmse: 0.074949, mae: 0.070583, val nll: -1.0238, val mse 0.0072, lr 0.000010000\n",
      "2864,\tIter: 2864, train loss: -0.8983, avg nll: -0.9612, avg wnll: 44.6066, avg kl: 0.0193, mse: 0.008730, wmse: 0.079411, mae: 0.073796, val nll: -1.0246, val mse 0.0076, lr 0.000010000\n",
      "2865,\tIter: 2865, train loss: -0.9146, avg nll: -0.9775, avg wnll: 43.6016, avg kl: 0.0201, mse: 0.008556, wmse: 0.077449, mae: 0.073069, val nll: -0.9490, val mse 0.0088, lr 0.000010000\n",
      "2866,\tIter: 2866, train loss: -0.9215, avg nll: -0.9855, avg wnll: 44.9018, avg kl: 0.0224, mse: 0.008309, wmse: 0.076027, mae: 0.071050, val nll: -0.8421, val mse 0.0108, lr 0.000010000\n",
      "2867,\tIter: 2867, train loss: -0.6337, avg nll: -0.7252, avg wnll: 59.1237, avg kl: 0.0206, mse: 0.014179, wmse: 0.129468, mae: 0.088020, val nll: -0.9888, val mse 0.0079, lr 0.000010000\n",
      "2868,\tIter: 2868, train loss: -0.9366, avg nll: -0.9964, avg wnll: 43.5307, avg kl: 0.0199, mse: 0.007983, wmse: 0.072932, mae: 0.070373, val nll: -1.0526, val mse 0.0074, lr 0.000010000\n",
      "2869,\tIter: 2869, train loss: -0.9739, avg nll: -1.0307, avg wnll: 37.8534, avg kl: 0.0185, mse: 0.007649, wmse: 0.069817, mae: 0.068052, val nll: -0.9416, val mse 0.0094, lr 0.000010000\n",
      "2870,\tIter: 2870, train loss: -0.9685, avg nll: -1.0250, avg wnll: 38.5843, avg kl: 0.0176, mse: 0.007778, wmse: 0.071055, mae: 0.068261, val nll: -0.9662, val mse 0.0089, lr 0.000010000\n",
      "test nll: -0.9938, test mse: 0.0083\n",
      "2871,\tIter: 2871, train loss: -0.9970, avg nll: -1.0540, avg wnll: 35.9105, avg kl: 0.0190, mse: 0.007600, wmse: 0.068700, mae: 0.067845, val nll: -1.0142, val mse 0.0078, lr 0.000010000\n",
      "2872,\tIter: 2872, train loss: -0.9584, avg nll: -1.0162, avg wnll: 36.7477, avg kl: 0.0178, mse: 0.008010, wmse: 0.072072, mae: 0.068937, val nll: -1.0444, val mse 0.0072, lr 0.000010000\n",
      "2873,\tIter: 2873, train loss: -0.9726, avg nll: -1.0300, avg wnll: 36.1379, avg kl: 0.0190, mse: 0.007675, wmse: 0.069553, mae: 0.068009, val nll: -1.0295, val mse 0.0078, lr 0.000010000\n",
      "2874,\tIter: 2874, train loss: -0.9624, avg nll: -1.0191, avg wnll: 39.0163, avg kl: 0.0181, mse: 0.007724, wmse: 0.071059, mae: 0.069114, val nll: -1.0997, val mse 0.0064, lr 0.000010000\n",
      "2875,\tIter: 2875, train loss: -0.9768, avg nll: -1.0321, avg wnll: 37.7574, avg kl: 0.0173, mse: 0.007592, wmse: 0.069041, mae: 0.068504, val nll: -1.0262, val mse 0.0076, lr 0.000010000\n",
      "2876,\tIter: 2876, train loss: -0.9799, avg nll: -1.0364, avg wnll: 38.6176, avg kl: 0.0183, mse: 0.007650, wmse: 0.069426, mae: 0.067688, val nll: -1.1185, val mse 0.0070, lr 0.000010000\n",
      "2877,\tIter: 2877, train loss: -0.8862, avg nll: -0.9504, avg wnll: 45.6022, avg kl: 0.0181, mse: 0.009215, wmse: 0.084055, mae: 0.073969, val nll: -1.0665, val mse 0.0067, lr 0.000010000\n",
      "2878,\tIter: 2878, train loss: -1.0102, avg nll: -1.0645, avg wnll: 37.4160, avg kl: 0.0177, mse: 0.007322, wmse: 0.066441, mae: 0.066205, val nll: -0.9009, val mse 0.0095, lr 0.000010000\n",
      "2879,\tIter: 2879, train loss: -0.9947, avg nll: -1.0506, avg wnll: 39.6294, avg kl: 0.0187, mse: 0.007442, wmse: 0.068139, mae: 0.066524, val nll: -1.0216, val mse 0.0078, lr 0.000010000\n",
      "2880,\tIter: 2880, train loss: -0.9664, avg nll: -1.0247, avg wnll: 43.0180, avg kl: 0.0184, mse: 0.007989, wmse: 0.072846, mae: 0.069185, val nll: -0.8730, val mse 0.0101, lr 0.000010000\n",
      "test nll: -0.9149, test mse: 0.0092\n",
      "2881,\tIter: 2881, train loss: -0.8839, avg nll: -0.9483, avg wnll: 44.9700, avg kl: 0.0187, mse: 0.009149, wmse: 0.082875, mae: 0.074047, val nll: -1.0352, val mse 0.0082, lr 0.000010000\n",
      "2882,\tIter: 2882, train loss: -0.9947, avg nll: -1.0505, avg wnll: 38.7420, avg kl: 0.0191, mse: 0.007333, wmse: 0.066970, mae: 0.067328, val nll: -1.0715, val mse 0.0071, lr 0.000010000\n",
      "2883,\tIter: 2883, train loss: -0.9976, avg nll: -1.0516, avg wnll: 39.0227, avg kl: 0.0171, mse: 0.007387, wmse: 0.067330, mae: 0.067295, val nll: -1.0398, val mse 0.0080, lr 0.000010000\n",
      "2884,\tIter: 2884, train loss: -1.0134, avg nll: -1.0685, avg wnll: 36.8001, avg kl: 0.0183, mse: 0.007349, wmse: 0.066088, mae: 0.066205, val nll: -0.7297, val mse 0.0126, lr 0.000010000\n",
      "2885,\tIter: 2885, train loss: -0.9296, avg nll: -0.9902, avg wnll: 47.5759, avg kl: 0.0179, mse: 0.008536, wmse: 0.077932, mae: 0.072135, val nll: -1.1013, val mse 0.0068, lr 0.000010000\n",
      "2886,\tIter: 2886, train loss: -0.9299, avg nll: -0.9891, avg wnll: 43.0931, avg kl: 0.0182, mse: 0.008193, wmse: 0.074093, mae: 0.070359, val nll: -1.0215, val mse 0.0082, lr 0.000010000\n",
      "2887,\tIter: 2887, train loss: -0.9721, avg nll: -1.0304, avg wnll: 39.5599, avg kl: 0.0188, mse: 0.007896, wmse: 0.072027, mae: 0.068919, val nll: -1.0831, val mse 0.0068, lr 0.000010000\n",
      "2888,\tIter: 2888, train loss: -1.0022, avg nll: -1.0547, avg wnll: 38.3218, avg kl: 0.0164, mse: 0.007234, wmse: 0.066049, mae: 0.065797, val nll: -1.0469, val mse 0.0070, lr 0.000010000\n",
      "2889,\tIter: 2889, train loss: -1.0112, avg nll: -1.0646, avg wnll: 37.8461, avg kl: 0.0171, mse: 0.007246, wmse: 0.065926, mae: 0.066164, val nll: -0.9469, val mse 0.0091, lr 0.000010000\n",
      "2890,\tIter: 2890, train loss: -0.7740, avg nll: -0.8442, avg wnll: 51.4885, avg kl: 0.0168, mse: 0.010700, wmse: 0.096732, mae: 0.076665, val nll: -1.0275, val mse 0.0079, lr 0.000010000\n",
      "test nll: -0.8627, test mse: 0.0107\n",
      "2891,\tIter: 2891, train loss: -1.0025, avg nll: -1.0558, avg wnll: 37.4357, avg kl: 0.0169, mse: 0.007278, wmse: 0.065807, mae: 0.066265, val nll: -1.0509, val mse 0.0072, lr 0.000010000\n",
      "2892,\tIter: 2892, train loss: -0.9700, avg nll: -1.0261, avg wnll: 41.2040, avg kl: 0.0172, mse: 0.007779, wmse: 0.070866, mae: 0.068133, val nll: -0.9550, val mse 0.0091, lr 0.000010000\n",
      "2893,\tIter: 2893, train loss: -0.9791, avg nll: -1.0345, avg wnll: 38.9829, avg kl: 0.0169, mse: 0.007709, wmse: 0.069789, mae: 0.068640, val nll: -1.0888, val mse 0.0068, lr 0.000010000\n",
      "2894,\tIter: 2894, train loss: -0.9821, avg nll: -1.0373, avg wnll: 41.2534, avg kl: 0.0169, mse: 0.007668, wmse: 0.069186, mae: 0.068422, val nll: -0.9618, val mse 0.0084, lr 0.000010000\n",
      "2895,\tIter: 2895, train loss: -0.9859, avg nll: -1.0397, avg wnll: 40.7269, avg kl: 0.0166, mse: 0.007447, wmse: 0.067689, mae: 0.066526, val nll: -1.0035, val mse 0.0079, lr 0.000010000\n",
      "2896,\tIter: 2896, train loss: -0.9645, avg nll: -1.0207, avg wnll: 41.7443, avg kl: 0.0175, mse: 0.007756, wmse: 0.070931, mae: 0.068869, val nll: -0.7788, val mse 0.0120, lr 0.000010000\n",
      "2897,\tIter: 2897, train loss: -0.9830, avg nll: -1.0372, avg wnll: 40.0519, avg kl: 0.0164, mse: 0.007564, wmse: 0.069337, mae: 0.067983, val nll: -1.0327, val mse 0.0078, lr 0.000010000\n",
      "2898,\tIter: 2898, train loss: -0.9996, avg nll: -1.0548, avg wnll: 40.9347, avg kl: 0.0183, mse: 0.007372, wmse: 0.066910, mae: 0.067366, val nll: -1.0079, val mse 0.0081, lr 0.000010000\n",
      "2899,\tIter: 2899, train loss: -0.9712, avg nll: -1.0292, avg wnll: 40.4344, avg kl: 0.0182, mse: 0.007971, wmse: 0.072723, mae: 0.068469, val nll: -0.9738, val mse 0.0089, lr 0.000010000\n",
      "2900,\tIter: 2900, train loss: -0.9908, avg nll: -1.0460, avg wnll: 42.3547, avg kl: 0.0179, mse: 0.007457, wmse: 0.067589, mae: 0.067920, val nll: -0.9979, val mse 0.0078, lr 0.000010000\n",
      "test nll: -0.9869, test mse: 0.0081\n",
      "2901,\tIter: 2901, train loss: -0.9890, avg nll: -1.0441, avg wnll: 39.1512, avg kl: 0.0178, mse: 0.007454, wmse: 0.067829, mae: 0.067684, val nll: -0.8788, val mse 0.0100, lr 0.000010000\n",
      "2902,\tIter: 2902, train loss: -0.9535, avg nll: -1.0085, avg wnll: 38.9858, avg kl: 0.0160, mse: 0.007804, wmse: 0.071293, mae: 0.069578, val nll: -0.8961, val mse 0.0099, lr 0.000010000\n",
      "2903,\tIter: 2903, train loss: -0.9770, avg nll: -1.0345, avg wnll: 41.6083, avg kl: 0.0174, mse: 0.008009, wmse: 0.072979, mae: 0.069462, val nll: -0.8002, val mse 0.0113, lr 0.000010000\n",
      "2904,\tIter: 2904, train loss: -0.9358, avg nll: -0.9953, avg wnll: 44.5691, avg kl: 0.0184, mse: 0.008209, wmse: 0.073905, mae: 0.071331, val nll: -0.7810, val mse 0.0130, lr 0.000010000\n",
      "2905,\tIter: 2905, train loss: -1.0053, avg nll: -1.0585, avg wnll: 39.4361, avg kl: 0.0171, mse: 0.007239, wmse: 0.065940, mae: 0.067110, val nll: -1.0321, val mse 0.0077, lr 0.000010000\n",
      "2906,\tIter: 2906, train loss: -1.0178, avg nll: -1.0697, avg wnll: 37.0823, avg kl: 0.0167, mse: 0.007032, wmse: 0.063973, mae: 0.066296, val nll: -1.0364, val mse 0.0076, lr 0.000010000\n",
      "2907,\tIter: 2907, train loss: -1.0027, avg nll: -1.0566, avg wnll: 40.7834, avg kl: 0.0172, mse: 0.007337, wmse: 0.066907, mae: 0.066699, val nll: 1.0425, val mse 0.0417, lr 0.000010000\n",
      "2908,\tIter: 2908, train loss: -0.9589, avg nll: -1.0168, avg wnll: 41.2382, avg kl: 0.0173, mse: 0.008127, wmse: 0.073907, mae: 0.069220, val nll: -0.9557, val mse 0.0080, lr 0.000010000\n",
      "2909,\tIter: 2909, train loss: -0.9991, avg nll: -1.0551, avg wnll: 39.9518, avg kl: 0.0186, mse: 0.007480, wmse: 0.067509, mae: 0.066723, val nll: -1.1314, val mse 0.0063, lr 0.000010000\n",
      "2910,\tIter: 2910, train loss: -1.0220, avg nll: -1.0739, avg wnll: 38.9981, avg kl: 0.0166, mse: 0.007066, wmse: 0.064394, mae: 0.064797, val nll: -0.9638, val mse 0.0088, lr 0.000010000\n",
      "test nll: -1.0271, test mse: 0.0079\n",
      "2911,\tIter: 2911, train loss: -0.9220, avg nll: -0.9840, avg wnll: 46.1578, avg kl: 0.0190, mse: 0.008612, wmse: 0.078354, mae: 0.071719, val nll: -1.0361, val mse 0.0076, lr 0.000010000\n",
      "2912,\tIter: 2912, train loss: -0.9175, avg nll: -0.9766, avg wnll: 46.3000, avg kl: 0.0168, mse: 0.008461, wmse: 0.076066, mae: 0.071893, val nll: -0.8300, val mse 0.0115, lr 0.000010000\n",
      "2913,\tIter: 2913, train loss: -0.9859, avg nll: -1.0419, avg wnll: 40.0866, avg kl: 0.0182, mse: 0.007568, wmse: 0.068320, mae: 0.067299, val nll: -1.0578, val mse 0.0073, lr 0.000010000\n",
      "2914,\tIter: 2914, train loss: -1.0061, avg nll: -1.0601, avg wnll: 38.9972, avg kl: 0.0165, mse: 0.007498, wmse: 0.068649, mae: 0.067577, val nll: -0.8479, val mse 0.0111, lr 0.000010000\n",
      "2915,\tIter: 2915, train loss: -0.9811, avg nll: -1.0348, avg wnll: 43.0185, avg kl: 0.0158, mse: 0.007599, wmse: 0.069052, mae: 0.067067, val nll: -1.0447, val mse 0.0077, lr 0.000010000\n",
      "2916,\tIter: 2916, train loss: -0.9944, avg nll: -1.0487, avg wnll: 40.1328, avg kl: 0.0166, mse: 0.007554, wmse: 0.068537, mae: 0.067709, val nll: -0.8654, val mse 0.0095, lr 0.000010000\n",
      "2917,\tIter: 2917, train loss: -0.9874, avg nll: -1.0422, avg wnll: 41.5272, avg kl: 0.0170, mse: 0.007559, wmse: 0.069421, mae: 0.067889, val nll: -1.0469, val mse 0.0074, lr 0.000010000\n",
      "2918,\tIter: 2918, train loss: -1.0077, avg nll: -1.0595, avg wnll: 41.5073, avg kl: 0.0157, mse: 0.007225, wmse: 0.065257, mae: 0.066858, val nll: -0.8702, val mse 0.0111, lr 0.000010000\n",
      "2919,\tIter: 2919, train loss: -0.9690, avg nll: -1.0260, avg wnll: 41.7454, avg kl: 0.0175, mse: 0.007902, wmse: 0.072101, mae: 0.069494, val nll: -1.0082, val mse 0.0080, lr 0.000010000\n",
      "2920,\tIter: 2920, train loss: -1.0100, avg nll: -1.0644, avg wnll: 38.5565, avg kl: 0.0178, mse: 0.007343, wmse: 0.066499, mae: 0.065913, val nll: -1.0213, val mse 0.0081, lr 0.000010000\n",
      "test nll: -1.0669, test mse: 0.0074\n",
      "2921,\tIter: 2921, train loss: -0.9811, avg nll: -1.0378, avg wnll: 41.3802, avg kl: 0.0185, mse: 0.007650, wmse: 0.069096, mae: 0.068249, val nll: -1.1101, val mse 0.0065, lr 0.000010000\n",
      "2922,\tIter: 2922, train loss: -0.9461, avg nll: -1.0039, avg wnll: 43.3690, avg kl: 0.0166, mse: 0.008254, wmse: 0.074397, mae: 0.069946, val nll: -1.0064, val mse 0.0075, lr 0.000010000\n",
      "2923,\tIter: 2923, train loss: -0.9971, avg nll: -1.0506, avg wnll: 39.6661, avg kl: 0.0168, mse: 0.007361, wmse: 0.066670, mae: 0.066673, val nll: -0.9108, val mse 0.0095, lr 0.000010000\n",
      "2924,\tIter: 2924, train loss: -1.0031, avg nll: -1.0572, avg wnll: 42.6051, avg kl: 0.0176, mse: 0.007307, wmse: 0.066557, mae: 0.066336, val nll: -0.8913, val mse 0.0103, lr 0.000010000\n",
      "2925,\tIter: 2925, train loss: -0.9715, avg nll: -1.0266, avg wnll: 42.8251, avg kl: 0.0163, mse: 0.007778, wmse: 0.071583, mae: 0.068705, val nll: -1.0106, val mse 0.0082, lr 0.000010000\n",
      "2926,\tIter: 2926, train loss: -0.9952, avg nll: -1.0481, avg wnll: 40.1756, avg kl: 0.0165, mse: 0.007298, wmse: 0.066520, mae: 0.066180, val nll: -0.9858, val mse 0.0086, lr 0.000010000\n",
      "2927,\tIter: 2927, train loss: -1.0195, avg nll: -1.0725, avg wnll: 35.9409, avg kl: 0.0175, mse: 0.007114, wmse: 0.065053, mae: 0.065678, val nll: -0.9559, val mse 0.0090, lr 0.000010000\n",
      "2928,\tIter: 2928, train loss: -0.9801, avg nll: -1.0353, avg wnll: 38.6784, avg kl: 0.0164, mse: 0.007750, wmse: 0.070177, mae: 0.068596, val nll: -1.1077, val mse 0.0066, lr 0.000010000\n",
      "2929,\tIter: 2929, train loss: -0.9356, avg nll: -0.9958, avg wnll: 45.9943, avg kl: 0.0173, mse: 0.008589, wmse: 0.077665, mae: 0.071520, val nll: -1.0460, val mse 0.0072, lr 0.000010000\n",
      "2930,\tIter: 2930, train loss: -0.9338, avg nll: -0.9921, avg wnll: 45.0681, avg kl: 0.0170, mse: 0.008242, wmse: 0.075012, mae: 0.070152, val nll: -1.1218, val mse 0.0065, lr 0.000010000\n",
      "test nll: -1.0407, test mse: 0.0076\n",
      "2931,\tIter: 2931, train loss: -0.9349, avg nll: -0.9942, avg wnll: 45.2569, avg kl: 0.0168, mse: 0.008497, wmse: 0.076802, mae: 0.072216, val nll: -0.9747, val mse 0.0086, lr 0.000010000\n",
      "2932,\tIter: 2932, train loss: -0.9837, avg nll: -1.0374, avg wnll: 40.7554, avg kl: 0.0159, mse: 0.007545, wmse: 0.068992, mae: 0.067755, val nll: -1.0081, val mse 0.0084, lr 0.000010000\n",
      "2933,\tIter: 2933, train loss: -0.9984, avg nll: -1.0528, avg wnll: 39.9527, avg kl: 0.0169, mse: 0.007488, wmse: 0.068215, mae: 0.066838, val nll: -1.0630, val mse 0.0070, lr 0.000010000\n",
      "2934,\tIter: 2934, train loss: -1.0077, avg nll: -1.0613, avg wnll: 37.2339, avg kl: 0.0169, mse: 0.007348, wmse: 0.066719, mae: 0.065302, val nll: -1.0613, val mse 0.0070, lr 0.000010000\n",
      "2935,\tIter: 2935, train loss: -1.0228, avg nll: -1.0748, avg wnll: 37.9627, avg kl: 0.0170, mse: 0.006990, wmse: 0.063514, mae: 0.065581, val nll: -0.9824, val mse 0.0089, lr 0.000010000\n",
      "2936,\tIter: 2936, train loss: -0.9685, avg nll: -1.0254, avg wnll: 42.9136, avg kl: 0.0175, mse: 0.007872, wmse: 0.071656, mae: 0.068448, val nll: -1.0033, val mse 0.0080, lr 0.000010000\n",
      "2937,\tIter: 2937, train loss: -0.9933, avg nll: -1.0480, avg wnll: 39.7024, avg kl: 0.0162, mse: 0.007688, wmse: 0.069776, mae: 0.068135, val nll: -1.0353, val mse 0.0074, lr 0.000010000\n",
      "2938,\tIter: 2938, train loss: -0.9510, avg nll: -1.0097, avg wnll: 44.6221, avg kl: 0.0173, mse: 0.008280, wmse: 0.075529, mae: 0.069950, val nll: -1.0399, val mse 0.0069, lr 0.000010000\n",
      "2939,\tIter: 2939, train loss: -1.0644, avg nll: -1.1131, avg wnll: 34.8621, avg kl: 0.0163, mse: 0.006480, wmse: 0.059037, mae: 0.061929, val nll: -0.9651, val mse 0.0083, lr 0.000010000\n",
      "2940,\tIter: 2940, train loss: -1.0380, avg nll: -1.0890, avg wnll: 39.9800, avg kl: 0.0164, mse: 0.006916, wmse: 0.063567, mae: 0.064335, val nll: -0.9493, val mse 0.0085, lr 0.000010000\n",
      "test nll: -0.9820, test mse: 0.0082\n",
      "2941,\tIter: 2941, train loss: -1.0068, avg nll: -1.0601, avg wnll: 41.7462, avg kl: 0.0167, mse: 0.007301, wmse: 0.066128, mae: 0.066583, val nll: -1.0548, val mse 0.0072, lr 0.000010000\n",
      "2942,\tIter: 2942, train loss: -1.0199, avg nll: -1.0730, avg wnll: 40.3678, avg kl: 0.0168, mse: 0.007249, wmse: 0.066584, mae: 0.067423, val nll: -1.0825, val mse 0.0070, lr 0.000010000\n",
      "2943,\tIter: 2943, train loss: -0.9697, avg nll: -1.0278, avg wnll: 43.6116, avg kl: 0.0171, mse: 0.008193, wmse: 0.074003, mae: 0.068816, val nll: -0.9534, val mse 0.0098, lr 0.000010000\n",
      "2944,\tIter: 2944, train loss: -1.0508, avg nll: -1.1004, avg wnll: 37.3931, avg kl: 0.0157, mse: 0.006793, wmse: 0.061298, mae: 0.063968, val nll: -0.9727, val mse 0.0085, lr 0.000010000\n",
      "2945,\tIter: 2945, train loss: -0.9173, avg nll: -0.9787, avg wnll: 47.3004, avg kl: 0.0163, mse: 0.009003, wmse: 0.082135, mae: 0.072478, val nll: -0.9973, val mse 0.0081, lr 0.000010000\n",
      "2946,\tIter: 2946, train loss: -0.9241, avg nll: -0.9836, avg wnll: 46.3621, avg kl: 0.0169, mse: 0.008513, wmse: 0.077863, mae: 0.072010, val nll: -0.9927, val mse 0.0083, lr 0.000010000\n",
      "2947,\tIter: 2947, train loss: -0.9482, avg nll: -1.0053, avg wnll: 46.7366, avg kl: 0.0172, mse: 0.007975, wmse: 0.072320, mae: 0.069564, val nll: -1.0177, val mse 0.0075, lr 0.000010000\n",
      "2948,\tIter: 2948, train loss: -0.9320, avg nll: -0.9908, avg wnll: 45.4876, avg kl: 0.0177, mse: 0.008228, wmse: 0.075320, mae: 0.071352, val nll: -1.1146, val mse 0.0061, lr 0.000010000\n",
      "2949,\tIter: 2949, train loss: -0.9883, avg nll: -1.0439, avg wnll: 40.0056, avg kl: 0.0172, mse: 0.007681, wmse: 0.069111, mae: 0.068576, val nll: -1.0330, val mse 0.0076, lr 0.000010000\n",
      "2950,\tIter: 2950, train loss: -1.0167, avg nll: -1.0707, avg wnll: 37.8067, avg kl: 0.0176, mse: 0.007276, wmse: 0.066606, mae: 0.065241, val nll: -0.9091, val mse 0.0094, lr 0.000010000\n",
      "test nll: -1.0131, test mse: 0.0080\n",
      "2951,\tIter: 2951, train loss: -0.9733, avg nll: -1.0285, avg wnll: 43.8114, avg kl: 0.0166, mse: 0.007722, wmse: 0.069911, mae: 0.068812, val nll: -1.0343, val mse 0.0078, lr 0.000010000\n",
      "2952,\tIter: 2952, train loss: -1.0085, avg nll: -1.0616, avg wnll: 40.2756, avg kl: 0.0165, mse: 0.007320, wmse: 0.066210, mae: 0.066065, val nll: -0.9885, val mse 0.0091, lr 0.000010000\n",
      "2953,\tIter: 2953, train loss: -1.0252, avg nll: -1.0751, avg wnll: 37.0683, avg kl: 0.0147, mse: 0.007041, wmse: 0.063959, mae: 0.065029, val nll: -0.9127, val mse 0.0097, lr 0.000010000\n",
      "2954,\tIter: 2954, train loss: -0.9641, avg nll: -1.0196, avg wnll: 47.1545, avg kl: 0.0168, mse: 0.007752, wmse: 0.070198, mae: 0.068939, val nll: -0.9042, val mse 0.0092, lr 0.000010000\n",
      "2955,\tIter: 2955, train loss: -0.9983, avg nll: -1.0499, avg wnll: 36.7935, avg kl: 0.0152, mse: 0.007282, wmse: 0.066337, mae: 0.066243, val nll: -1.1589, val mse 0.0058, lr 0.000010000\n",
      "2956,\tIter: 2956, train loss: -1.0239, avg nll: -1.0748, avg wnll: 38.5199, avg kl: 0.0154, mse: 0.007096, wmse: 0.064963, mae: 0.064128, val nll: -0.9168, val mse 0.0089, lr 0.000010000\n",
      "2957,\tIter: 2957, train loss: -1.0329, avg nll: -1.0829, avg wnll: 37.5806, avg kl: 0.0154, mse: 0.006915, wmse: 0.061951, mae: 0.064459, val nll: -0.9968, val mse 0.0075, lr 0.000010000\n",
      "2958,\tIter: 2958, train loss: -1.0341, avg nll: -1.0841, avg wnll: 39.0572, avg kl: 0.0156, mse: 0.006903, wmse: 0.063121, mae: 0.064737, val nll: -1.0700, val mse 0.0071, lr 0.000010000\n",
      "2959,\tIter: 2959, train loss: -0.9975, avg nll: -1.0488, avg wnll: 37.6521, avg kl: 0.0150, mse: 0.007260, wmse: 0.066331, mae: 0.066642, val nll: -1.1036, val mse 0.0068, lr 0.000010000\n",
      "2960,\tIter: 2960, train loss: -1.0251, avg nll: -1.0767, avg wnll: 40.0569, avg kl: 0.0154, mse: 0.007247, wmse: 0.065412, mae: 0.065188, val nll: -0.9417, val mse 0.0090, lr 0.000010000\n",
      "test nll: -1.0223, test mse: 0.0079\n",
      "2961,\tIter: 2961, train loss: -1.0912, avg nll: -1.1377, avg wnll: 33.2139, avg kl: 0.0154, mse: 0.006225, wmse: 0.056895, mae: 0.061145, val nll: -0.8954, val mse 0.0105, lr 0.000010000\n",
      "2962,\tIter: 2962, train loss: -0.9805, avg nll: -1.0349, avg wnll: 43.3117, avg kl: 0.0156, mse: 0.007775, wmse: 0.069210, mae: 0.068348, val nll: -1.0763, val mse 0.0069, lr 0.000010000\n",
      "2963,\tIter: 2963, train loss: -1.0329, avg nll: -1.0840, avg wnll: 42.0602, avg kl: 0.0165, mse: 0.006924, wmse: 0.063146, mae: 0.064906, val nll: -1.0110, val mse 0.0075, lr 0.000010000\n",
      "2964,\tIter: 2964, train loss: -1.0201, avg nll: -1.0716, avg wnll: 36.6413, avg kl: 0.0149, mse: 0.007331, wmse: 0.066728, mae: 0.066285, val nll: -0.9109, val mse 0.0094, lr 0.000010000\n",
      "2965,\tIter: 2965, train loss: -1.0051, avg nll: -1.0581, avg wnll: 41.4380, avg kl: 0.0165, mse: 0.007295, wmse: 0.066944, mae: 0.066437, val nll: -1.0765, val mse 0.0064, lr 0.000010000\n",
      "2966,\tIter: 2966, train loss: -0.9967, avg nll: -1.0492, avg wnll: 43.6023, avg kl: 0.0151, mse: 0.007481, wmse: 0.067767, mae: 0.066946, val nll: -1.0812, val mse 0.0075, lr 0.000010000\n",
      "2967,\tIter: 2967, train loss: -1.0103, avg nll: -1.0634, avg wnll: 42.0125, avg kl: 0.0163, mse: 0.007377, wmse: 0.066882, mae: 0.066634, val nll: -0.9881, val mse 0.0080, lr 0.000010000\n",
      "2968,\tIter: 2968, train loss: -1.0153, avg nll: -1.0679, avg wnll: 41.1350, avg kl: 0.0164, mse: 0.007249, wmse: 0.066224, mae: 0.066099, val nll: -1.0766, val mse 0.0072, lr 0.000010000\n",
      "2969,\tIter: 2969, train loss: -1.0297, avg nll: -1.0813, avg wnll: 41.3945, avg kl: 0.0162, mse: 0.007066, wmse: 0.063472, mae: 0.065285, val nll: -1.0887, val mse 0.0069, lr 0.000010000\n",
      "2970,\tIter: 2970, train loss: -1.0168, avg nll: -1.0698, avg wnll: 41.8519, avg kl: 0.0162, mse: 0.007346, wmse: 0.066576, mae: 0.066496, val nll: -0.4224, val mse 0.0159, lr 0.000010000\n",
      "test nll: -1.1451, test mse: 0.0062\n",
      "2971,\tIter: 2971, train loss: -1.0307, avg nll: -1.0817, avg wnll: 42.1150, avg kl: 0.0160, mse: 0.007013, wmse: 0.064433, mae: 0.064904, val nll: -1.1052, val mse 0.0070, lr 0.000010000\n",
      "2972,\tIter: 2972, train loss: -1.0584, avg nll: -1.1081, avg wnll: 37.4477, avg kl: 0.0164, mse: 0.006657, wmse: 0.060780, mae: 0.063573, val nll: -1.1413, val mse 0.0061, lr 0.000010000\n",
      "2973,\tIter: 2973, train loss: -0.9886, avg nll: -1.0424, avg wnll: 45.2310, avg kl: 0.0158, mse: 0.007607, wmse: 0.069513, mae: 0.068579, val nll: -1.0593, val mse 0.0071, lr 0.000010000\n",
      "2974,\tIter: 2974, train loss: -1.0433, avg nll: -1.0924, avg wnll: 38.1252, avg kl: 0.0150, mse: 0.006827, wmse: 0.061539, mae: 0.064225, val nll: -0.9216, val mse 0.0087, lr 0.000010000\n",
      "2975,\tIter: 2975, train loss: -1.0525, avg nll: -1.1018, avg wnll: 39.3089, avg kl: 0.0161, mse: 0.006647, wmse: 0.060908, mae: 0.063596, val nll: -1.0980, val mse 0.0074, lr 0.000010000\n",
      "2976,\tIter: 2976, train loss: -1.0013, avg nll: -1.0542, avg wnll: 42.5883, avg kl: 0.0153, mse: 0.007503, wmse: 0.067580, mae: 0.067023, val nll: -1.1253, val mse 0.0063, lr 0.000010000\n",
      "2977,\tIter: 2977, train loss: -1.0523, avg nll: -1.1023, avg wnll: 38.0389, avg kl: 0.0161, mse: 0.006780, wmse: 0.061381, mae: 0.063736, val nll: -0.9022, val mse 0.0090, lr 0.000010000\n",
      "2978,\tIter: 2978, train loss: -1.0439, avg nll: -1.0930, avg wnll: 40.3220, avg kl: 0.0150, mse: 0.006828, wmse: 0.062118, mae: 0.063578, val nll: -1.0065, val mse 0.0071, lr 0.000010000\n",
      "2979,\tIter: 2979, train loss: -1.0079, avg nll: -1.0604, avg wnll: 42.3471, avg kl: 0.0170, mse: 0.007113, wmse: 0.064362, mae: 0.065789, val nll: -1.0646, val mse 0.0068, lr 0.000010000\n",
      "2980,\tIter: 2980, train loss: -1.0373, avg nll: -1.0866, avg wnll: 43.5961, avg kl: 0.0147, mse: 0.006901, wmse: 0.063419, mae: 0.064868, val nll: -1.1247, val mse 0.0064, lr 0.000010000\n",
      "test nll: -1.1238, test mse: 0.0062\n",
      "2981,\tIter: 2981, train loss: -0.9549, avg nll: -1.0116, avg wnll: 45.5665, avg kl: 0.0153, mse: 0.008285, wmse: 0.076215, mae: 0.071496, val nll: -0.9633, val mse 0.0089, lr 0.000010000\n",
      "2982,\tIter: 2982, train loss: -0.9843, avg nll: -1.0378, avg wnll: 45.4411, avg kl: 0.0160, mse: 0.007492, wmse: 0.068219, mae: 0.067784, val nll: -1.0230, val mse 0.0076, lr 0.000010000\n",
      "2983,\tIter: 2983, train loss: -1.0346, avg nll: -1.0859, avg wnll: 41.2460, avg kl: 0.0164, mse: 0.006964, wmse: 0.063685, mae: 0.064706, val nll: -0.9897, val mse 0.0081, lr 0.000010000\n",
      "2984,\tIter: 2984, train loss: -1.0319, avg nll: -1.0825, avg wnll: 38.8078, avg kl: 0.0158, mse: 0.006955, wmse: 0.063173, mae: 0.065607, val nll: -0.9525, val mse 0.0084, lr 0.000010000\n",
      "2985,\tIter: 2985, train loss: -0.9014, avg nll: -0.9627, avg wnll: 49.0503, avg kl: 0.0154, mse: 0.009163, wmse: 0.082959, mae: 0.073646, val nll: -0.8632, val mse 0.0100, lr 0.000010000\n",
      "2986,\tIter: 2986, train loss: -1.0108, avg nll: -1.0623, avg wnll: 41.9852, avg kl: 0.0148, mse: 0.007337, wmse: 0.067422, mae: 0.066176, val nll: -1.1023, val mse 0.0065, lr 0.000010000\n",
      "2987,\tIter: 2987, train loss: -0.9798, avg nll: -1.0339, avg wnll: 45.0954, avg kl: 0.0156, mse: 0.007703, wmse: 0.070447, mae: 0.068177, val nll: -1.1043, val mse 0.0066, lr 0.000010000\n",
      "2988,\tIter: 2988, train loss: -1.0512, avg nll: -1.1004, avg wnll: 36.4628, avg kl: 0.0151, mse: 0.006817, wmse: 0.061428, mae: 0.063387, val nll: -1.1033, val mse 0.0068, lr 0.000010000\n",
      "2989,\tIter: 2989, train loss: -0.9873, avg nll: -1.0409, avg wnll: 43.0730, avg kl: 0.0165, mse: 0.007415, wmse: 0.067665, mae: 0.067324, val nll: -1.0590, val mse 0.0069, lr 0.000010000\n",
      "2990,\tIter: 2990, train loss: -1.0239, avg nll: -1.0748, avg wnll: 39.5661, avg kl: 0.0147, mse: 0.007258, wmse: 0.065905, mae: 0.064703, val nll: -1.1366, val mse 0.0065, lr 0.000010000\n",
      "test nll: -1.0054, test mse: 0.0076\n",
      "2991,\tIter: 2991, train loss: -1.0096, avg nll: -1.0625, avg wnll: 41.5983, avg kl: 0.0154, mse: 0.007505, wmse: 0.068116, mae: 0.066375, val nll: -1.0819, val mse 0.0067, lr 0.000010000\n",
      "2992,\tIter: 2992, train loss: -0.9882, avg nll: -1.0436, avg wnll: 43.9522, avg kl: 0.0167, mse: 0.007749, wmse: 0.070977, mae: 0.067288, val nll: -0.9873, val mse 0.0079, lr 0.000010000\n",
      "2993,\tIter: 2993, train loss: -0.9820, avg nll: -1.0379, avg wnll: 43.4487, avg kl: 0.0168, mse: 0.007812, wmse: 0.070439, mae: 0.068720, val nll: -1.1147, val mse 0.0064, lr 0.000010000\n",
      "2994,\tIter: 2994, train loss: -1.0204, avg nll: -1.0717, avg wnll: 42.8883, avg kl: 0.0154, mse: 0.007174, wmse: 0.065334, mae: 0.065632, val nll: -0.8302, val mse 0.0115, lr 0.000010000\n",
      "2995,\tIter: 2995, train loss: -0.9554, avg nll: -1.0106, avg wnll: 44.2684, avg kl: 0.0158, mse: 0.007883, wmse: 0.071369, mae: 0.068868, val nll: -0.9323, val mse 0.0088, lr 0.000010000\n",
      "2996,\tIter: 2996, train loss: -1.0055, avg nll: -1.0575, avg wnll: 38.1991, avg kl: 0.0144, mse: 0.007531, wmse: 0.069375, mae: 0.067267, val nll: -1.0876, val mse 0.0067, lr 0.000010000\n",
      "2997,\tIter: 2997, train loss: -0.9680, avg nll: -1.0226, avg wnll: 42.8755, avg kl: 0.0154, mse: 0.007837, wmse: 0.071090, mae: 0.068487, val nll: -1.0536, val mse 0.0072, lr 0.000010000\n",
      "2998,\tIter: 2998, train loss: -1.0279, avg nll: -1.0779, avg wnll: 38.2093, avg kl: 0.0157, mse: 0.006865, wmse: 0.061724, mae: 0.064687, val nll: -1.0417, val mse 0.0071, lr 0.000010000\n",
      "2999,\tIter: 2999, train loss: -1.0737, avg nll: -1.1194, avg wnll: 36.7301, avg kl: 0.0143, mse: 0.006277, wmse: 0.057175, mae: 0.062236, val nll: -1.0358, val mse 0.0075, lr 0.000010000\n",
      "3000,\tIter: 3000, train loss: -0.9573, avg nll: -1.0132, avg wnll: 46.7503, avg kl: 0.0158, mse: 0.008021, wmse: 0.072769, mae: 0.070473, val nll: -0.9996, val mse 0.0083, lr 0.000010000\n",
      "test nll: -0.9050, test mse: 0.0101\n",
      "saving.................\n",
      "done\n",
      "3001,\tIter: 3001, train loss: -1.0308, avg nll: -1.0810, avg wnll: 37.5468, avg kl: 0.0140, mse: 0.007223, wmse: 0.064845, mae: 0.064846, val nll: -1.0525, val mse 0.0074, lr 0.000010000\n",
      "3002,\tIter: 3002, train loss: -1.0039, avg nll: -1.0559, avg wnll: 45.8790, avg kl: 0.0157, mse: 0.007257, wmse: 0.065762, mae: 0.066547, val nll: -0.9563, val mse 0.0085, lr 0.000010000\n",
      "3003,"
     ]
    }
   ],
   "source": [
    "! python3 ../../train.py data_folder=../../datasets/ZTF_MCG+08-11-011\\\n",
    "                        device=mps \\\n",
    "                        checkpoint=../../datasets/ZTF_MCG+08-11-011-0.9715341329574585.h5 \\\n",
    "                        training.optimizer.lr=0.00001 \\\n",
    "                        dataset.start_col=1 \\\n",
    "                        dataset.sep=comma \\\n",
    "                        dataset.shuffle=false \\\n",
    "                        training.scheduler.reset=true \\\n",
    "                        fixed.num_resamples=12 \\\n",
    "                        save_at=200 \\\n",
    "                        training.niters=100000 \\\n",
    "                        print_at=1 \\\n",
    "                        training.loss.kl_annealing=false \\\n",
    "                        filter.min_length=0 \\\n",
    "                        filter.keep_missing=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6331e2b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py:233: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_name='config', config_path='conf')\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Namespace(data_folder='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_MCG+08-11-011', checkpoint='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../checkpoints/exp_30/ZTF_gri0.8933992385864258.h5', seed=2, device='mps', shuffle=False, start_col=1, test_split=0.2, sep='comma', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=8, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=6000, patience=100000, batch_size=2, k_iwae=1, lr=5e-05, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, reset=True, factor=0.9, lr_patience=500, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=False, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=True, min_length=0, print_at=1, save_at=1000, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=12, is_bounded=True) 7255\n",
      "found 1 for band='r'\n",
      "found 1 for band='i'\n",
      "found 1 for band='g'\n",
      "max time:  1480.9922\n",
      "created union_tp attribute of length 3500\n",
      "dataset created, lcs.dataset.shape=(13, 3, 415, 3)\n",
      "train size: 10, valid size: 2, test size: 3\n",
      "=> loading checkpoint '/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../checkpoints/exp_30/ZTF_gri0.8933992385864258.h5'\n",
      "Namespace(data_folder='/home2/fggr82/astr/hetast/src/datasets/ZTF_gri', start_col=1, checkpoint=None, seed=2, device='mps', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=8, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=6000, patience=10000, batch_size=2, k_iwae=1, lr=0.0001, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, factor=0.9, lr_patience=35, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=True, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=False, min_length=25, print_at=1, save_at=30, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=0, is_bounded=True)\n",
      "reset scheduler to args.factor=0.9, args.threshold=0.01,args.lr_patience=500, args.lr=5e-05\n",
      "loaded checkpoint w/ loss=0.8933992385864258\n",
      "model_size=388294\n",
      "1321,/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/layers.py:83: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
      "\tIter: 1321, train loss: 461.9676, avg nll: 422.4739, avg wnll: 41063.1211, avg kl: 4.9006, mse: 6.918611, wmse: 61.622688, mae: 2.050118, val nll: 2.4801, val mse 4.9705, lr 0.000050000\n",
      "1322,\tIter: 1322, train loss: 27.7409, avg nll: 2.5437, avg wnll: 84.4621, avg kl: 7.6319, mse: 3.513058, wmse: 30.674986, mae: 1.448038, val nll: 5.7430, val mse 5.2851, lr 0.000050000\n",
      "1323,^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py\", line 242, in <module>\n",
      "    main()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 119, in run\n",
      "    ret = run_job(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py\", line 239, in main\n",
      "    train(args)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py\", line 127, in train\n",
      "    loss_info = net.compute_unsupervised_loss(\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/vae_model.py\", line 251, in compute_unsupervised_loss\n",
      "    loglik = self.compute_loglik(target_y, px, self.norm)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/vae_model.py\", line 216, in compute_loglik\n",
      "    log_p = utils.log_normal_pdf(\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/utils.py\", line 446, in log_normal_pdf\n",
      "    const = torch.from_numpy(np.array([2.0 * np.pi])).float().to(x.device)\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python3 ../../train.py data_folder=../../datasets/ZTF_MCG+08-11-011 \\\n",
    "                         checkpoint=../checkpoints/exp_30/ZTF_gri0.8933992385864258.h5 \\\n",
    "                         dataset.start_col=1 \\\n",
    "                         dataset.shuffle=false \\\n",
    "                         fixed.num_resamples=12 \\\n",
    "                         device=mps \\\n",
    "                         print_at=1 \\\n",
    "                         training.scheduler.reset=True \\\n",
    "                         training.optimizer.lr=0.00005\\\n",
    "                         save_at=1000 \\\n",
    "                         filter.keep_missing=True \\\n",
    "                         training.loss.kl_annealing=false \\\n",
    "                         filter.min_length=0\\\n",
    "                         dataset.sep=comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "9383fcbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py:233: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_name='config', config_path='conf')\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Namespace(data_folder='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_rm_segs/MCG+08-11-011/X/ZTF_epoch1_', checkpoint='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../checkpoints/exp_30/ZTF_gri0.8933992385864258.h5', seed=2, device='mps', shuffle=False, start_col=0, test_split=0.2, sep='whitespace', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=8, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=6000, patience=100000, batch_size=2, k_iwae=1, lr=0.0001, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, reset=True, factor=0.9, lr_patience=500, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=False, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=True, min_length=0, print_at=1, save_at=1000, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=12, is_bounded=True) 2220\n",
      "found 1 for band='r'\n",
      "found 2 for band='i'\n",
      "found 2 for band='g'\n",
      "found 0 for band='.ipynb_checkpoints'\n",
      "max time:  280.6875\n",
      "created union_tp attribute of length 3500\n",
      "dataset created, lcs.dataset.shape=(13, 3, 138, 3)\n",
      "train size: 10, valid size: 2, test size: 3\n",
      "=> loading checkpoint '/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../checkpoints/exp_30/ZTF_gri0.8933992385864258.h5'\n",
      "Namespace(data_folder='/home2/fggr82/astr/hetast/src/datasets/ZTF_gri', start_col=1, checkpoint=None, seed=2, device='mps', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=8, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=6000, patience=10000, batch_size=2, k_iwae=1, lr=0.0001, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, factor=0.9, lr_patience=35, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=True, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=False, min_length=25, print_at=1, save_at=30, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=0, is_bounded=True)\n",
      "reset scheduler to args.factor=0.9, args.threshold=0.01,args.lr_patience=500, args.lr=0.0001\n",
      "loaded checkpoint w/ loss=0.8933992385864258\n",
      "model_size=388294\n",
      "1321,/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/layers.py:83: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
      "\tIter: 1321, train loss: nan, avg nll: nan, avg wnll: nan, avg kl: nan, mse: nan, wmse: nan, mae: nan, val nll: nan, val mse nan, lr 0.000100000\n",
      "nan in loss,,,,,,,,, stopping\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python3 ../../train.py data_folder=../../datasets/ZTF_rm_segs/MCG+08-11-011/X/ZTF_epoch1_ \\\n",
    "                         checkpoint=../checkpoints/exp_30/ZTF_gri0.8933992385864258.h5 \\\n",
    "                         dataset.start_col=0 \\\n",
    "                         dataset.shuffle=false \\\n",
    "                         fixed.num_resamples=12 \\\n",
    "                         device=mps \\\n",
    "                         print_at=1 \\\n",
    "                         training.scheduler.reset=True \\\n",
    "                         training.optimizer.lr=0.0001\\\n",
    "                         save_at=1000 \\\n",
    "                         training.loss.kl_annealing=false \\\n",
    "                         filter.min_length=0 \\\n",
    "                         filter.keep_missing=True \\\n",
    "                         dataset.sep=whitespace \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "25b37f5f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py:233: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_name='config', config_path='conf')\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "Namespace(data_folder='/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../datasets/ZTF_rm_segs/NGC5548/X/ZTF_epoch3_', checkpoint=None, seed=2, device='mps', shuffle=False, start_col=0, test_split=0.2, sep='whitespace', net='HeTVAE', mixing='concat', n_union_tp=3500, embed_time=128, num_heads=8, latent_dim=64, num_ref_points=16, rec_hidden=128, width=512, niters=6000, patience=100000, batch_size=2, k_iwae=1, lr=0.0001, beta1=0.9, beta2=0.999, scheduler=True, warmup=10, reset=True, factor=0.9, lr_patience=500, threshold=0.01, dropout=0.1, inc_errors=False, frac=0.5, mse_weight=5.0, kl_annealing=False, kl_itrs=6000, n_cycles=32, start=0.0, stop=0.8, ratio=0.5, keep_missing=False, min_length=1, print_at=1, save_at=1000, kl_zero=False, const_var=False, var_per_dim=False, num_resamples=12, is_bounded=True) 7667\n",
      "found 2 for band='r'\n",
      "found 2 for band='i'\n",
      "found 2 for band='g'\n",
      "max time:  361.02734\n",
      "created union_tp attribute of length 3500\n",
      "dataset created, lcs.dataset.shape=(13, 3, 541, 3)\n",
      "train size: 10, valid size: 2, test size: 3\n",
      "model_size=388294\n",
      "1,/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/layers.py:83: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  scores = scores.unsqueeze(-1).repeat_interleave(dim, dim=-1)\n",
      "\tIter: 1, train loss: 6.5747, avg nll: 1.5645, avg wnll: 55.9429, avg kl: 0.0537, mse: 0.991302, wmse: 7.420420, mae: 0.849805, val nll: 1.6122, val mse 1.0230, lr 0.000100000\n",
      "2,\tIter: 2, train loss: 6.7266, avg nll: 1.6176, avg wnll: 60.7659, avg kl: 0.0481, mse: 1.012172, wmse: 7.591295, mae: 0.859930, val nll: 1.5647, val mse 0.9525, lr 0.000100000\n",
      "3,\tIter: 3, train loss: 6.7380, avg nll: 1.6738, avg wnll: 67.0292, avg kl: 0.0539, mse: 1.002056, wmse: 7.517063, mae: 0.858793, val nll: 1.7117, val mse 0.9922, lr 0.000100000\n",
      "4,\tIter: 4, train loss: 6.8845, avg nll: 1.7929, avg wnll: 77.9589, avg kl: 0.0659, mse: 1.005139, wmse: 7.536200, mae: 0.856107, val nll: 1.8750, val mse 0.9947, lr 0.000100000\n",
      "5,\tIter: 5, train loss: 7.0708, avg nll: 2.0054, avg wnll: 95.8376, avg kl: 0.0859, mse: 0.995904, wmse: 7.463745, mae: 0.854888, val nll: 2.2254, val mse 1.0210, lr 0.000100000\n",
      "6,^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py\", line 242, in <module>\n",
      "    main()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 119, in run\n",
      "    ret = run_job(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py\", line 239, in main\n",
      "    train(args)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/notebooks/misc/../../train.py\", line 127, in train\n",
      "    loss_info = net.compute_unsupervised_loss(\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/vae_model.py\", line 248, in compute_unsupervised_loss\n",
      "    px, qz = self.get_reconstruction(\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/vae_model.py\", line 192, in get_reconstruction\n",
      "    px = self.decode(z, target_x)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/vae_model.py\", line 153, in decode\n",
      "    hidden = self.decoder(target_x, self.query, z)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/hetvae/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/layers.py\", line 131, in forward\n",
      "    x, intensity = self.attention(query, key, value, mask, self.dropout)\n",
      "  File \"/Users/mattlowery/Desktop/Desko/code/astro/hetast/src/layers.py\", line 82, in attention\n",
      "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python3 ../../train.py data_folder=datasets/ZTF_g \\\n",
    "                         dataset.start_col=1 \\\n",
    "                         dataset.shuffle=True \\\n",
    "                         device=mps \\\n",
    "                         print_at=1 \\\n",
    "                         training.optimizer.lr=0.0001\\\n",
    "                         save_at=1000 \\\n",
    "                         filter.keep_missing=true\\\n",
    "                         filter.min_length=1 \\\n",
    "                         dataset.sep=comma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hetvae",
   "language": "python",
   "name": "hetvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
