{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader, device='mps', k_iwae=2): # how will we decide to set target_x, or choose not to mask so you use all the points in the interpolation\n",
    "    pred_mean, pred_std = [], []\n",
    "    masks = []\n",
    "    targets = []\n",
    "    tp =[]\n",
    "    np.random.seed(0)\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch_len = batch.shape[0]\n",
    "            batch = batch.to(device)\n",
    "            subsampled_mask = batch[:,:,:,4]\n",
    "            recon_mask = batch[:,:,:,5]\n",
    "            context_y = torch.cat((batch[:,:,:,1] * subsampled_mask, subsampled_mask), 1).transpose(2,1)\n",
    "            px, qz = net.get_reconstruction(batch[:, 0, :,0], context_y, batch[:, 0, :,0], num_samples=k_iwae)\n",
    "            pred_mean.append(px.mean.cpu().numpy())\n",
    "            pred_std.append(torch.exp(0.5 * px.logvar).cpu().numpy())\n",
    "            targets.append((batch[:, :, :,1]).cpu().numpy())\n",
    "            masks.append(subsampled_mask.cpu().numpy())\n",
    "            tp.append(batch[:, 0, :,0].cpu().numpy())\n",
    "      \n",
    "    pred_mean = np.concatenate(pred_mean, axis=1)\n",
    "    pred_std = np.concatenate(pred_std, axis=1)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    masks = np.concatenate(masks, axis=0)\n",
    "    tp = np.concatenate(tp, axis=0)\n",
    "    print(pred_mean.shape, pred_std.shape, targets.shape, masks.shape, tp.shape)\n",
    "    inputs = np.ma.masked_where(masks < 1., targets)\n",
    "    inputs = np.transpose(inputs, [0,2,1])\n",
    "    # reparam trick\n",
    "    preds = np.random.randn(k_iwae//2, k_iwae, pred_mean.shape[1], pred_mean.shape[2], pred_mean.shape[3]) * pred_std + pred_mean\n",
    "    preds = preds.reshape(-1, pred_mean.shape[1], pred_mean.shape[2], pred_mean.shape[3])\n",
    "    return preds\n",
    "\n",
    "def get_latent_dist(dataloader, device='mps', k_iwae=2):\n",
    "    qz_mean, qz_std = [], []\n",
    "    np.random.seed(0)\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch_len = batch.shape[0]\n",
    "            batch = batch.to(device)\n",
    "            subsampled_mask = batch[:,:,:,4]\n",
    "            recon_mask = batch[:,:,:,5]\n",
    "            context_y = torch.cat((batch[:,:,:,1] * subsampled_mask, subsampled_mask), 1).transpose(2,1)\n",
    "            # context_x = train_batch[:,0,:,0], where we'd set a target x\n",
    "            #print(batch[:, 0, :,0].shape)\n",
    "            px, qz = net.get_reconstruction(batch[:, 0, :,0], context_y, batch[:, 0, :,0], num_samples=k_iwae)\n",
    "            qz_mean.append(qz.mean.cpu().numpy())\n",
    "            qz_std.append(torch.exp(0.5 * qz.logvar).cpu().numpy())\n",
    "   \n",
    "    qz_mean = np.concatenate(qz_mean, axis=0)\n",
    "    qz_std = np.concatenate(qz_std, axis=0)\n",
    "    print(qz_mean.shape, qz_std.shape)\n",
    "    preds = np.random.randn(k_iwae//2, k_iwae, qz_mean.shape[0], qz_mean.shape[1], qz_mean.shape[2]) * qz_std + qz_mean\n",
    "    preds = preds.reshape(-1, qz_mean.shape[0], qz_mean.shape[1], qz_mean.shape[2])\n",
    "    median = preds.mean(0)\n",
    "    print(median.shape)\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer,epoch, train_loader, args, device=\"cuda\", frac=0.5, errors=False, beta=0.1):\n",
    "      \n",
    "    train_loss = 0.\n",
    "    train_n = 0.\n",
    "    avg_loglik, avg_kl, mse, mae = 0., 0., 0., 0.\n",
    "    for i, train_batch in enumerate(train_loader):\n",
    "        batch_len = train_batch.shape[0] \n",
    "        #train_batch[:,:,2] = torch.ones((train_batch[:,:,3].shape))\n",
    "        recon_mask, subsampled_mask = make_masks(train_batch, frac=0.5)\n",
    "        \n",
    "        train_batch = torch.cat((train_batch, torch.unsqueeze(subsampled_mask, 2), torch.unsqueeze(recon_mask, 2)), axis=-1)\n",
    "        # print(torch.unsqueeze(subsampled_mask, 2).shape)\n",
    "        # print(train_batch.shape)\n",
    "        # train_batch[:,:,4:5] = torch.unsqueeze(recon_mask[:,:], 2)\n",
    "        # train_batch[:,:,3:4] = torch.unsqueeze(subsampled_mask[:,:], 2)\n",
    "        train_batch = train_batch.to(device)\n",
    "        x = train_batch[:,:,0]\n",
    "        y = train_batch[:,:,1:2]\n",
    "        subsampled_mask = train_batch[:,:,3:4]\n",
    "        recon_mask = train_batch[:,:,4:5]\n",
    "        if errors:\n",
    "            sample_weight = train_batch[:,:,2:3]\n",
    "        else:\n",
    "            sample_weight = 1.\n",
    "        # weights for loss in analogy to standard weighted least squares error \n",
    "\n",
    "        seqlen = train_batch.size(1) \n",
    "        # subsampled flux values and their corresponding masks....\n",
    "        context_y = torch.cat((\n",
    "            y * subsampled_mask, subsampled_mask\n",
    "        ), -1) \n",
    "        recon_context_y = torch.cat((            # flux values with only recon_mask values showing\n",
    "                y * recon_mask, recon_mask\n",
    "            ), -1) \n",
    "# format: compute_unsupervised_loss(self, context_x, context_y, target_x, target_y, num_samples=1, beta=1):\n",
    "        loss_info = net.compute_unsupervised_loss(\n",
    "            x,\n",
    "            context_y,  \n",
    "            x,  # can pick the points we want to project to\n",
    "            recon_context_y,\n",
    "            num_samples=args.k_iwae, # 1? \n",
    "            beta=beta, # beta i s a \n",
    "            # optional, will be zero if not set\n",
    "            sample_weight = sample_weight,\n",
    "\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss_info.composite_loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        train_loss += loss_info.composite_loss.item() * batch_len\n",
    "        avg_loglik += loss_info.loglik * batch_len\n",
    "        avg_kl += loss_info.kl * batch_len\n",
    "        mse += loss_info.mse * batch_len\n",
    "        mae += loss_info.mae * batch_len\n",
    "        train_n += batch_len\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            'Iter: {}, train loss: {:.4f}, avg nll: {:.4f}, avg kl: {:.4f}, '\n",
    "            'mse: {:.6f}, mae: {:.6f}'.format(\n",
    "                epoch,\n",
    "                train_loss / train_n,\n",
    "                -avg_loglik / train_n,\n",
    "                avg_kl / train_n,\n",
    "                mse / train_n,\n",
    "                mae / train_n\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return -avg_loglik / train_n, mse / train_n, y, recon_mask, subsampled_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hetvae",
   "language": "python",
   "name": "hetvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
